{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import gamma, poisson\n",
    "\n",
    "import epyestim\n",
    "import epyestim.covid19 as covid19\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE, r2_score\n",
    "from xgboost import XGBRegressor, DMatrix, train\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, TimeDistributed, RepeatVector\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import plotly.express as px\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "\n",
    "to_sum_KPIs = ['totale_casi_giornalieri', 'terapia_intensiva_giornalieri', 'terapia_intensiva', 'nuovi_positivi', 'tamponi_giornalieri']\n",
    "covidKPIsPrecompute = ['%pos']+to_sum_KPIs\n",
    "trafficKPIsPrecompute = ['Handover', 'Download vol.', 'Upload vol.', '#Users']\n",
    "\n",
    "# sums regions such as trento + bolzano\n",
    "def sumRegions(df, dateCol = 'Date', regionCol='Regione', cols = to_sum_KPIs, region1 = \"P.A. Bolzano\", region2 = \"P.A. Trento\", regionNew = \"Trentino-Alto Adige\"):\n",
    "    dfRegion1, dfRegion2 = df.loc[df[regionCol] == region1], df.loc[df[regionCol] == region2]\n",
    "    dfRegion1.set_index(dateCol, inplace=True)\n",
    "    dfRegion2.set_index(dateCol, inplace=True)\n",
    "    newVals = dfRegion1[to_sum_KPIs]+dfRegion2[to_sum_KPIs]\n",
    "    newVals.reset_index(inplace=True)\n",
    "    newVals['Regione'] = regionNew\n",
    "    df = df.loc[(df[regionCol] != region1) & (df[regionCol] != region2)]\n",
    "    return df.append(newVals)\n",
    "\n",
    "# adds italy as cumulative over days\n",
    "def addItalyData(df, cols):\n",
    "    dfTemp = df.resample('D', on='Date').sum().reset_index()\n",
    "    dfTemp['Regione']='Italia'\n",
    "    dfTemp = dfTemp[cols]\n",
    "    return pd.concat([df, dfTemp])\n",
    "\n",
    "def fill_with_areas(dateRange, fig, is_train):\n",
    "    if is_train:\n",
    "        color = 'rgba(255, 0, 0, 0.2)'\n",
    "    else:\n",
    "        color = 'rgba(0, 0, 255, 0.2)'\n",
    "    fig.add_shape(type=\"rect\",\n",
    "        yref=\"paper\",\n",
    "        x0=dateRange[0], y0=0,\n",
    "        x1=dateRange[-1], y1=1,\n",
    "        line=dict(\n",
    "            width=0,\n",
    "        ),\n",
    "        fillcolor=color,\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "data_path = \"/Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/\"\n",
    "by_region_path = \"{}By_Region/\".format(data_path)\n",
    "saved = \"{}saved/\".format(data_path)\n",
    "traffic_daily = \"{}TS_1800_daily.pkl\".format(saved)\n",
    "region_traffic_daily = \"{}all.pkl\".format(saved)\n",
    "covid = \"{}covid/\".format(data_path)\n",
    "covid_daily = \"{}covid_2303.csv\".format(covid)\n",
    "\n",
    "capped_last_date = pd.to_datetime('2021-01-15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_path = \"{}meteo/\".format(data_path)\n",
    "dfs_filenames = [f for f in listdir(meteo_path) if isfile(join(meteo_path, f))]\n",
    "dfs = []\n",
    "path_temperature_predictions = \"{}predictions/temperatures.csv\".format(saved)\n",
    "SAVE_TEMPERATURE = False\n",
    "if SAVE_TEMPERATURE:\n",
    "    for f in dfs_filenames:\n",
    "        splits = f.split(\"_\")\n",
    "        if len(splits) == 2 and \".\" in splits[1]:\n",
    "            filename = \"{}{}\".format(meteo_path, f)\n",
    "            current_df = pd.read_csv(filename)\n",
    "            region_name = splits[0]\n",
    "            #if \"rentino\" not in region_name and \"osta\" not in region_name:\n",
    "            month = splits[1][4:].split(\".\")[0]\n",
    "            current_df['Regione'] = [r for r in regions_covid if region_name in r.lower()][0]\n",
    "            current_df['month'] = int(month)\n",
    "            current_df['year'] = int(2021 if \"2021\" in filename else 2020)\n",
    "            dfs.append(current_df)\n",
    "        df_temperature = pd.concat(dfs)\n",
    "        df_temperature['Date'] = df_temperature.apply(lambda x: pd.to_datetime(\"{}/{}/{}\".format(x.year, x.month, int(x.date.split(\" \")[1]))), axis=1)\n",
    "        df_temperature.set_index(['Date', 'Regione'], inplace=True)\n",
    "        df_temperature['Date'] = pd.to_datetime(df_temperature['Date'])\n",
    "        df_temperature.to_csv(path_temperature_predictions)\n",
    "else:\n",
    "    df_temperature = pd.read_csv(path_temperature_predictions)\n",
    "    df_temperature['Date'] = pd.to_datetime(df_temperature['Date'])\n",
    "    df_temperature.set_index(['Date', 'Regione'], inplace=True)\n",
    "    \n",
    "regions_temperature = df_temperature.index.get_level_values(1).unique()\n",
    "regions = regions_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle COVID data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute_rt = False\n",
    "import_covid  = True\n",
    "path_covid = \"{}covid.csv\".format(saved)\n",
    "\n",
    "if import_covid:\n",
    "    df_covid = pd.read_csv(covid_daily)\n",
    "    if \"Regione\" not in df_covid.columns:\n",
    "        df_covid.rename(columns={'denominazione_regione': 'Regione'}, inplace=True)\n",
    "        df_covid['tamponi_giornalieri'] = df_covid.groupby([\n",
    "                        'Regione'])['tamponi'].diff()\n",
    "        df_covid.loc[df_covid['tamponi_giornalieri'].isna() ,\n",
    "                               'tamponi_giornalieri'] = df_covid['tamponi']\n",
    "\n",
    "\n",
    "        df_covid['deceduti_giornalieri'] = df_covid.groupby([\n",
    "                            'Regione'])['deceduti'].diff()\n",
    "        df_covid.loc[df_covid['deceduti_giornalieri'].isna() ,\n",
    "                               'deceduti_giornalieri'] = df_covid['deceduti']\n",
    "\n",
    "        df_covid['terapia_intensiva_giornalieri'] = df_covid.groupby([\n",
    "                            'Regione'])['terapia_intensiva'].diff()\n",
    "        df_covid.loc[df_covid['terapia_intensiva_giornalieri'].isna() ,\n",
    "                               'terapia_intensiva_giornalieri'] = df_covid['terapia_intensiva']\n",
    "\n",
    "        df_covid['totale_casi_giornalieri'] = df_covid.groupby([\n",
    "                            'Regione'])['totale_casi'].diff()\n",
    "        df_covid.loc[df_covid['totale_casi_giornalieri'].isna() ,\n",
    "                               'totale_casi_giornalieri'] = df_covid['totale_casi']\n",
    "    covid_cols = ['Date', 'Regione', 'terapia_intensiva', 'nuovi_positivi', 'tamponi_giornalieri', 'totale_casi', 'deceduti', 'totale_casi_giornalieri', 'terapia_intensiva_giornalieri']\n",
    "    \n",
    "    try:\n",
    "        df_covid.data = pd.to_datetime(df_covid.data)\n",
    "        df_covid.rename(columns={'data': 'Date'}, inplace=True)\n",
    "    except:\n",
    "        pass # already correct name\n",
    "    df_covid = sumRegions(df_covid)\n",
    "    regions_covid = df_covid['Regione'].unique()\n",
    "    #df_covid = df_covid[df_covid['Regione'].isin(regions)].dropna()\n",
    "    df_covid.to_csv(path_covid)\n",
    "else:\n",
    "    try:\n",
    "        del df_covid\n",
    "    except:\n",
    "        print(\"No df covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "path_covid_predictions=\"{}predictions/covid_2303.pkl\".format(saved)\n",
    "if recompute_rt:\n",
    "    for r in regions:\n",
    "        print(\"REGIONE: {}\".format(r))\n",
    "        current_df = df_covid.loc[df_covid['Regione'] == r]\n",
    "        current_df['Date'] = pd.to_datetime(current_df['Date']).dt.date\n",
    "        current_df['DateIndex'] = current_df.loc[:, 'Date']\n",
    "        current_df.set_index('DateIndex', inplace=True)\n",
    "        #current_df = current_df.loc[current_df['nuovi_positivi'] > 0]\n",
    "        current_df = current_df.loc[pd.to_datetime('2020/03/01'):]\n",
    "        idxs = (current_df['nuovi_positivi'] < 0)# | (current_df.isna()) | (current_df['nuovi_positivi'] == np.inf) | (current_df['nuovi_positivi'] == -np.inf)\n",
    "        if idxs.sum() > 0:\n",
    "            current_df.loc[idxs, 'nuovi_positivi'] = np.nan\n",
    "        current_df.fillna(method='ffill', inplace=True)\n",
    "        current_df.dropna(subset=['nuovi_positivi'], inplace=True)\n",
    "        #current_df[current_df.loc[:, 'nuovi_positivi']]\n",
    "        #current_df.dropna(subset=['nuovi_positivi'], inplace=True)\n",
    "        #\n",
    "        current_df = current_df.drop_duplicates(keep='first')\n",
    "        #print(current_df['nuovi_positivi'].shape, current_df['nuovi_positivi'].apply(lambda x: x < 0).sum())\n",
    "        #current_df.dropna(subset=['totale_casi_giornalieri'], inplace=True)\n",
    "        #print(current_df['totale_casi_giornalieri'].isna().sum())\n",
    "        #print(current_df['totale_casi_giornalieri'].sum())\n",
    "        r_t_series = covid19.r_covid(current_df['nuovi_positivi'])\n",
    "        current_df = pd.merge(current_df, r_t_series, left_index=True, right_index=True)\n",
    "        dfs.append(current_df)\n",
    "    df_covid_predictions = pd.concat(dfs)\n",
    "    del dfs\n",
    "    df_covid_predictions.set_index(['Date', 'Regione'], inplace=True)\n",
    "    df_covid_predictions['%pos'] = (df_covid_predictions['nuovi_positivi']/df_covid_predictions['tamponi_giornalieri'])\n",
    "    df_covid_predictions.to_pickle(path_covid_predictions)\n",
    "else:\n",
    "    df_covid_predictions = pd.read_pickle(path_covid_predictions)\n",
    "\n",
    "df_unseen_covid = df_covid_predictions.loc[df_covid_predictions.index.get_level_values('Date')>=capped_last_date]\n",
    "#df_covid_predictions = df_covid_predictions.loc[df_covid_predictions.index.get_level_values('Date')<capped_last_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle traffic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_traffic = True\n",
    "recompute_kalman = False\n",
    "recompute_MA = True\n",
    "path_traffic = \"{}traffic.csv\".format(saved)\n",
    "start_date_unavailable, end_date_unavailable = pd.to_datetime('2020-08-01'), pd.to_datetime('2020-10-01')\n",
    "dates_unavailable = pd.date_range(start_date_unavailable, end_date_unavailable)\n",
    "if import_traffic:\n",
    "    df_traffic_daily = pd.read_pickle(region_traffic_daily)\n",
    "    df_traffic_daily.loc[df_traffic_daily['Regione'] == \"Emilia Romagna\", \"Regione\"] = \"Emilia-Romagna\"\n",
    "    df_traffic_predictions = df_traffic_daily.loc[df_traffic_daily['Regione'].isin(regions)]\n",
    "    df_traffic_predictions = df_traffic_predictions.groupby('Regione').resample('D', on='Date').sum().reset_index()\n",
    "    df_traffic_predictions = df_traffic_predictions.replace({'0':np.nan, 0:np.nan})\n",
    "    df_traffic_predictions = df_traffic_predictions.loc[(df_traffic_predictions['Date']<start_date_unavailable)|(df_traffic_predictions['Date']>=end_date_unavailable)]\n",
    "    df_traffic_predictions = df_traffic_predictions.fillna(method='ffill')\n",
    "    df_traffic_predictions['Date'] = pd.to_datetime(df_traffic_predictions['Date']).dt.date\n",
    "    df_traffic_predictions.set_index(['Date', 'Regione'], inplace=True)\n",
    "    df_traffic_predictions.to_csv(path_traffic)\n",
    "else:\n",
    "    df_traffic_predictions = pd.read_csv(path_traffic)\n",
    "    df_traffic_predictions['Date'] = pd.to_datetime(df_traffic_predictions['Date']).dt.date\n",
    "    df_traffic_predictions.set_index(['Date', 'Regione'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply MA to traffic features\n",
    "path_traffic_predictions=\"{}predictions/traffic.pkl\".format(saved)\n",
    "if recompute_MA:\n",
    "    for trafficKPI in trafficKPIsPrecompute:\n",
    "        #current_df_kalman = pd.DataFrame({\"{}_smoothened\".format(trafficKPI): []})\n",
    "        dfs_current_kpi = []\n",
    "        for region in regions:\n",
    "            series = df_traffic_predictions.xs(region, level=1)[trafficKPI]\n",
    "            # t = 21/03 -> current_series = series[:t] -> .em(current_series) -> features_for_day_t = smooth(current_series)\n",
    "            rolling_amount = 7\n",
    "            series_ma = series.rolling(rolling_amount).mean()\n",
    "            \n",
    "            series_ma = series_ma.loc[(series_ma.index<start_date_unavailable)|(series_ma.index>=end_date_unavailable+pd.Timedelta(days=rolling_amount))]\n",
    "            \n",
    "            df_region_kpi = pd.DataFrame({\"noisy\": series})\n",
    "            df_region_kpi['smooth'] = series_ma\n",
    "            df_region_kpi['Regione'] = region\n",
    "            df_region_kpi.reset_index(inplace=True)\n",
    "            df_region_kpi.set_index(['Date', 'Regione'], inplace=True)\n",
    "            dfs_current_kpi.append(df_region_kpi)\n",
    "\n",
    "        df_traffic_predictions[\"{}_MA\".format(trafficKPI)] = pd.concat(dfs_current_kpi)['smooth']\n",
    "        df_traffic_predictions.to_pickle(path_traffic_predictions)\n",
    "else:\n",
    "    df_traffic_predictions = pd.read_pickle(path_traffic_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficKPIs = [col for col in df_traffic_predictions.columns if \"MA\" in col]\n",
    "covidKPIs = [col for col in df_covid_predictions.columns if \"mean\" in col]\n",
    "temperatureKPIs = []#[col for col in df_temperature.columns if \"min\" in col]\n",
    "targetCovid = ['R_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Handover_MA', 'Download vol._MA', 'Upload vol._MA', '#Users_MA']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficKPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_prediction(range_dates, min_farsightness, farsightness, delta_features, step_target):\n",
    "    lags = range(delta_features)\n",
    "    lags_target = range(min_farsightness, farsightness, step_target)\n",
    "    all_dfs = []\n",
    "    # prima ondata\n",
    "    for region in regions_to_train:\n",
    "        # filter ts by region\n",
    "        df_traffic_ts = df_traffic_predictions.loc[(df_traffic_predictions.index.get_level_values(1)==region), trafficKPIs].copy()\n",
    "        df_covid_ts = df_covid_predictions.loc[df_covid_predictions.index.get_level_values(1)==region, list(set(covidKPIs+targetCovid))].copy()\n",
    "        df_temperature_ts = df_temperature.loc[df_temperature.index.get_level_values(1)==region, temperatureKPIs].copy()\n",
    "        \n",
    "        df_traffic_ts = df_traffic_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "        df_temperature_ts = df_temperature_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "\n",
    "        df_covid_ts.reset_index(inplace=True)\n",
    "        df_temperature_ts.reset_index(inplace=True)\n",
    "        df_traffic_ts.reset_index(inplace=True)\n",
    "\n",
    "        df_covid_ts = df_covid_ts.set_index('Date')\n",
    "        df_temperature_ts = df_temperature_ts.set_index('Date')\n",
    "        df_traffic_ts = df_traffic_ts.set_index('Date')\n",
    "\n",
    "        df_ts = pd.DataFrame()\n",
    "        features = []\n",
    "        targets = []\n",
    "        target_col = targetCovid[0]\n",
    "        df_target_ts = df_covid_ts.copy()\n",
    "\n",
    "        train_dates_intersection = df_traffic_ts.index.intersection(df_covid_ts.index)\n",
    "\n",
    "        train_dates = []\n",
    "        if len(temperatureKPIs) > 0:\n",
    "            train_dates_intersection = train_dates_intersection.isin(df_temperature_ts.index)\n",
    "        for date_val in train_dates_intersection:\n",
    "            if any(date_val in x for x in range_dates):\n",
    "                train_dates.append(date_val)\n",
    "\n",
    "        train_dates = pd.to_datetime(train_dates)\n",
    "\n",
    "        df_covid_ts, df_traffic_ts, df_temperature_ts = df_covid_ts.loc[df_covid_ts.index.isin(train_dates)], df_traffic_ts.loc[df_traffic_ts.index.isin(train_dates)], df_temperature_ts.loc[df_temperature_ts.index.isin(train_dates)]\n",
    "\n",
    "        for lag in lags_target:\n",
    "            target = \"target_{}\".format(lag)\n",
    "            targets.append(target)\n",
    "            df_ts[target] = df_target_ts.copy().shift(-1*lag)[target_col]\n",
    "        \n",
    "        # use also today feature\n",
    "        use_today_feature = True\n",
    "        if use_today_feature:\n",
    "            if len(trafficKPIs) > 0:\n",
    "                df_ts[trafficKPIs] = df_traffic_ts[trafficKPIs].copy()\n",
    "                features += trafficKPIs\n",
    "            if len(covidKPIs) > 0:\n",
    "                df_ts[covidKPIs] = df_covid_ts[covidKPIs].copy()\n",
    "                features += covidKPIs\n",
    "        \n",
    "        for lag in lags:\n",
    "            lag_shift = lag+1\n",
    "            for col in trafficKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                #print(feature, df_traffic_ts.shift(lag_shift).loc[:, col])\n",
    "                df_ts[feature] = df_traffic_ts.copy().shift(lag_shift).loc[:, col]\n",
    "                features.append(feature)\n",
    "            for col in covidKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_covid_ts.copy().shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            for col in temperatureKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_temperature_ts.copy().shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "\n",
    "        df_ts = df_ts[targets+features]\n",
    "        df_ts.dropna(subset=features, inplace=True)\n",
    "        df_ts['Regione'] = region\n",
    "        df_ts = df_ts.reset_index().set_index(['Date', 'Regione'])\n",
    "        all_dfs.append(df_ts.copy())\n",
    "    return pd.concat(all_dfs), targets, features, lags, lags_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider_po, divider_so = pd.to_datetime('2020-07-01'), pd.to_datetime('2020-10-01')\n",
    "start_train_po, end_train_so = pd.to_datetime('2020-03-01'), pd.to_datetime('2020-10-25')\n",
    "start_po = start_train_po\n",
    "ranges_train_PO = [pd.date_range(start_po, divider_po)]\n",
    "ranges_train_SO = [pd.date_range(divider_so, end_train_so)]\n",
    "last_date_with_unseen = min(df_traffic_predictions.index.get_level_values(0).max(), df_unseen_covid.index.get_level_values(0).max())\n",
    "\n",
    "last_date = min(last_date_with_unseen, capped_last_date)\n",
    "\n",
    "ranges_unseen = [pd.date_range(last_date, last_date_with_unseen)]\n",
    "\n",
    "if len(temperatureKPIs) > 0:\n",
    "    last_date = min(last_date, df_temperature.index.get_level_values(0).max())\n",
    "ranges_so = [pd.date_range(divider_so, last_date)]\n",
    "regions_to_train = regions\n",
    "\n",
    "min_farsightness = 1\n",
    "farsightness = 35\n",
    "delta_features = 7\n",
    "step_target = 1\n",
    "\n",
    "ranges_test_SO = [pd.date_range(end_train_so-pd.Timedelta(days=delta_features-1), last_date_with_unseen)]\n",
    "\n",
    "(df_train_prediction_PO, targets, features, lags, lags_target), (df_train_prediction_SO, _, _, _, _) = \\\n",
    "    build_df_prediction(ranges_train_PO, min_farsightness, farsightness, delta_features, step_target), \\\n",
    "    build_df_prediction(ranges_train_SO, min_farsightness, farsightness, delta_features, step_target)\n",
    "\n",
    "(df_test_prediction, _, _, _, _) = build_df_prediction(ranges_test_SO, min_farsightness, farsightness, delta_features, step_target)\n",
    "df_train_prediction = pd.concat([df_train_prediction_PO, df_train_prediction_SO])\n",
    "\n",
    "df_unseen_prediction = df_test_prediction.loc[df_test_prediction.index.get_level_values('Date')>capped_last_date]\n",
    "df_test_prediction = df_test_prediction.loc[df_test_prediction.index.get_level_values('Date')<=capped_last_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES: ['Handover_MA', 'Download vol._MA', 'Upload vol._MA', '#Users_MA', 'R_mean', 'Handover_MA_1', 'Download vol._MA_1', 'Upload vol._MA_1', '#Users_MA_1', 'R_mean_1', 'Handover_MA_2', 'Download vol._MA_2', 'Upload vol._MA_2', '#Users_MA_2', 'R_mean_2', 'Handover_MA_3', 'Download vol._MA_3', 'Upload vol._MA_3', '#Users_MA_3', 'R_mean_3', 'Handover_MA_4', 'Download vol._MA_4', 'Upload vol._MA_4', '#Users_MA_4', 'R_mean_4', 'Handover_MA_5', 'Download vol._MA_5', 'Upload vol._MA_5', '#Users_MA_5', 'R_mean_5', 'Handover_MA_6', 'Download vol._MA_6', 'Upload vol._MA_6', '#Users_MA_6', 'R_mean_6', 'Handover_MA_7', 'Download vol._MA_7', 'Upload vol._MA_7', '#Users_MA_7', 'R_mean_7'], TARGETS: ['target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9', 'target_10', 'target_11', 'target_12', 'target_13', 'target_14', 'target_15', 'target_16', 'target_17', 'target_18', 'target_19', 'target_20', 'target_21', 'target_22', 'target_23', 'target_24', 'target_25', 'target_26', 'target_27', 'target_28', 'target_29', 'target_30', 'target_31', 'target_32', 'target_33', 'target_34']\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'reg:squarederror'}\n",
    "\n",
    "is_xgb = False\n",
    "is_polynomial = False\n",
    "is_lstm = True\n",
    "\n",
    "features_without_lag = trafficKPIs+covidKPIs+temperatureKPIs\n",
    "num_features_t = len(features_without_lag)\n",
    "n_timesteps = len(lags)+1\n",
    "\n",
    "features = [col for col in df_test_prediction.columns if \"target\" not in col]\n",
    "targets = [col for col in df_test_prediction.columns if \"target\" in col]\n",
    "\n",
    "print(\"FEATURES: {}, TARGETS: {}\".format(features, targets))\n",
    "\n",
    "MAX_EPOCHS = 128\n",
    "\n",
    "def build_mlp(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def build_lstm_1(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def build_lstm_2(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def build_lstm_3(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(1))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def build_lstm_4(n_timesteps, n_features, n_outputs):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_lstm_5(n_timesteps, n_features, n_outputs):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "models_constructors = {\n",
    "    \"EncDecLSTM_DL\": partial(build_lstm_3, n_timesteps, num_features_t)\n",
    "}\n",
    "\n",
    "def build_model(model_name, n_outputs):\n",
    "    return build_lstm_5(n_timesteps, num_features_t, n_outputs)\n",
    "    \n",
    "model_name = [m for m in models_constructors.keys() if \"DL\" in m][0]\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "def train_in_interval(interval):\n",
    "    models_regions = {}\n",
    "    for region in regions_to_train:\n",
    "        df_ts = df_train_prediction.loc[df_train_prediction.index.get_level_values(1)==region]\n",
    "        df_ts = df_ts.reset_index().set_index('Date').drop(columns='Regione')\n",
    "        df_ts = df_ts.loc[(df_ts.index>=interval[0])&(df_ts.index < interval[1])]\n",
    "        \n",
    "        #df_ts_lag = df_ts.copy().drop(columns=[col for col in targets if (col not in features) and (col != target)]).dropna()\n",
    "        model = build_model(model_name, len(targets))\n",
    "        #for model_name in models_constructors.keys():\n",
    "        print(\"{} for {} with lag ({}-{}): {} -> {}\".format(model_name, region, min(lags_target), max(lags_target), min(interval), max(interval)))\n",
    "        \n",
    "        size_int = int(df_ts.shape[0]*0.7)\n",
    "        features_train, features_val = df_ts.iloc[:size_int][features], df_ts.iloc[size_int:][features]\n",
    "        targets_train, targets_val = df_ts.loc[features_train.index, targets].dropna(), df_ts.loc[features_val.index, targets].dropna()\n",
    "        \n",
    "        train_indices = features_train.index.intersection(targets_train.index)\n",
    "        val_indices = features_val.index.intersection(targets_val.index)\n",
    "        \n",
    "        print(\"{}, {}\".format(train_indices.shape, val_indices.shape))\n",
    "        '''\n",
    "        features_train, features_val, targets_train, targets_val = \\\n",
    "            features_train.loc[train_indices], features_val.loc[val_indices], \\\n",
    "            targets_train.loc[train_indices], targets_val.loc[val_indices]\n",
    "        '''\n",
    "        \n",
    "        lstm_input_train = features_train.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "        lstm_input_val = features_val.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "        \n",
    "        print(\"DBG: {} + {}, {} + {}\".format(lstm_input_train.shape, lstm_input_val.shape,targets_train.shape, targets_val.shape))\n",
    "        \n",
    "        model.fit(x=lstm_input_train, y=targets_train, epochs=MAX_EPOCHS,\n",
    "                  validation_data=(lstm_input_val, targets_val),\n",
    "                  callbacks=[early_stopping])\n",
    "        models_regions[region] = model\n",
    "    return models_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncDecLSTM_DL for Trentino-Alto Adige with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(83,), (36,)\n",
      "DBG: (83, 8, 5) + (36, 8, 5), (83, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 3s 232ms/step - loss: 0.9253 - mean_absolute_error: 0.8614 - val_loss: 0.9116 - val_mean_absolute_error: 0.9086\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4662 - mean_absolute_error: 0.5474 - val_loss: 0.3008 - val_mean_absolute_error: 0.4389\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3051 - mean_absolute_error: 0.4479 - val_loss: 0.3416 - val_mean_absolute_error: 0.4807\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1650 - mean_absolute_error: 0.3314 - val_loss: 0.2926 - val_mean_absolute_error: 0.4417\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1615 - mean_absolute_error: 0.3116 - val_loss: 0.1829 - val_mean_absolute_error: 0.3499\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1388 - mean_absolute_error: 0.2861 - val_loss: 0.1788 - val_mean_absolute_error: 0.3491\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1219 - mean_absolute_error: 0.2819 - val_loss: 0.1570 - val_mean_absolute_error: 0.3259\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1214 - mean_absolute_error: 0.2877 - val_loss: 0.1744 - val_mean_absolute_error: 0.3292\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1182 - mean_absolute_error: 0.2712 - val_loss: 0.1643 - val_mean_absolute_error: 0.3199\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1081 - mean_absolute_error: 0.2603 - val_loss: 0.1382 - val_mean_absolute_error: 0.3033\n",
      "Epoch 11/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1079 - mean_absolute_error: 0.2670 - val_loss: 0.1352 - val_mean_absolute_error: 0.2986\n",
      "Epoch 12/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1022 - mean_absolute_error: 0.2533 - val_loss: 0.1379 - val_mean_absolute_error: 0.2968\n",
      "Epoch 13/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1025 - mean_absolute_error: 0.2500 - val_loss: 0.1262 - val_mean_absolute_error: 0.2879\n",
      "Epoch 14/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0970 - mean_absolute_error: 0.2461 - val_loss: 0.1244 - val_mean_absolute_error: 0.2846\n",
      "Epoch 15/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0947 - mean_absolute_error: 0.2458 - val_loss: 0.1453 - val_mean_absolute_error: 0.2971\n",
      "Epoch 16/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0997 - mean_absolute_error: 0.2470 - val_loss: 0.1424 - val_mean_absolute_error: 0.2944\n",
      "Epoch 17/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0922 - mean_absolute_error: 0.2399 - val_loss: 0.1400 - val_mean_absolute_error: 0.2917\n",
      "EncDecLSTM_DL for Puglia with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (36,)\n",
      "DBG: (84, 8, 5) + (36, 8, 5), (84, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 4s 182ms/step - loss: 1.2342 - mean_absolute_error: 1.0228 - val_loss: 1.9875 - val_mean_absolute_error: 1.3617\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.8133 - mean_absolute_error: 0.7453 - val_loss: 1.2966 - val_mean_absolute_error: 1.0737\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3557 - mean_absolute_error: 0.4494 - val_loss: 0.6088 - val_mean_absolute_error: 0.6560\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1931 - mean_absolute_error: 0.3793 - val_loss: 0.4408 - val_mean_absolute_error: 0.5446\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0946 - mean_absolute_error: 0.2290 - val_loss: 0.5273 - val_mean_absolute_error: 0.6154\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1137 - mean_absolute_error: 0.2775 - val_loss: 0.5521 - val_mean_absolute_error: 0.6301\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1180 - mean_absolute_error: 0.2858 - val_loss: 0.4739 - val_mean_absolute_error: 0.5823\n",
      "EncDecLSTM_DL for Emilia-Romagna with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 200ms/step - loss: 0.7289 - mean_absolute_error: 0.8288 - val_loss: 0.8139 - val_mean_absolute_error: 0.8928\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3647 - mean_absolute_error: 0.5353 - val_loss: 0.3818 - val_mean_absolute_error: 0.5867\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1723 - mean_absolute_error: 0.3614 - val_loss: 0.1364 - val_mean_absolute_error: 0.2627\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0606 - mean_absolute_error: 0.1899 - val_loss: 0.1400 - val_mean_absolute_error: 0.2895\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0628 - mean_absolute_error: 0.1903 - val_loss: 0.0971 - val_mean_absolute_error: 0.2047\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0514 - mean_absolute_error: 0.1810 - val_loss: 0.0869 - val_mean_absolute_error: 0.1919\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0379 - mean_absolute_error: 0.1413 - val_loss: 0.0803 - val_mean_absolute_error: 0.1898\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0363 - mean_absolute_error: 0.1419 - val_loss: 0.0909 - val_mean_absolute_error: 0.2296\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0335 - mean_absolute_error: 0.1341 - val_loss: 0.0592 - val_mean_absolute_error: 0.1509\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0288 - mean_absolute_error: 0.1260 - val_loss: 0.0522 - val_mean_absolute_error: 0.1376\n",
      "Epoch 11/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0280 - mean_absolute_error: 0.1260 - val_loss: 0.0565 - val_mean_absolute_error: 0.1578\n",
      "Epoch 12/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0256 - mean_absolute_error: 0.1225 - val_loss: 0.0560 - val_mean_absolute_error: 0.1615\n",
      "Epoch 13/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0239 - mean_absolute_error: 0.1141 - val_loss: 0.0673 - val_mean_absolute_error: 0.1962\n",
      "EncDecLSTM_DL for Veneto with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 190ms/step - loss: 0.8156 - mean_absolute_error: 0.8445 - val_loss: 1.0118 - val_mean_absolute_error: 0.9645\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4350 - mean_absolute_error: 0.5391 - val_loss: 0.3345 - val_mean_absolute_error: 0.4857\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2426 - mean_absolute_error: 0.4239 - val_loss: 0.3617 - val_mean_absolute_error: 0.4835\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1000 - mean_absolute_error: 0.2431 - val_loss: 0.6263 - val_mean_absolute_error: 0.6431\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0834 - mean_absolute_error: 0.2109 - val_loss: 0.2486 - val_mean_absolute_error: 0.4106\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0595 - mean_absolute_error: 0.1856 - val_loss: 0.1668 - val_mean_absolute_error: 0.3269\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0445 - mean_absolute_error: 0.1643 - val_loss: 0.1624 - val_mean_absolute_error: 0.3133\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0484 - mean_absolute_error: 0.1790 - val_loss: 0.1974 - val_mean_absolute_error: 0.3478\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0441 - mean_absolute_error: 0.1631 - val_loss: 0.1734 - val_mean_absolute_error: 0.3205\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0401 - mean_absolute_error: 0.1529 - val_loss: 0.1301 - val_mean_absolute_error: 0.2753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0373 - mean_absolute_error: 0.1478 - val_loss: 0.1342 - val_mean_absolute_error: 0.2757\n",
      "Epoch 12/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0357 - mean_absolute_error: 0.1397 - val_loss: 0.1373 - val_mean_absolute_error: 0.2779\n",
      "Epoch 13/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0350 - mean_absolute_error: 0.1397 - val_loss: 0.1174 - val_mean_absolute_error: 0.2569\n",
      "Epoch 14/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0337 - mean_absolute_error: 0.1392 - val_loss: 0.1287 - val_mean_absolute_error: 0.2686\n",
      "Epoch 15/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0310 - mean_absolute_error: 0.1306 - val_loss: 0.1293 - val_mean_absolute_error: 0.2691\n",
      "Epoch 16/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0307 - mean_absolute_error: 0.1314 - val_loss: 0.1168 - val_mean_absolute_error: 0.2555\n",
      "Epoch 17/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0285 - mean_absolute_error: 0.1275 - val_loss: 0.1286 - val_mean_absolute_error: 0.2674\n",
      "Epoch 18/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0292 - mean_absolute_error: 0.1275 - val_loss: 0.1301 - val_mean_absolute_error: 0.2690\n",
      "Epoch 19/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0272 - mean_absolute_error: 0.1215 - val_loss: 0.1229 - val_mean_absolute_error: 0.2606\n",
      "EncDecLSTM_DL for Lombardia with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 203ms/step - loss: 0.8027 - mean_absolute_error: 0.8893 - val_loss: 0.7217 - val_mean_absolute_error: 0.8335\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4689 - mean_absolute_error: 0.6714 - val_loss: 0.5028 - val_mean_absolute_error: 0.6858\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1875 - mean_absolute_error: 0.3687 - val_loss: 0.2175 - val_mean_absolute_error: 0.4063\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1590 - mean_absolute_error: 0.3319 - val_loss: 0.0955 - val_mean_absolute_error: 0.2260\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0497 - mean_absolute_error: 0.1632 - val_loss: 0.0957 - val_mean_absolute_error: 0.2417\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0638 - mean_absolute_error: 0.2018 - val_loss: 0.0748 - val_mean_absolute_error: 0.2021\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0483 - mean_absolute_error: 0.1668 - val_loss: 0.0756 - val_mean_absolute_error: 0.2080\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0355 - mean_absolute_error: 0.1331 - val_loss: 0.0907 - val_mean_absolute_error: 0.2386\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0331 - mean_absolute_error: 0.1358 - val_loss: 0.1157 - val_mean_absolute_error: 0.2787\n",
      "EncDecLSTM_DL for Abruzzo with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(83,), (36,)\n",
      "DBG: (83, 8, 5) + (36, 8, 5), (83, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 185ms/step - loss: 1.0944 - mean_absolute_error: 0.9908 - val_loss: 1.5312 - val_mean_absolute_error: 1.1733\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7718 - mean_absolute_error: 0.7795 - val_loss: 0.8932 - val_mean_absolute_error: 0.8456\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3281 - mean_absolute_error: 0.4617 - val_loss: 0.3941 - val_mean_absolute_error: 0.4666\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1489 - mean_absolute_error: 0.3058 - val_loss: 0.3421 - val_mean_absolute_error: 0.4339\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1157 - mean_absolute_error: 0.2569 - val_loss: 0.3012 - val_mean_absolute_error: 0.3893\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1242 - mean_absolute_error: 0.2810 - val_loss: 0.2759 - val_mean_absolute_error: 0.3727\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1031 - mean_absolute_error: 0.2518 - val_loss: 0.2659 - val_mean_absolute_error: 0.3622\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0872 - mean_absolute_error: 0.2235 - val_loss: 0.2920 - val_mean_absolute_error: 0.3825\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0823 - mean_absolute_error: 0.2021 - val_loss: 0.2906 - val_mean_absolute_error: 0.3825\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0807 - mean_absolute_error: 0.1988 - val_loss: 0.2780 - val_mean_absolute_error: 0.3722\n",
      "EncDecLSTM_DL for Molise with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(83,), (36,)\n",
      "DBG: (83, 8, 5) + (36, 8, 5), (83, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 214ms/step - loss: 2.8785 - mean_absolute_error: 1.4870 - val_loss: 3.1866 - val_mean_absolute_error: 1.6059\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.7785 - mean_absolute_error: 1.0673 - val_loss: 1.2113 - val_mean_absolute_error: 0.8666\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.1940 - mean_absolute_error: 0.9295 - val_loss: 0.7951 - val_mean_absolute_error: 0.6708\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8516 - mean_absolute_error: 0.7512 - val_loss: 1.1458 - val_mean_absolute_error: 0.8376\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8419 - mean_absolute_error: 0.7087 - val_loss: 1.0120 - val_mean_absolute_error: 0.7765\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6909 - mean_absolute_error: 0.6446 - val_loss: 0.6780 - val_mean_absolute_error: 0.6265\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6032 - mean_absolute_error: 0.5883 - val_loss: 0.6479 - val_mean_absolute_error: 0.6166\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5940 - mean_absolute_error: 0.5916 - val_loss: 0.9024 - val_mean_absolute_error: 0.7267\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5288 - mean_absolute_error: 0.5570 - val_loss: 1.0071 - val_mean_absolute_error: 0.7728\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5249 - mean_absolute_error: 0.5583 - val_loss: 0.9231 - val_mean_absolute_error: 0.7349\n",
      "EncDecLSTM_DL for Sicilia with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 200ms/step - loss: 1.3091 - mean_absolute_error: 1.0595 - val_loss: 1.6019 - val_mean_absolute_error: 1.2386\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7121 - mean_absolute_error: 0.6941 - val_loss: 0.8886 - val_mean_absolute_error: 0.9033\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4644 - mean_absolute_error: 0.5839 - val_loss: 0.4445 - val_mean_absolute_error: 0.5770\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1821 - mean_absolute_error: 0.3420 - val_loss: 0.2521 - val_mean_absolute_error: 0.3953\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1351 - mean_absolute_error: 0.2675 - val_loss: 0.2384 - val_mean_absolute_error: 0.3890\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1342 - mean_absolute_error: 0.2842 - val_loss: 0.2538 - val_mean_absolute_error: 0.3946\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1207 - mean_absolute_error: 0.2727 - val_loss: 0.2338 - val_mean_absolute_error: 0.3791\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0961 - mean_absolute_error: 0.2354 - val_loss: 0.2220 - val_mean_absolute_error: 0.3713\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0973 - mean_absolute_error: 0.2446 - val_loss: 0.2591 - val_mean_absolute_error: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0884 - mean_absolute_error: 0.2302 - val_loss: 0.2897 - val_mean_absolute_error: 0.4545\n",
      "Epoch 11/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0855 - mean_absolute_error: 0.2216 - val_loss: 0.2470 - val_mean_absolute_error: 0.4105\n",
      "EncDecLSTM_DL for Valle d'Aosta with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(81,), (36,)\n",
      "DBG: (81, 8, 5) + (36, 8, 5), (81, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 202ms/step - loss: 2.2505 - mean_absolute_error: 1.3681 - val_loss: 4.0042 - val_mean_absolute_error: 1.8198\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.6754 - mean_absolute_error: 1.1109 - val_loss: 2.7625 - val_mean_absolute_error: 1.4407\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.9317 - mean_absolute_error: 0.7714 - val_loss: 1.1514 - val_mean_absolute_error: 0.9511\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5372 - mean_absolute_error: 0.6059 - val_loss: 22.9080 - val_mean_absolute_error: 3.2067\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4487 - mean_absolute_error: 0.4603 - val_loss: 1.5462 - val_mean_absolute_error: 0.9769\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.3302 - mean_absolute_error: 0.4717 - val_loss: 1.0823 - val_mean_absolute_error: 0.8777\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2450 - mean_absolute_error: 0.4016 - val_loss: 1.1308 - val_mean_absolute_error: 0.8363\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1576 - mean_absolute_error: 0.3070 - val_loss: 1.6009 - val_mean_absolute_error: 1.0118\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1878 - mean_absolute_error: 0.3572 - val_loss: 1.1628 - val_mean_absolute_error: 0.8468\n",
      "EncDecLSTM_DL for Calabria with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(81,), (36,)\n",
      "DBG: (81, 8, 5) + (36, 8, 5), (81, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 212ms/step - loss: 3.0233 - mean_absolute_error: 1.5459 - val_loss: 1.8698 - val_mean_absolute_error: 1.2093\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 2.1605 - mean_absolute_error: 1.2231 - val_loss: 1.1052 - val_mean_absolute_error: 0.8200\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.0577 - mean_absolute_error: 0.7671 - val_loss: 0.8733 - val_mean_absolute_error: 0.7002\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7007 - mean_absolute_error: 0.6430 - val_loss: 0.9036 - val_mean_absolute_error: 0.7097\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8446 - mean_absolute_error: 0.6702 - val_loss: 0.9107 - val_mean_absolute_error: 0.7115\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.8537 - mean_absolute_error: 0.6740 - val_loss: 0.8189 - val_mean_absolute_error: 0.6623\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6515 - mean_absolute_error: 0.5770 - val_loss: 0.7094 - val_mean_absolute_error: 0.6130\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5249 - mean_absolute_error: 0.5461 - val_loss: 0.7292 - val_mean_absolute_error: 0.6398\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5457 - mean_absolute_error: 0.6003 - val_loss: 0.7267 - val_mean_absolute_error: 0.6451\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4777 - mean_absolute_error: 0.5402 - val_loss: 0.6577 - val_mean_absolute_error: 0.5976\n",
      "Epoch 11/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4568 - mean_absolute_error: 0.5060 - val_loss: 0.6425 - val_mean_absolute_error: 0.5799\n",
      "Epoch 12/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4692 - mean_absolute_error: 0.5165 - val_loss: 0.6330 - val_mean_absolute_error: 0.5765\n",
      "Epoch 13/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4540 - mean_absolute_error: 0.5122 - val_loss: 0.6278 - val_mean_absolute_error: 0.5838\n",
      "Epoch 14/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4258 - mean_absolute_error: 0.4958 - val_loss: 0.6306 - val_mean_absolute_error: 0.5943\n",
      "Epoch 15/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4188 - mean_absolute_error: 0.4898 - val_loss: 0.6214 - val_mean_absolute_error: 0.5886\n",
      "Epoch 16/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4184 - mean_absolute_error: 0.4884 - val_loss: 0.6032 - val_mean_absolute_error: 0.5667\n",
      "Epoch 17/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3723 - mean_absolute_error: 0.4653 - val_loss: 0.5974 - val_mean_absolute_error: 0.5540\n",
      "Epoch 18/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3777 - mean_absolute_error: 0.4652 - val_loss: 0.5938 - val_mean_absolute_error: 0.5486\n",
      "Epoch 19/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3914 - mean_absolute_error: 0.4782 - val_loss: 0.5865 - val_mean_absolute_error: 0.5457\n",
      "Epoch 20/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3293 - mean_absolute_error: 0.4317 - val_loss: 0.5818 - val_mean_absolute_error: 0.5415\n",
      "Epoch 21/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3433 - mean_absolute_error: 0.4438 - val_loss: 0.5800 - val_mean_absolute_error: 0.5372\n",
      "Epoch 22/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3594 - mean_absolute_error: 0.4547 - val_loss: 0.5819 - val_mean_absolute_error: 0.5351\n",
      "Epoch 23/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3357 - mean_absolute_error: 0.4431 - val_loss: 0.5782 - val_mean_absolute_error: 0.5312\n",
      "Epoch 24/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3340 - mean_absolute_error: 0.4438 - val_loss: 0.5671 - val_mean_absolute_error: 0.5241\n",
      "Epoch 25/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3131 - mean_absolute_error: 0.4288 - val_loss: 0.5713 - val_mean_absolute_error: 0.5213\n",
      "Epoch 26/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2746 - mean_absolute_error: 0.4054 - val_loss: 0.5676 - val_mean_absolute_error: 0.5136\n",
      "Epoch 27/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2631 - mean_absolute_error: 0.3913 - val_loss: 0.5767 - val_mean_absolute_error: 0.5128\n",
      "EncDecLSTM_DL for Liguria with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(83,), (36,)\n",
      "DBG: (83, 8, 5) + (36, 8, 5), (83, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 3s 513ms/step - loss: 0.6889 - mean_absolute_error: 0.8152 - val_loss: 0.9190 - val_mean_absolute_error: 0.9258\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3190 - mean_absolute_error: 0.5123 - val_loss: 0.3892 - val_mean_absolute_error: 0.5490\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1676 - mean_absolute_error: 0.3482 - val_loss: 0.2484 - val_mean_absolute_error: 0.4199\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0696 - mean_absolute_error: 0.2084 - val_loss: 0.1866 - val_mean_absolute_error: 0.3741\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0556 - mean_absolute_error: 0.1764 - val_loss: 0.1696 - val_mean_absolute_error: 0.3549\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0610 - mean_absolute_error: 0.1939 - val_loss: 0.1838 - val_mean_absolute_error: 0.3613\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0508 - mean_absolute_error: 0.1724 - val_loss: 0.1809 - val_mean_absolute_error: 0.3525\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0401 - mean_absolute_error: 0.1559 - val_loss: 0.1664 - val_mean_absolute_error: 0.3352\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0426 - mean_absolute_error: 0.1607 - val_loss: 0.1873 - val_mean_absolute_error: 0.3546\n",
      "Epoch 10/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0388 - mean_absolute_error: 0.1533 - val_loss: 0.1994 - val_mean_absolute_error: 0.3666\n",
      "Epoch 11/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0369 - mean_absolute_error: 0.1488 - val_loss: 0.1676 - val_mean_absolute_error: 0.3336\n",
      "EncDecLSTM_DL for Friuli Venezia Giulia with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 205ms/step - loss: 1.0707 - mean_absolute_error: 0.9750 - val_loss: 1.4810 - val_mean_absolute_error: 1.1672\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5325 - mean_absolute_error: 0.6003 - val_loss: 0.6832 - val_mean_absolute_error: 0.7168\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4166 - mean_absolute_error: 0.5417 - val_loss: 0.3666 - val_mean_absolute_error: 0.4434\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1842 - mean_absolute_error: 0.3276 - val_loss: 0.3533 - val_mean_absolute_error: 0.4805\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1184 - mean_absolute_error: 0.2459 - val_loss: 0.6289 - val_mean_absolute_error: 0.6953\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1126 - mean_absolute_error: 0.2397 - val_loss: 0.2373 - val_mean_absolute_error: 0.3664\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0767 - mean_absolute_error: 0.2115 - val_loss: 0.2454 - val_mean_absolute_error: 0.3401\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0753 - mean_absolute_error: 0.2028 - val_loss: 0.2490 - val_mean_absolute_error: 0.3560\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0701 - mean_absolute_error: 0.1992 - val_loss: 0.2483 - val_mean_absolute_error: 0.3615\n",
      "EncDecLSTM_DL for Campania with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 204ms/step - loss: 0.9641 - mean_absolute_error: 0.9085 - val_loss: 1.2653 - val_mean_absolute_error: 1.0631\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5601 - mean_absolute_error: 0.6057 - val_loss: 0.7408 - val_mean_absolute_error: 0.7605\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.3525 - mean_absolute_error: 0.4965 - val_loss: 0.4688 - val_mean_absolute_error: 0.5320\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1360 - mean_absolute_error: 0.2630 - val_loss: 0.2998 - val_mean_absolute_error: 0.3804\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1285 - mean_absolute_error: 0.2676 - val_loss: 0.2588 - val_mean_absolute_error: 0.3626\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1259 - mean_absolute_error: 0.2844 - val_loss: 0.2665 - val_mean_absolute_error: 0.3576\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1147 - mean_absolute_error: 0.2619 - val_loss: 0.2667 - val_mean_absolute_error: 0.3604\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1038 - mean_absolute_error: 0.2330 - val_loss: 0.2766 - val_mean_absolute_error: 0.3732\n",
      "EncDecLSTM_DL for Marche with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 224ms/step - loss: 1.0252 - mean_absolute_error: 0.9484 - val_loss: 1.5333 - val_mean_absolute_error: 1.1842\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5859 - mean_absolute_error: 0.6340 - val_loss: 1.0024 - val_mean_absolute_error: 0.9300\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4424 - mean_absolute_error: 0.5700 - val_loss: 0.6254 - val_mean_absolute_error: 0.6895\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.2277 - mean_absolute_error: 0.3801 - val_loss: 0.3084 - val_mean_absolute_error: 0.4010\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1221 - mean_absolute_error: 0.2493 - val_loss: 0.4205 - val_mean_absolute_error: 0.5251\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1745 - mean_absolute_error: 0.2755 - val_loss: 0.2400 - val_mean_absolute_error: 0.3511\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1052 - mean_absolute_error: 0.2446 - val_loss: 0.3014 - val_mean_absolute_error: 0.3947\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0927 - mean_absolute_error: 0.2272 - val_loss: 0.3119 - val_mean_absolute_error: 0.4050\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0845 - mean_absolute_error: 0.2267 - val_loss: 0.3032 - val_mean_absolute_error: 0.3974\n",
      "EncDecLSTM_DL for Basilicata with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(77,), (34,)\n",
      "DBG: (77, 8, 5) + (34, 8, 5), (77, 34) + (34, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 221ms/step - loss: 3.8514 - mean_absolute_error: 1.8028 - val_loss: 3.8778 - val_mean_absolute_error: 1.7121\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.6808 - mean_absolute_error: 1.4161 - val_loss: 2.1103 - val_mean_absolute_error: 1.1855\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.2989 - mean_absolute_error: 0.9682 - val_loss: 1.7449 - val_mean_absolute_error: 1.0240\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7202 - mean_absolute_error: 0.6539 - val_loss: 1.1187 - val_mean_absolute_error: 0.7911\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5310 - mean_absolute_error: 0.5628 - val_loss: 1.0301 - val_mean_absolute_error: 0.7500\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3555 - mean_absolute_error: 0.4501 - val_loss: 0.9656 - val_mean_absolute_error: 0.7301\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3320 - mean_absolute_error: 0.4312 - val_loss: 1.0924 - val_mean_absolute_error: 0.7580\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2884 - mean_absolute_error: 0.4104 - val_loss: 1.0982 - val_mean_absolute_error: 0.7597\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2578 - mean_absolute_error: 0.3756 - val_loss: 1.0044 - val_mean_absolute_error: 0.7154\n",
      "EncDecLSTM_DL for Sardegna with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(82,), (36,)\n",
      "DBG: (82, 8, 5) + (36, 8, 5), (82, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 198ms/step - loss: 2.1890 - mean_absolute_error: 1.3491 - val_loss: 1.5412 - val_mean_absolute_error: 1.2057\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.1590 - mean_absolute_error: 0.8980 - val_loss: 0.4130 - val_mean_absolute_error: 0.5577\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4592 - mean_absolute_error: 0.5300 - val_loss: 0.3067 - val_mean_absolute_error: 0.4479\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4251 - mean_absolute_error: 0.5374 - val_loss: 0.5479 - val_mean_absolute_error: 0.6661\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2932 - mean_absolute_error: 0.3729 - val_loss: 0.6715 - val_mean_absolute_error: 0.7538\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.2674 - mean_absolute_error: 0.3480 - val_loss: 0.5908 - val_mean_absolute_error: 0.6917\n",
      "EncDecLSTM_DL for Lazio with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (36,)\n",
      "DBG: (84, 8, 5) + (36, 8, 5), (84, 34) + (36, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 231ms/step - loss: 0.7784 - mean_absolute_error: 0.8560 - val_loss: 0.8199 - val_mean_absolute_error: 0.8890\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3268 - mean_absolute_error: 0.5040 - val_loss: 0.3341 - val_mean_absolute_error: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.2024 - mean_absolute_error: 0.3807 - val_loss: 0.1459 - val_mean_absolute_error: 0.2738\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0916 - mean_absolute_error: 0.2439 - val_loss: 0.1216 - val_mean_absolute_error: 0.2655\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0767 - mean_absolute_error: 0.2043 - val_loss: 0.1513 - val_mean_absolute_error: 0.3129\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0824 - mean_absolute_error: 0.2262 - val_loss: 0.1081 - val_mean_absolute_error: 0.2537\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0707 - mean_absolute_error: 0.2005 - val_loss: 0.0864 - val_mean_absolute_error: 0.2115\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0592 - mean_absolute_error: 0.1772 - val_loss: 0.0896 - val_mean_absolute_error: 0.2182\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0542 - mean_absolute_error: 0.1715 - val_loss: 0.1055 - val_mean_absolute_error: 0.2579\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0527 - mean_absolute_error: 0.1666 - val_loss: 0.0915 - val_mean_absolute_error: 0.2359\n",
      "EncDecLSTM_DL for Umbria with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 221ms/step - loss: 2.5284 - mean_absolute_error: 1.4357 - val_loss: 2.0285 - val_mean_absolute_error: 1.3438\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.7791 - mean_absolute_error: 1.1318 - val_loss: 1.1746 - val_mean_absolute_error: 0.9800\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1111 - mean_absolute_error: 0.8593 - val_loss: 0.5436 - val_mean_absolute_error: 0.5684\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6972 - mean_absolute_error: 0.6824 - val_loss: 0.3736 - val_mean_absolute_error: 0.4393\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4999 - mean_absolute_error: 0.5260 - val_loss: 0.6038 - val_mean_absolute_error: 0.6058\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4690 - mean_absolute_error: 0.5073 - val_loss: 0.4070 - val_mean_absolute_error: 0.4823\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3723 - mean_absolute_error: 0.4693 - val_loss: 0.2959 - val_mean_absolute_error: 0.3856\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3718 - mean_absolute_error: 0.4610 - val_loss: 0.2931 - val_mean_absolute_error: 0.3861\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3212 - mean_absolute_error: 0.4359 - val_loss: 0.2713 - val_mean_absolute_error: 0.3698\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3172 - mean_absolute_error: 0.4490 - val_loss: 0.2685 - val_mean_absolute_error: 0.3694\n",
      "Epoch 11/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2755 - mean_absolute_error: 0.4134 - val_loss: 0.2895 - val_mean_absolute_error: 0.3916\n",
      "Epoch 12/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.2915 - mean_absolute_error: 0.4135 - val_loss: 0.2698 - val_mean_absolute_error: 0.3756\n",
      "Epoch 13/128\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.2894 - mean_absolute_error: 0.4114 - val_loss: 0.2228 - val_mean_absolute_error: 0.3358\n",
      "Epoch 14/128\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2652 - mean_absolute_error: 0.4131 - val_loss: 0.2130 - val_mean_absolute_error: 0.3318\n",
      "Epoch 15/128\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.2545 - mean_absolute_error: 0.4103 - val_loss: 0.2052 - val_mean_absolute_error: 0.3232\n",
      "Epoch 16/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2385 - mean_absolute_error: 0.3873 - val_loss: 0.2286 - val_mean_absolute_error: 0.3461\n",
      "Epoch 17/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2375 - mean_absolute_error: 0.3832 - val_loss: 0.2108 - val_mean_absolute_error: 0.3317\n",
      "Epoch 18/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2197 - mean_absolute_error: 0.3768 - val_loss: 0.1852 - val_mean_absolute_error: 0.3103\n",
      "Epoch 19/128\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.2025 - mean_absolute_error: 0.3681 - val_loss: 0.2055 - val_mean_absolute_error: 0.3294\n",
      "Epoch 20/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2012 - mean_absolute_error: 0.3599 - val_loss: 0.1837 - val_mean_absolute_error: 0.3103\n",
      "Epoch 21/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1938 - mean_absolute_error: 0.3568 - val_loss: 0.1963 - val_mean_absolute_error: 0.3247\n",
      "Epoch 22/128\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1961 - mean_absolute_error: 0.3573 - val_loss: 0.1805 - val_mean_absolute_error: 0.3122\n",
      "Epoch 23/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1868 - mean_absolute_error: 0.3492 - val_loss: 0.1781 - val_mean_absolute_error: 0.3132\n",
      "Epoch 24/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1831 - mean_absolute_error: 0.3470 - val_loss: 0.1761 - val_mean_absolute_error: 0.3144\n",
      "Epoch 25/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1851 - mean_absolute_error: 0.3479 - val_loss: 0.1719 - val_mean_absolute_error: 0.3132\n",
      "Epoch 26/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1799 - mean_absolute_error: 0.3443 - val_loss: 0.1753 - val_mean_absolute_error: 0.3168\n",
      "Epoch 27/128\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1746 - mean_absolute_error: 0.3365 - val_loss: 0.1744 - val_mean_absolute_error: 0.3158\n",
      "Epoch 28/128\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1803 - mean_absolute_error: 0.3419 - val_loss: 0.1569 - val_mean_absolute_error: 0.3021\n",
      "Epoch 29/128\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1658 - mean_absolute_error: 0.3292 - val_loss: 0.1844 - val_mean_absolute_error: 0.3263\n",
      "Epoch 30/128\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1726 - mean_absolute_error: 0.3331 - val_loss: 0.1458 - val_mean_absolute_error: 0.2911\n",
      "Epoch 31/128\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1701 - mean_absolute_error: 0.3313 - val_loss: 0.1596 - val_mean_absolute_error: 0.3060\n",
      "Epoch 32/128\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1578 - mean_absolute_error: 0.3177 - val_loss: 0.2078 - val_mean_absolute_error: 0.3472\n",
      "Epoch 33/128\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1498 - mean_absolute_error: 0.3058 - val_loss: 0.2522 - val_mean_absolute_error: 0.3895\n",
      "EncDecLSTM_DL for Piemonte with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 204ms/step - loss: 0.5885 - mean_absolute_error: 0.7454 - val_loss: 0.7494 - val_mean_absolute_error: 0.8273\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2265 - mean_absolute_error: 0.4025 - val_loss: 0.3509 - val_mean_absolute_error: 0.5177\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1483 - mean_absolute_error: 0.3255 - val_loss: 0.1965 - val_mean_absolute_error: 0.3567\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0533 - mean_absolute_error: 0.1723 - val_loss: 0.4778 - val_mean_absolute_error: 0.5035\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0712 - mean_absolute_error: 0.2014 - val_loss: 0.2175 - val_mean_absolute_error: 0.3637\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0513 - mean_absolute_error: 0.1713 - val_loss: 0.1616 - val_mean_absolute_error: 0.3216\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0401 - mean_absolute_error: 0.1443 - val_loss: 0.1745 - val_mean_absolute_error: 0.3308\n",
      "Epoch 8/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0447 - mean_absolute_error: 0.1604 - val_loss: 0.1861 - val_mean_absolute_error: 0.3432\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0389 - mean_absolute_error: 0.1457 - val_loss: 0.1720 - val_mean_absolute_error: 0.3251\n",
      "EncDecLSTM_DL for Toscana with lag (1-34): 2020-03-01 00:00:00 -> 2020-10-25 00:00:00\n",
      "(84,), (37,)\n",
      "DBG: (84, 8, 5) + (37, 8, 5), (84, 34) + (37, 34)\n",
      "Epoch 1/128\n",
      "3/3 [==============================] - 2s 189ms/step - loss: 0.8735 - mean_absolute_error: 0.8995 - val_loss: 1.0139 - val_mean_absolute_error: 0.9822\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5024 - mean_absolute_error: 0.6262 - val_loss: 0.6418 - val_mean_absolute_error: 0.7600\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.3220 - mean_absolute_error: 0.4653 - val_loss: 0.3530 - val_mean_absolute_error: 0.5279\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.2133 - mean_absolute_error: 0.3815 - val_loss: 0.1772 - val_mean_absolute_error: 0.3349\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0931 - mean_absolute_error: 0.2339 - val_loss: 0.2260 - val_mean_absolute_error: 0.3769\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0881 - mean_absolute_error: 0.2225 - val_loss: 0.1388 - val_mean_absolute_error: 0.2924\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0628 - mean_absolute_error: 0.1909 - val_loss: 0.1351 - val_mean_absolute_error: 0.2877\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0568 - mean_absolute_error: 0.1803 - val_loss: 0.1367 - val_mean_absolute_error: 0.2922\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0527 - mean_absolute_error: 0.1814 - val_loss: 0.1407 - val_mean_absolute_error: 0.2991\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0502 - mean_absolute_error: 0.1770 - val_loss: 0.1378 - val_mean_absolute_error: 0.2967\n"
     ]
    }
   ],
   "source": [
    "do_train = True\n",
    "\n",
    "if do_train:\n",
    "    models_regions = train_in_interval((start_train_po, end_train_so))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST START\n",
      "EncDecLSTM_DL for Trentino-Alto Adige with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Puglia with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Emilia-Romagna with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Veneto with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Lombardia with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Abruzzo with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Molise with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Sicilia with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Valle d'Aosta with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Calabria with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Liguria with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Friuli Venezia Giulia with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Campania with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Marche with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Basilicata with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Sardegna with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Lazio with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Umbria with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Piemonte with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n",
      "EncDecLSTM_DL for Toscana with lag = (1-34): 2020-10-26 00:00:00 -> 2021-01-14 00:00:00, (81, 74)\n"
     ]
    }
   ],
   "source": [
    "train_dates_region_every_n = {}\n",
    "test_dates_region_every_n = {}\n",
    "train_dates_region = {}\n",
    "test_dates_region = {}\n",
    "df_ts_test_region = {}\n",
    "\n",
    "# TODO aggiungere validation o no???\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "def test_in_interval(interval):\n",
    "    print(\"TEST START\")\n",
    "                \n",
    "    df_results = pd.DataFrame() # lag, region, prediction, target; index = date\n",
    "    results_dict = []\n",
    "\n",
    "    for region in regions_to_train:\n",
    "        df_ts = df_test_prediction.loc[df_test_prediction.index.get_level_values(1)==region]\n",
    "        df_ts = df_ts.reset_index().set_index('Date').drop(columns='Regione')\n",
    "        df_ts = df_ts.loc[(df_ts.index>=interval[0])&(df_ts.index < interval[1])]\n",
    "        first_date, last_date = df_ts.index.min(), df_ts.index.max()\n",
    "        current_region_values = []\n",
    "        \n",
    "        test_dates_region[region] = pd.date_range(first_date, last_date)\n",
    "        df_ts_test_region[region] = df_ts\n",
    "        test_dates = test_dates_region[region].unique()\n",
    "        assert test_dates_region[region].shape[0]==len(test_dates), \"Something wrong\"\n",
    "        #for idx_lag, lag in enumerate(lags_target):\n",
    "        #    for model_name in models_constructors.keys():\n",
    "        #target_col = targets[idx_lag]\n",
    "        #walk_forward_df = df_train_prediction.copy().drop(columns=[col for col in targets if (col not in features) and (col != target_col)]).dropna()\n",
    "\n",
    "        current_df_train_prediction = df_train_prediction.copy().xs(region, level='Regione')\n",
    "        walk_forward_df = current_df_train_prediction#.drop(columns=[col for col in targets if (col not in features)]).dropna()\n",
    "        \n",
    "        \n",
    "        current_df_ts = df_ts[features+targets].copy().dropna()\n",
    "        test_dates = current_df_ts.index\n",
    "        \n",
    "        # TODO continuare da qui: ...\n",
    "        print(\"{} for {} with lag = ({}-{}): {} -> {}, {}\".format(model_name, region, min(lags_target), max(lags_target), min(test_dates), max(test_dates), current_df_ts.shape))\n",
    "        for i, t in enumerate(test_dates):\n",
    "            current_df_ts = df_ts.loc[t:t+datetime.timedelta(days=0)]\n",
    "            X_test_ts = current_df_ts[features]\n",
    "            \n",
    "            lstm_input = X_test_ts.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "            predictions = models_regions[region].predict(lstm_input).flatten()\n",
    "\n",
    "            X_test_fit, y_test_fit = X_test_ts, current_df_ts[targets].values\n",
    "            \n",
    "            for i, p in enumerate(predictions):\n",
    "                lag = lags_target[i]\n",
    "                target_col = \"target_{}\".format(lag)\n",
    "                target_val = y_test_fit[0, i]\n",
    "                current_result = {\"model\": model_name,\"date\": t + datetime.timedelta(days=lag), \"lag\": lag, \"region\": region, \"prediction\": p, \"target\": target_val}\n",
    "                results_dict.append(current_result)\n",
    "\n",
    "            walk_forward_df = walk_forward_df.append(current_df_ts)\n",
    "            walk_forward_df = walk_forward_df.sort_index()\n",
    "            \n",
    "            window_train = 64\n",
    "            # I keep the last model and update weights using a window (last 30 values)\n",
    "            model = models_regions[region]\n",
    "            lstm_input = walk_forward_df[features].to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "            lstm_input = lstm_input[-1*window_train:]\n",
    "            lstm_target = walk_forward_df[targets].values[-1*window_train:]\n",
    "            model.fit(lstm_input, lstm_target, epochs=10, batch_size=8, verbose=0)\n",
    "            models_regions[region] = model\n",
    "            \n",
    "    df_results = pd.DataFrame(results_dict)\n",
    "    df_results = df_results.dropna()\n",
    "    df_results.set_index(['model', 'date', 'region', 'lag'], inplace=True)\n",
    "    df_results['error']=(df_results['prediction']-df_results['target']).abs()\n",
    "    df_results['error_2'] = df_results['error']**2\n",
    "    return models_regions, df_results\n",
    "\n",
    "min_date, max_date = df_test_prediction.index.get_level_values(0).min(), df_test_prediction.index.get_level_values(0).max()\n",
    "if do_train:\n",
    "    models_regions, df_results = test_in_interval((min_date, max_date))\n",
    "else:\n",
    "    path_results = \"{}predictions/results_v3.csv\".format(saved)\n",
    "    df_results = pd.read_csv(path_results)\n",
    "    df_results['date'] = pd.to_datetime(df_results['date'])\n",
    "    df_results.set_index(['model', 'date', 'region', 'lag'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_results_groupped(df_results, col_prediction = 'prediction', col_error = 'error_2', col_rmse = 'rmse', col_r2 = 'r2', col_mape = 'mape'):\n",
    "    try:\n",
    "        groupped_df = df_results.groupby(level=['model', 'region', 'lag'])\n",
    "    except:\n",
    "        print(\"WARNING: not groupped\")\n",
    "        groupped_df = df_results\n",
    "    df = pd.DataFrame()\n",
    "    df[col_rmse] = np.sqrt(groupped_df[col_error].mean())\n",
    "    df[col_r2]=groupped_df.apply(lambda g: r2_score( g[col_prediction], g['target'] ))\n",
    "    df[col_mape] = groupped_df.apply(lambda g: np.mean(np.abs((g['target'] - g['prediction']) / g['target'])) * 100)\n",
    "    return df[[col_rmse, col_r2, col_mape]]\n",
    "\n",
    "df_results_mean = build_df_results_groupped(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results...\n",
      "Saving RMSE, R2, MAPE...\n",
      "Saving models...\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Trentino-Alto Adige/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Puglia/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Emilia-Romagna/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Veneto/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Lombardia/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Abruzzo/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Molise/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Sicilia/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Valle d'Aosta/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Calabria/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Liguria/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Friuli Venezia Giulia/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Campania/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Marche/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Basilicata/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Sardegna/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Lazio/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Umbria/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Piemonte/assets\n",
      "INFO:tensorflow:Assets written to: /Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/saved/models/results_v5_LSTM_both_models/EncDecLSTM_DL/Toscana/assets\n",
      "Saving datasets...\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "name_current_save = 'results_v5_LSTM_both'\n",
    "# v14: da controllare,  con poly ma dopo aver sistemato la new\n",
    "# v15: senza Rt (poly)\n",
    "# v16: solo Rt (Poly)\n",
    "path_results_to_save = \"{}predictions/{}\".format(saved, name_current_save)\n",
    "path_results_to_save_models = \"{}models/{}\".format(saved, name_current_save)\n",
    "path_results_to_mean_save = \"{}_mean\".format(path_results_to_save)\n",
    "path_results_to_model_save = \"{}_models\".format(path_results_to_save_models)\n",
    "path_results_to_save_train = \"{}_df_train\".format(path_results_to_save)\n",
    "path_results_to_save_test = \"{}_df_test\".format(path_results_to_save)\n",
    "path_results_to_save_unseen = \"{}_df_unseen\".format(path_results_to_save)\n",
    "print(\"Saving results...\")\n",
    "df_results.to_csv(\"{}.csv\".format(path_results_to_save))\n",
    "print(\"Saving RMSE, R2, MAPE...\")\n",
    "df_results_mean.to_csv(\"{}.csv\".format(path_results_to_mean_save))\n",
    "print(\"Saving models...\")\n",
    "for region_name in models_regions.keys():\n",
    "    #for lag in models_regions[model_name][region_name].keys():\n",
    "    current_models_dir = '{}/{}/{}/'.format(path_results_to_model_save, model_name, region_name)\n",
    "    \n",
    "    current_model = models_regions[region_name]\n",
    "    try:\n",
    "        os.makedirs(current_models_dir)\n",
    "    except:\n",
    "        pass\n",
    "    current_model.save(\"{}\".format(current_models_dir))\n",
    "# TODO salvare i dataset train, test, unseen\n",
    "print(\"Saving datasets...\")\n",
    "df_train_prediction.to_csv(\"{}.csv\".format(path_results_to_save_train))\n",
    "df_test_prediction.to_csv(\"{}.csv\".format(path_results_to_save_test))\n",
    "df_unseen_prediction.to_csv(\"{}.csv\".format(path_results_to_save_unseen))\n",
    "\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d9403fded0b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mis_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_poly3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_poly2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"XGBoost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"Poly3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"Poly2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"RandomForest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"EncDecLSTM\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mcurrent_models_regions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_models_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mmodel_per_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_models_regions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-d9403fded0b4>\u001b[0m in \u001b[0;36minit_models_dict\u001b[0;34m(model_dir)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mmodels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mregion_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mmodel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mn_lag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-d9403fded0b4>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mmodels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mregion_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mmodel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mn_lag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'model'"
     ]
    }
   ],
   "source": [
    "to_check = name_current_save\n",
    "model_dir = name_current_save+\"_models\"#'results_v16_ma_poly_after_update_only_covid_models'\n",
    "\n",
    "\n",
    "path_datasets = \"{}predictions/{}\".format(saved, to_check)\n",
    "#path_train = \"{}_df_train\".format(path_datasets)\n",
    "path_test = \"{}_df_test.csv\".format(path_datasets)\n",
    "path_unseen = \"{}_df_unseen.csv\".format(path_datasets)\n",
    "\n",
    "df_test_selected = pd.read_csv(path_test)\n",
    "# TODO altro??\n",
    "df_unseen_selected = pd.read_csv(path_unseen)\n",
    "\n",
    "\n",
    "\n",
    "def init_models_dict(model_dir):\n",
    "    path_results_dir = join(saved, 'models', model_dir)\n",
    "    models = os.listdir(path_results_dir)\n",
    "    models_dict = {}\n",
    "    for model in models:\n",
    "        models_dict[model] = {}\n",
    "        model_path = join(path_results_dir, model)\n",
    "        regions = os.listdir(model_path)\n",
    "        for region in regions:\n",
    "            models_dict[model][region]={}\n",
    "            region_path = join(model_path, region)\n",
    "            model_names = sorted([f for f in os.listdir(region_path) if isfile(join(region_path, f))], key=lambda f: int(f.split(\"_\")[1].split(\".\")[0]))\n",
    "            for model_name in model_names:\n",
    "                n_lag = int(model_name.split(\"_\")[1].split(\".\")[0])\n",
    "                loaded_model = pickle.load(open(join(region_path, model_name), \"rb\" ))\n",
    "                models_dict[model][region][n_lag]=loaded_model\n",
    "    return models_dict\n",
    "\n",
    "# reusing same model for prediction\n",
    "# TODO usare dash per mostrare i 3 casi separati\n",
    "region='Piemonte'\n",
    "model_name = 'XGBoost'\n",
    "is_xgb, is_poly3, is_poly2, is_rf, is_lstm = model_name==\"XGBoost\", model_name==\"Poly3\", model_name==\"Poly2\", model_name==\"RandomForest\", model_name==\"EncDecLSTM\"\n",
    "\n",
    "current_models_regions = init_models_dict(model_dir)\n",
    "model_per_target = current_models_regions[model_name][region]\n",
    "\n",
    "farsightness = max(model_per_target.keys())\n",
    "\n",
    "num_samples_retrain = 120\n",
    "if is_xgb or is_rf:\n",
    "    num_samples_retrain = 120\n",
    "elif is_lstm:\n",
    "    num_samples_retrain = 80\n",
    "    \n",
    "last_date_seen = df_test_selected.index.get_level_values('Date').max()\n",
    "start_date_unseen = df_test_selected+datetime.timedelta(days=1)\n",
    "\n",
    "current_region_df = df_unseen_selected.xs(region, level='Regione')\n",
    "current_region_test_df = df_test_selected.xs(region, level='Regione')\n",
    "\n",
    "current_train, current_unseen = current_region_test_df, current_region_df\n",
    "\n",
    "# take only last num_samples_retrain\n",
    "current_train = current_train.iloc[-num_samples_retrain:]\n",
    "\n",
    "features_train = current_train[features_selected]\n",
    "target_series_train = {int(col.split(\"_\")[1]):current_train[col] for col in current_train.columns if \"target\" in col}\n",
    "features_unseen = current_unseen[features_selected]\n",
    "#target_series_unseen = {int(col.split(\"_\")[0]):current_unseen[col] for col in current_unseen.columns if \"target\" in col}\n",
    "\n",
    "num_features_t = len([col for col in features_selected if not any(char.isdigit() for char in col)])\n",
    "n_timesteps = features_train.shape[1]//num_features_t\n",
    "\n",
    "\n",
    "dates = features_unseen.index\n",
    "num_dates= len(dates)\n",
    "predictions, index_predictions = [], []\n",
    "idx_dates = list(range(0, num_dates, farsightness))\n",
    "dates_to_return = dates[idx_dates]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "steps_ahead = [f for f in model_per_target.keys() if f <= farsightness]\n",
    "\n",
    "n_timesteps = 8\n",
    "num_features_t = len(trafficKPIs)+len(covidKPIs)\n",
    "\n",
    "min_y, max_y = float(\"+inf\"), float(\"-inf\")\n",
    "\n",
    "for idx, idx_d in enumerate(idx_dates):\n",
    "    d = dates[idx_d]\n",
    "    feature_current = features_unseen.loc[d:d]#.to_numpy()\n",
    "    #print(feature_current)\n",
    "    if 'LSTM' in model_name:\n",
    "        feature_current = feature_current.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "    #print(feature_current.index)\n",
    "    for step_ahead in steps_ahead:\n",
    "        current_model = model_per_target[step_ahead]\n",
    "        #print(feature_current.shape)\n",
    "        current_prediction = current_model.predict(feature_current.values)\n",
    "        #print(step_ahead)\n",
    "        if 'LSTM' in model_name:\n",
    "            try:\n",
    "                current_prediction = current_prediction[-1][-1][-1]\n",
    "            except:\n",
    "                current_prediction = current_prediction[-1][-1]\n",
    "            predictions.append(current_prediction)\n",
    "        else:\n",
    "            current_prediction = current_prediction[-1]\n",
    "            predictions.append(current_prediction)\n",
    "        #print(\"{}: {}\".format(step_ahead, current_prediction))\n",
    "        index_predictions.append(d + datetime.timedelta(days=step_ahead))\n",
    "    # TODO retrain!!! Simulate that\n",
    "    if idx < len(idx_dates)-1:\n",
    "        print(\"RETRAIN!!!\")\n",
    "        # I can retrain\n",
    "        next_d = d+datetime.timedelta(days=steps_ahead[-1])\n",
    "        current_train_df = current_region_df.loc[:next_d]\n",
    "        \n",
    "        current_train_df = current_train_df.iloc[-num_samples_retrain:]\n",
    "        current_features_train = current_train_df[features_selected]\n",
    "        \n",
    "        for key in model_per_target.keys():\n",
    "            model = model_per_target[key]\n",
    "            features_at_day_d = current_region_df.loc[:d]\n",
    "            target_series_train = {int(col.split(\"_\")[1]):current_train_df[col] for col in current_train_df.columns if \"target\" in col}\n",
    "            current_features_train, target_series_train[key] = current_features_train.dropna(), target_series_train[key].dropna()\n",
    "            common_idxs = current_features_train.index.intersection(target_series_train[key].index)\n",
    "            current_features_train = current_features_train.loc[common_idxs]\n",
    "            target_series_train[key] = target_series_train[key].loc[common_idxs]\n",
    "            if is_lstm:\n",
    "                \n",
    "                size_int = int(current_features_train.shape[0]*0.7)\n",
    "                current_features_train_1, current_features_train_2 = current_features_train.iloc[:size_int], current_features_train.iloc[size_int:]\n",
    "                current_target_train, current_target_val = target_series_train[key].loc[current_features_train_1.index], target_series_train[key].loc[current_features_train_2.index]\n",
    "                lstm_input_train = current_features_train_1.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "                lstm_input_val = current_features_train_2.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "\n",
    "                history = model.fit(x=lstm_input_train, y=current_target_train, epochs=MAX_EPOCHS, verbose=0,\n",
    "                                  validation_data=(lstm_input_val, current_target_val),\n",
    "                                  callbacks=[early_stopping])\n",
    "                \n",
    "                #callback = EarlyStopping(monitor='loss', patience=3)\n",
    "                #model.fit(lstm_input, target_series_train[key], epochs=100, batch_size=32, verbose=0, callbacks=[callback])\n",
    "            else:\n",
    "                model.fit(current_features_train.values, target_series_train[key])\n",
    "\n",
    "series_predictions = pd.Series(data=predictions, index=index_predictions)\n",
    "series_target = df_unseen_covid.xs(region, level='Regione').loc[start_date_unseen:]['R_mean']\n",
    "\n",
    "\n",
    "min_y = min(series_predictions.min(), series_target.min())\n",
    "max_y = max(series_predictions.max(), series_target.max())\n",
    "\n",
    "for d in [dates[i] for i in idx_dates]:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        line = dict(color=\"black\", width=2, dash='dash'),\n",
    "        marker_size=1,\n",
    "        x=[d, d],\n",
    "        y=[min_y, max_y],\n",
    "        showlegend=False\n",
    "    ))       \n",
    "\n",
    "#series_target.plot()\n",
    "#series_predictions.plot()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "        line = dict(color=\"orange\", width=1),\n",
    "        marker_size=1,\n",
    "        x=series_predictions.index,\n",
    "        y=series_predictions,\n",
    "        showlegend=False\n",
    "    ))  \n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "        line = dict(color=\"red\", width=1),\n",
    "        marker_size=1,\n",
    "        x=series_target.index,\n",
    "        y=series_target,\n",
    "        showlegend=False\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qui si visualizza il corrente\n",
    "region='Lombardia'\n",
    "model_name = 'Poly2'\n",
    "is_xgb, is_poly3, is_poly2, is_rf, is_lstm = model_name==\"XGBoost\", model_name==\"Poly3\", model_name==\"Poly2\", model_name==\"RandomForest\", model_name==\"EncDecLSTM\"\n",
    "\n",
    "num_samples_retrain = 45\n",
    "if is_xgb or is_rf:\n",
    "    num_samples_retrain = 60\n",
    "elif is_lstm:\n",
    "    num_samples_retrain = 80\n",
    "\n",
    "last_date_seen = pd.to_datetime('2021-01-15')\n",
    "start_date_unseen = last_date_seen+datetime.timedelta(days=1)\n",
    "\n",
    "current_region_df = df_test_prediction.xs(region, level='Regione')\n",
    "\n",
    "current_train, current_unseen = current_region_df.loc[:last_date_seen], current_region_df.loc[start_date_unseen:]\n",
    "\n",
    "# take only last num_samples_retrain\n",
    "current_train = current_train.iloc[-num_samples_retrain:]\n",
    "\n",
    "features_train = current_train[features]\n",
    "target_series_train = {int(col.split(\"_\")[1]):current_train[col] for col in current_train.columns if \"target\" in col}\n",
    "features_unseen = current_unseen[features]\n",
    "#target_series_unseen = {int(col.split(\"_\")[0]):current_unseen[col] for col in current_unseen.columns if \"target\" in col}\n",
    "\n",
    "num_features_t = len(trafficKPIs)\n",
    "n_timesteps = features_train.shape[1]//num_features_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', restore_best_weights=True)\n",
    "\n",
    "if is_poly2:\n",
    "    model_per_target = {key: make_pipeline(PolynomialFeatures(2), Ridge()) for key in target_series_train.keys()}\n",
    "elif is_poly3:\n",
    "    model_per_target = {key: make_pipeline(PolynomialFeatures(3), Ridge()) for key in target_series_train.keys()}\n",
    "elif is_rf:\n",
    "    model_per_target = {key: RandomForestRegressor() for key in target_series_train.keys()}\n",
    "elif is_xgb:\n",
    "    model_per_target = {key: XGBRegressor() for key in target_series_train.keys()}\n",
    "elif is_lstm:\n",
    "    model_per_target = {key: build_lstm_3(n_timesteps, num_features_t) for key in target_series_train.keys()}\n",
    "for key in model_per_target.keys():\n",
    "    model = model_per_target[key]\n",
    "    current_features_train = features_train.copy()\n",
    "    current_features_train, target_series_train[key] = current_features_train.dropna(), target_series_train[key].dropna()\n",
    "    current_features_train = current_features_train.loc[target_series_train[key].index]\n",
    "    target_series_train[key] = target_series_train[key].loc[current_features_train.index]\n",
    "    if is_lstm:\n",
    "        size_int = int(current_features_train.shape[0]*0.7)\n",
    "        current_features_train_1, current_features_train_2 = current_features_train.iloc[:size_int], current_features_train.iloc[size_int:]\n",
    "        current_target_train, current_target_val = target_series_train[key].loc[current_features_train_1.index], target_series_train[key].loc[current_features_train_2.index]\n",
    "        lstm_input_train = current_features_train_1.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "        lstm_input_val = current_features_train_2.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "        \n",
    "        model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "                    metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "        \n",
    "        MAX_EPOCHS = 128\n",
    "        \n",
    "        history = model.fit(x=lstm_input_train, y=current_target_train, epochs=MAX_EPOCHS,\n",
    "                          validation_data=(lstm_input_val, current_target_val),\n",
    "                          callbacks=[early_stopping])\n",
    "        \n",
    "    else:\n",
    "        model.fit(current_features_train, target_series_train[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "farsightness = max(model_per_target.keys())\n",
    "\n",
    "dates = features_unseen.index\n",
    "num_dates= len(dates)\n",
    "predictions, index_predictions = [], []\n",
    "idx_dates = list(range(0, num_dates, farsightness))\n",
    "dates_to_return = dates[idx_dates]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "steps_ahead = [f for f in model_per_target.keys() if f <= farsightness]\n",
    "\n",
    "n_timesteps = 8\n",
    "num_features_t = len(trafficKPIs)\n",
    "\n",
    "min_y, max_y = float(\"+inf\"), float(\"-inf\")\n",
    "\n",
    "use_already_trained = True\n",
    "if use_already_trained:\n",
    "    model_per_target = models_regions['Poly1']['Lombardia']\n",
    "\n",
    "for idx, idx_d in enumerate(idx_dates):\n",
    "    d = dates[idx_d]\n",
    "    feature_current = features_unseen.loc[d:d]#.to_numpy()\n",
    "    #print(feature_current)\n",
    "    if 'LSTM' in model_name:\n",
    "        feature_current = feature_current.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "    #print(feature_current.index)\n",
    "    for step_ahead in steps_ahead:\n",
    "        current_model = model_per_target[step_ahead]\n",
    "        #print(feature_current.shape)\n",
    "        current_prediction = current_model.predict(feature_current)\n",
    "        #print(step_ahead)\n",
    "        if 'LSTM' in model_name:\n",
    "            try:\n",
    "                current_prediction = current_prediction[-1][-1][-1]\n",
    "            except:\n",
    "                current_prediction = current_prediction[-1][-1]\n",
    "            predictions.append(current_prediction)\n",
    "        else:\n",
    "            current_prediction = current_prediction[-1]\n",
    "            predictions.append(current_prediction)\n",
    "        #print(\"{}: {}\".format(step_ahead, current_prediction))\n",
    "        index_predictions.append(d + datetime.timedelta(days=step_ahead))\n",
    "    # TODO retrain!!! Simulate that\n",
    "    if idx < len(idx_dates)-1:\n",
    "        print(\"RETRAIN!!!\")\n",
    "        # I can retrain\n",
    "        next_d = d+datetime.timedelta(days=steps_ahead[-1])\n",
    "        current_train_df = current_region_df.loc[:next_d]\n",
    "        \n",
    "        current_train_df = current_train_df.iloc[-num_samples_retrain:]\n",
    "        current_features_train = current_train_df[features]\n",
    "        \n",
    "        for key in model_per_target.keys():\n",
    "            model = model_per_target[key]\n",
    "            features_at_day_d = current_region_df.loc[:d]\n",
    "            target_series_train = {int(col.split(\"_\")[1]):current_train_df[col] for col in current_train_df.columns if \"target\" in col}\n",
    "            current_features_train, target_series_train[key] = current_features_train.dropna(), target_series_train[key].dropna()\n",
    "            current_features_train = current_features_train.loc[target_series_train[key].index]\n",
    "            target_series_train[key] = target_series_train[key].loc[current_features_train.index]\n",
    "            if is_lstm:\n",
    "                \n",
    "                size_int = int(current_features_train.shape[0]*0.7)\n",
    "                current_features_train_1, current_features_train_2 = current_features_train.iloc[:size_int], current_features_train.iloc[size_int:]\n",
    "                current_target_train, current_target_val = target_series_train[key].loc[current_features_train_1.index], target_series_train[key].loc[current_features_train_2.index]\n",
    "                lstm_input_train = current_features_train_1.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "                lstm_input_val = current_features_train_2.to_numpy().reshape(-1, n_timesteps, num_features_t, order='C')\n",
    "\n",
    "                history = model.fit(x=lstm_input_train, y=current_target_train, epochs=MAX_EPOCHS, verbose=0,\n",
    "                                  validation_data=(lstm_input_val, current_target_val),\n",
    "                                  callbacks=[early_stopping])\n",
    "                \n",
    "                #callback = EarlyStopping(monitor='loss', patience=3)\n",
    "                #model.fit(lstm_input, target_series_train[key], epochs=100, batch_size=32, verbose=0, callbacks=[callback])\n",
    "            else:\n",
    "                model.fit(features_train_df, target_series_train[key])     \n",
    "\n",
    "series_predictions = pd.Series(data=predictions, index=index_predictions)\n",
    "series_target = df_covid_predictions.xs(region, level='Regione').loc[start_date_unseen:]['R_mean']\n",
    "\n",
    "\n",
    "min_y = min(series_predictions.min(), series_target.min())\n",
    "max_y = max(series_predictions.max(), series_target.max())\n",
    "\n",
    "for d in [dates[i] for i in idx_dates]:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        line = dict(color=\"black\", width=2, dash='dash'),\n",
    "        marker_size=1,\n",
    "        x=[d, d],\n",
    "        y=[min_y, max_y],\n",
    "        showlegend=False\n",
    "    ))       \n",
    "\n",
    "#series_target.plot()\n",
    "#series_predictions.plot()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "        line = dict(color=\"orange\", width=1),\n",
    "        marker_size=1,\n",
    "        x=series_predictions.index,\n",
    "        y=series_predictions,\n",
    "        showlegend=False\n",
    "    ))  \n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "        line = dict(color=\"red\", width=1),\n",
    "        marker_size=1,\n",
    "        x=series_target.index,\n",
    "        y=series_target,\n",
    "        showlegend=False\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-covid",
   "language": "python",
   "name": "traffic-covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
