{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import gamma, poisson\n",
    "\n",
    "import epyestim\n",
    "import epyestim.covid19 as covid19\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE, r2_score\n",
    "from xgboost import XGBRegressor, DMatrix, train\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "import plotly.express as px\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "\n",
    "to_sum_KPIs = ['totale_casi_giornalieri', 'terapia_intensiva_giornalieri', 'terapia_intensiva', 'nuovi_positivi', 'tamponi_giornalieri']\n",
    "covidKPIsPrecompute = ['%pos']+to_sum_KPIs\n",
    "trafficKPIsPrecompute = ['Handover', 'Download vol.', 'Upload vol.', '#Users']\n",
    "\n",
    "# sums regions such as trento + bolzano\n",
    "def sumRegions(df, dateCol = 'Date', regionCol='Regione', cols = to_sum_KPIs, region1 = \"P.A. Bolzano\", region2 = \"P.A. Trento\", regionNew = \"Trentino-Alto Adige\"):\n",
    "    dfRegion1, dfRegion2 = df.loc[df[regionCol] == region1], df.loc[df[regionCol] == region2]\n",
    "    dfRegion1.set_index(dateCol, inplace=True)\n",
    "    dfRegion2.set_index(dateCol, inplace=True)\n",
    "    newVals = dfRegion1[to_sum_KPIs]+dfRegion2[to_sum_KPIs]\n",
    "    newVals.reset_index(inplace=True)\n",
    "    newVals['Regione'] = regionNew\n",
    "    df = df.loc[(df[regionCol] != region1) & (df[regionCol] != region2)]\n",
    "    return df.append(newVals)\n",
    "\n",
    "# adds italy as cumulative over days\n",
    "def addItalyData(df, cols):\n",
    "    dfTemp = df.resample('D', on='Date').sum().reset_index()\n",
    "    dfTemp['Regione']='Italia'\n",
    "    dfTemp = dfTemp[cols]\n",
    "    return pd.concat([df, dfTemp])\n",
    "\n",
    "def fill_with_areas(dateRange, fig, is_train):\n",
    "    if is_train:\n",
    "        color = 'rgba(255, 0, 0, 0.2)'\n",
    "    else:\n",
    "        color = 'rgba(0, 0, 255, 0.2)'\n",
    "    fig.add_shape(type=\"rect\",\n",
    "        yref=\"paper\",\n",
    "        x0=dateRange[0], y0=0,\n",
    "        x1=dateRange[-1], y1=1,\n",
    "        line=dict(\n",
    "            width=0,\n",
    "        ),\n",
    "        fillcolor=color,\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "data_path = \"/Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/\"\n",
    "by_region_path = \"{}By_Region/\".format(data_path)\n",
    "saved = \"{}saved/\".format(data_path)\n",
    "traffic_daily = \"{}TS_1800_daily.pkl\".format(saved)\n",
    "region_traffic_daily = \"{}all.pkl\".format(saved)\n",
    "covid = \"{}covid/\".format(data_path)\n",
    "covid_daily = \"{}covid_regioni.csv\".format(covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_path = \"{}meteo/\".format(data_path)\n",
    "dfs_filenames = [f for f in listdir(meteo_path) if isfile(join(meteo_path, f))]\n",
    "dfs = []\n",
    "path_temperature_predictions = \"{}predictions/temperatures.csv\".format(saved)\n",
    "SAVE_TEMPERATURE = False\n",
    "if SAVE_TEMPERATURE:\n",
    "    for f in dfs_filenames:\n",
    "        splits = f.split(\"_\")\n",
    "        if len(splits) == 2 and \".\" in splits[1]:\n",
    "            filename = \"{}{}\".format(meteo_path, f)\n",
    "            current_df = pd.read_csv(filename)\n",
    "            region_name = splits[0]\n",
    "            #if \"rentino\" not in region_name and \"osta\" not in region_name:\n",
    "            month = splits[1][4:].split(\".\")[0]\n",
    "            current_df['Regione'] = [r for r in regions_covid if region_name in r.lower()][0]\n",
    "            current_df['month'] = int(month)\n",
    "            current_df['year'] = int(2021 if \"2021\" in filename else 2020)\n",
    "            dfs.append(current_df)\n",
    "        df_temperature = pd.concat(dfs)\n",
    "        df_temperature['Date'] = df_temperature.apply(lambda x: pd.to_datetime(\"{}/{}/{}\".format(x.year, x.month, int(x.date.split(\" \")[1]))), axis=1)\n",
    "        df_temperature.set_index(['Date', 'Regione'], inplace=True)\n",
    "        df_temperature['Date'] = pd.to_datetime(df_temperature['Date'])\n",
    "        df_temperature.to_csv(path_temperature_predictions)\n",
    "else:\n",
    "    df_temperature = pd.read_csv(path_temperature_predictions)\n",
    "    df_temperature['Date'] = pd.to_datetime(df_temperature['Date'])\n",
    "    df_temperature.set_index(['Date', 'Regione'], inplace=True)\n",
    "    \n",
    "regions_temperature = df_temperature.index.get_level_values(1).unique()\n",
    "regions = regions_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle COVID data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute_rt = False\n",
    "import_covid  = False\n",
    "path_covid = \"{}covid.csv\".format(saved)\n",
    "\n",
    "if import_covid:\n",
    "    df_covid = pd.read_csv(covid_daily)\n",
    "    if \"Regione\" not in df_covid.columns:\n",
    "        df_covid.rename(columns={'denominazione_regione': 'Regione'}, inplace=True)\n",
    "        df_covid['tamponi_giornalieri'] = df_covid.groupby([\n",
    "                        'Regione'])['tamponi'].diff()\n",
    "        df_covid.loc[df_covid['tamponi_giornalieri'].isna() ,\n",
    "                               'tamponi_giornalieri'] = df_covid['tamponi']\n",
    "\n",
    "\n",
    "        df_covid['deceduti_giornalieri'] = df_covid.groupby([\n",
    "                            'Regione'])['deceduti'].diff()\n",
    "        df_covid.loc[df_covid['deceduti_giornalieri'].isna() ,\n",
    "                               'deceduti_giornalieri'] = df_covid['deceduti']\n",
    "\n",
    "        df_covid['terapia_intensiva_giornalieri'] = df_covid.groupby([\n",
    "                            'Regione'])['terapia_intensiva'].diff()\n",
    "        df_covid.loc[df_covid['terapia_intensiva_giornalieri'].isna() ,\n",
    "                               'terapia_intensiva_giornalieri'] = df_covid['terapia_intensiva']\n",
    "\n",
    "        df_covid['totale_casi_giornalieri'] = df_covid.groupby([\n",
    "                            'Regione'])['totale_casi'].diff()\n",
    "        df_covid.loc[df_covid['totale_casi_giornalieri'].isna() ,\n",
    "                               'totale_casi_giornalieri'] = df_covid['totale_casi']\n",
    "    covid_cols = ['Date', 'Regione', 'terapia_intensiva', 'nuovi_positivi', 'tamponi_giornalieri', 'totale_casi', 'deceduti', 'totale_casi_giornalieri', 'terapia_intensiva_giornalieri']\n",
    "\n",
    "    df_covid.data = pd.to_datetime(df_covid.data)\n",
    "    df_covid.rename(columns={'data': 'Date'}, inplace=True)\n",
    "    df_covid = sumRegions(df_covid)\n",
    "    regions_covid = df_covid['Regione'].unique()\n",
    "    #df_covid = df_covid[df_covid['Regione'].isin(regions)].dropna()\n",
    "    df_covid.to_csv(path_covid)\n",
    "else:\n",
    "    try:\n",
    "        del df_covid\n",
    "    except:\n",
    "        print(\"No df covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "path_covid_predictions=\"{}predictions/covid.pkl\".format(saved)\n",
    "if recompute_rt:\n",
    "    for r in regions:\n",
    "        print(\"REGIONE: {}\".format(r))\n",
    "        current_df = df_covid.loc[df_covid['Regione'] == r]\n",
    "        current_df['Date'] = pd.to_datetime(current_df['Date']).dt.date\n",
    "        current_df['DateIndex'] = current_df.loc[:, 'Date']\n",
    "        current_df.set_index('DateIndex', inplace=True)\n",
    "        #current_df = current_df.loc[current_df['nuovi_positivi'] > 0]\n",
    "        current_df = current_df.loc[pd.to_datetime('2020/03/01'):pd.to_datetime('2021/01/31')]\n",
    "        idxs = (current_df['nuovi_positivi'] < 0)# | (current_df.isna()) | (current_df['nuovi_positivi'] == np.inf) | (current_df['nuovi_positivi'] == -np.inf)\n",
    "        if idxs.sum() > 0:\n",
    "            current_df.loc[idxs, 'nuovi_positivi'] = np.nan\n",
    "        current_df.fillna(method='ffill', inplace=True)\n",
    "        current_df.dropna(subset=['nuovi_positivi'], inplace=True)\n",
    "        #current_df[current_df.loc[:, 'nuovi_positivi']]\n",
    "        #current_df.dropna(subset=['nuovi_positivi'], inplace=True)\n",
    "        #\n",
    "        current_df = current_df.drop_duplicates(keep='first')\n",
    "        #print(current_df['nuovi_positivi'].shape, current_df['nuovi_positivi'].apply(lambda x: x < 0).sum())\n",
    "        #current_df.dropna(subset=['totale_casi_giornalieri'], inplace=True)\n",
    "        #print(current_df['totale_casi_giornalieri'].isna().sum())\n",
    "        #print(current_df['totale_casi_giornalieri'].sum())\n",
    "        r_t_series = covid19.r_covid(current_df['nuovi_positivi'])\n",
    "        current_df = pd.merge(current_df, r_t_series, left_index=True, right_index=True)\n",
    "        dfs.append(current_df)\n",
    "    df_covid_predictions = pd.concat(dfs)\n",
    "    del dfs\n",
    "    df_covid_predictions.set_index(['Date', 'Regione'], inplace=True)\n",
    "    df_covid_predictions['%pos'] = (df_covid_predictions['nuovi_positivi']/df_covid_predictions['tamponi_giornalieri'])\n",
    "    df_covid_predictions.to_pickle(path_covid_predictions)\n",
    "else:\n",
    "    df_covid_predictions = pd.read_pickle(path_covid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle traffic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_traffic = False\n",
    "recompute_kalman = False\n",
    "path_traffic = \"{}traffic.csv\".format(saved)\n",
    "if import_traffic:\n",
    "    df_traffic_daily = pd.read_pickle(region_traffic_daily)\n",
    "    df_traffic_daily.loc[df_traffic_daily['Regione'] == \"Emilia Romagna\", \"Regione\"] = \"Emilia-Romagna\"\n",
    "    df_traffic_predictions = df_traffic_daily.loc[df_traffic_daily['Regione'].isin(regions)]\n",
    "    df_traffic_predictions = df_traffic_predictions.groupby('Regione').resample('D', on='Date').sum().reset_index()\n",
    "    df_traffic_predictions['Date'] = pd.to_datetime(df_traffic_predictions['Date']).dt.date\n",
    "    df_traffic_predictions.set_index(['Date', 'Regione'], inplace=True)\n",
    "    df_traffic_predictions.to_csv(path_traffic)\n",
    "else:\n",
    "    df_traffic_predictions = pd.read_csv(path_traffic)\n",
    "    df_traffic_predictions['Date'] = pd.to_datetime(df_traffic_predictions['Date']).dt.date\n",
    "    df_traffic_predictions.set_index(['Date', 'Regione'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothen with Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Kalman Filter to traffic prediction\n",
    "dict_kalman = {}\n",
    "path_traffic_predictions=\"{}predictions/traffic.pkl\".format(saved)\n",
    "if recompute_kalman:\n",
    "    for trafficKPI in trafficKPIsPrecompute:\n",
    "        #current_df_kalman = pd.DataFrame({\"{}_smoothened\".format(trafficKPI): []})\n",
    "        dfs_current_kpi = []\n",
    "        for region in regions:\n",
    "            kf = KalmanFilter(transition_matrices = [1],\n",
    "                      observation_matrices = [1],\n",
    "                      initial_state_mean = 0,\n",
    "                      initial_state_covariance = 1,\n",
    "                      observation_covariance=1,\n",
    "                      transition_covariance=.05)\n",
    "\n",
    "            series = df_traffic_predictions.xs(region, level=1)[trafficKPI]\n",
    "\n",
    "            kf = kf.em(series)\n",
    "            (smoothened, smoothed_state_covariances) = kf.smooth(series)\n",
    "            df_region_kpi = pd.DataFrame({\"noisy\": series})\n",
    "            df_region_kpi['smooth'] = smoothened.squeeze()\n",
    "            df_region_kpi['Regione'] = region\n",
    "            df_region_kpi.reset_index(inplace=True)\n",
    "            df_region_kpi.set_index(['Date', 'Regione'], inplace=True)\n",
    "            dfs_current_kpi.append(df_region_kpi)\n",
    "\n",
    "            dict_kalman[\"{}_{}\".format(trafficKPI, region)] = kf\n",
    "\n",
    "        df_traffic_predictions[\"{}_smoothened\".format(trafficKPI)] = pd.concat(dfs_current_kpi)['smooth']\n",
    "        df_traffic_predictions.to_pickle(path_traffic_predictions)\n",
    "else:\n",
    "    df_traffic_predictions = pd.read_pickle(path_traffic_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_scatter = False\n",
    "if plot_scatter:\n",
    "    #x = it_time_varying_r.index\n",
    "    num_cols = 4\n",
    "    # 21//4 = 5\n",
    "    regions = df_covid['Regione'].unique()\n",
    "    fig = make_subplots(rows=6, cols=num_cols, subplot_titles=regions)\n",
    "    fig.update_layout(height=1200, width=900, title_text=\"Stacked Subplots\", legend = dict(font = dict(family = \"Courier\", size = 10, color = \"black\")))\n",
    "\n",
    "    for i, region in enumerate([r for r in regions[0:5] if r != \"Italia\"]):\n",
    "        row, col = (i // num_cols)+1, (i % num_cols)+1\n",
    "        df_region = df_covid.loc[df_covid['Regione'] == region]\n",
    "        df_region = df_region[100:]\n",
    "        df_region.set_index('Date', inplace=True)\n",
    "        df_region.fillna(method='ffill', inplace=True)\n",
    "        # TODO problema sembra che per alcune regioni ci siano valori solo a partire da X\n",
    "        #df_region.drop_duplicates(inplace=True)\n",
    "        #print(df_region['totale_casi_giornalieri'])\n",
    "\n",
    "        time_varying_r = covid19.r_covid(df_region['totale_casi_giornalieri'])\n",
    "        x = time_varying_r.index\n",
    "        y = time_varying_r['R_mean']\n",
    "        y_upper = time_varying_r['Q0.025']\n",
    "        y_lower = time_varying_r['Q0.975']\n",
    "\n",
    "\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    line=dict(color='rgb(0,100,80)'),\n",
    "                    mode='lines',\n",
    "                    name=\"Indice Rt\"\n",
    "                ), row=row, col=col\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                    name='Upper Bound',\n",
    "                    x=x,\n",
    "                    y=y_upper,\n",
    "                    mode='lines',\n",
    "                    marker=dict(color=\"#444\"),\n",
    "                    line=dict(width=0),\n",
    "                    showlegend=False\n",
    "                ), row=row, col=col\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                    name='Lower Bound',\n",
    "                    x=x,\n",
    "                    y=y_lower,\n",
    "                    marker=dict(color=\"#444\"),\n",
    "                    line=dict(width=0),\n",
    "                    mode='lines',\n",
    "                    fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "                    fill='tonexty',\n",
    "                    showlegend=False\n",
    "                ), row=row, col=col\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            title=region,\n",
    "            legend_title=\"Legenda\"\n",
    "        )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficKPIs = [col for col in df_traffic_predictions.columns if \"smooth\" in col]\n",
    "covidKPIs = [col for col in df_covid_predictions.columns if \"mean\" in col]\n",
    "temperatureKPIs = []#[col for col in df_temperature.columns if \"min\" in col]\n",
    "targetCovid = ['R_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del models_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO per ogni intervallo salvarsi le feature che si usano per controllare cosa c'è che non va"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_like_before = False\n",
    "if do_like_before:\n",
    "    params = {'objective': 'reg:squarederror'}\n",
    "    models_regions = {r:{} for r in regions}\n",
    "\n",
    "    def train_in_interval(interval, current_models_regions = None, init_from_scratch = False):\n",
    "        if init_from_scratch:\n",
    "            current_models_regions = {r:{} for r in regions}\n",
    "        else:\n",
    "            current_models_regions = models_regions\n",
    "        for region in regions_to_train:\n",
    "            print(\"{}: {} -> {}\".format(region, min(interval), max(interval)))\n",
    "            df_ts = df_train_prediction.loc[df_train_prediction.index.get_level_values(1)==region]\n",
    "            df_ts = df_ts.reset_index().set_index('Date').drop(columns='Regione')\n",
    "            df_ts = df_ts.loc[(df_ts.index>=interval[0])&(df_ts.index < interval[1])]\n",
    "            print(\"TRAIN START for interval: {} -> {}\".format(interval, df_ts.shape))\n",
    "            for lag in lags_target:\n",
    "                target = \"target_{}\".format(lag)\n",
    "                targets_vals = df_ts[target].values\n",
    "                xgtrain = DMatrix(data=df_ts[features].values, label=targets_vals)\n",
    "                try:\n",
    "                    current_models_regions[region][lag] = train(params, xgtrain, xgb_model=current_models_regions[region][lag])\n",
    "                except:\n",
    "                    model = train(params, xgtrain)\n",
    "                    current_models_regions[region][lag] = model\n",
    "        return current_models_regions\n",
    "\n",
    "    #models_regions = train_in_interval((start_train_po, divider_po), init_from_scratch=True)\n",
    "    models_regions = train_in_interval((start_train_po, end_train_so), init_from_scratch=True)\n",
    "    train_dates_region_every_n = {}\n",
    "    test_dates_region_every_n = {}\n",
    "    train_dates_region = {}\n",
    "    test_dates_region = {}\n",
    "    df_ts_test_region = {}\n",
    "\n",
    "    def test_in_interval(interval, current_models_regions, farsightness):\n",
    "        print(\"TEST START\")\n",
    "\n",
    "        df_results = pd.DataFrame() # lag, region, prediction, target; index = date\n",
    "        results_dict = []\n",
    "\n",
    "        for region in regions_to_train:\n",
    "            df_ts = df_test_prediction.loc[df_test_prediction.index.get_level_values(1)==region]\n",
    "            df_ts = df_ts.reset_index().set_index('Date').drop(columns='Regione')\n",
    "            df_ts = df_ts.loc[(df_ts.index>=interval[0])&(df_ts.index < interval[1])]\n",
    "            first_date, last_date = df_ts.index.min(), df_ts.index.max()\n",
    "            current_region_values = []\n",
    "            current_region_features = []\n",
    "\n",
    "            test_dates_region[region] = pd.date_range(first_date, last_date)\n",
    "            df_ts_test_region[region] = df_ts\n",
    "            test_dates = test_dates_region[region].unique()\n",
    "            assert test_dates_region[region].shape[0]==len(test_dates), \"Something wrong\"\n",
    "            print(\"{}: {} -> {}, {}\".format(region, min(test_dates), max(test_dates), df_ts.shape))\n",
    "            for i, t in enumerate(test_dates):\n",
    "                features_covid = [col for col in features if \"R_mean\" in col]\n",
    "                X_test_ts = df_ts.loc[t, features]\n",
    "                X_test_ts.sort_index(inplace=True)\n",
    "\n",
    "                for idx_lag, lag in enumerate(lags_target):\n",
    "                    target_col = targets[idx_lag]\n",
    "                    predictions = current_models_regions[region][lag].predict(DMatrix(X_test_ts.to_numpy().reshape(1, -1)))\n",
    "\n",
    "                    X_test_fit, y_test_fit = X_test_ts, df_ts.loc[t, target_col]\n",
    "\n",
    "                    #current_result = {\"date\": t + datetime.timedelta(days=lag), \"lag\": lag, \"region\": region, \"prediction\": predictions[0], \"target\": y_test_fit}\n",
    "                    # TODO devo aggiungere il delta o no??? Sembra troppo preciso\n",
    "                    #-> inserire due date, una per visualizzazione, una per inserimento in predictions_so_far\n",
    "                    #-> altrimenti torno al problema di prima\n",
    "\n",
    "                    #current_result = {\"date\": t + datetime.timedelta(days=lag), \"lag\": lag, \"region\": region, \"prediction\": predictions[0], \"target\": y_test_fit}\n",
    "                    current_result = {\"date\": t + datetime.timedelta(days=lag), \"lag\": lag, \"region\": region, \"prediction\": predictions[0], \"target\": y_test_fit}\n",
    "                    current_features = X_test_fit.copy()\n",
    "                    current_features['lag']=lag\n",
    "                    current_region_features.append(current_features)\n",
    "                    features_so_far = pd.DataFrame(current_region_features)\n",
    "                    # TODO aggiungere feature da inserire dopo in training\n",
    "                    results_dict.append(current_result)\n",
    "                    current_region_values.append(current_result)\n",
    "                    predictions_so_far = pd.DataFrame(current_region_values)\n",
    "                    predictions_so_far = predictions_so_far.set_index(['date', 'lag'])\n",
    "                    prediction_t = predictions_so_far.loc[(predictions_so_far.index.get_level_values(0) == pd.to_datetime(t))&(predictions_so_far.index.get_level_values(1) == lag)]\n",
    "\n",
    "                    features_so_far = features_so_far.reset_index().set_index(['index', 'lag'])\n",
    "                    features_t = features_so_far.loc[(features_so_far.index.get_level_values(0) == pd.to_datetime(t))&(features_so_far.index.get_level_values(1) == lag)]\n",
    "\n",
    "                    if i < len(test_dates)-1 and prediction_t.shape[0] > 0:\n",
    "                        xgtrain = DMatrix(data=features_t.to_numpy().reshape(1, -1), label=prediction_t['target'])\n",
    "                        #xgtrain = DMatrix(data=X_test_fit.to_numpy().reshape(1, -1), label=y_test_fit.to_numpy().reshape(1, -1))\n",
    "                        #current_models_regions[region][lag] = train(params, xgtrain, xgb_model=current_models_regions[region][lag])\n",
    "                        #current_models_regions[region][lag] = train(params, xgtrain, xgb_model=current_models_regions[region][lag])\n",
    "                        current_models_regions[region][lag] = train(params, xgtrain, xgb_model=current_models_regions[region][lag])\n",
    "                        # 1) retrain on entire\n",
    "                        # 2) retrain on entire and add a window -> 05/12, lag=1 -> (01/10, 4/12); (11/10, 14/12)\n",
    "                        # 3) LSTM\n",
    "        df_results = pd.DataFrame(results_dict)\n",
    "        df_results = df_results.dropna()\n",
    "        df_results.set_index(['date', 'region', 'lag'], inplace=True)\n",
    "        df_results['error']=(df_results['prediction']-df_results['target']).abs()\n",
    "        df_results['error_2'] = df_results['error']**2\n",
    "        return current_models_regions, df_results\n",
    "\n",
    "    min_date, max_date = df_test_prediction.index.get_level_values(0).min(), df_test_prediction.index.get_level_values(0).max()\n",
    "    models_regions, df_results = test_in_interval((min_date, max_date), models_regions, farsightness)\n",
    "\n",
    "\n",
    "    def build_df_results_groupped(df_results):\n",
    "        return np.sqrt(df_results.groupby(level=['region', 'lag'])['error_2'].mean()).reset_index()\n",
    "\n",
    "    df_results_mean = build_df_results_groupped(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divider_po, divider_so = pd.to_datetime('2020-07-01'), pd.to_datetime('2020-10-01')\n",
    "start_train_po, end_train_so = pd.to_datetime('2020-03-01'), pd.to_datetime('2020-11-01')\n",
    "start_po = start_train_po\n",
    "ranges_train_PO = [pd.date_range(start_po, divider_po)]\n",
    "ranges_train_SO = [pd.date_range(divider_so, end_train_so)]\n",
    "last_date = min(df_traffic_predictions.index.get_level_values(0).max(), df_covid_predictions.index.get_level_values(0).max(), df_temperature.index.get_level_values(0).max())\n",
    "ranges_so = [pd.date_range(divider_so, last_date)]\n",
    "regions_to_train = [\"Lombardia\"]#regions\n",
    "\n",
    "min_farsightness = 1\n",
    "farsightness = 60\n",
    "delta_features = 14\n",
    "lags = range(delta_features)\n",
    "lags_target = range(min_farsightness, farsightness, 4)\n",
    "\n",
    "#ranges_test_SO = [pd.date_range(end_train_so-pd.Timedelta(days=delta_features-1), last_date)]\n",
    "ranges_test_SO = [pd.date_range(end_train_so-pd.Timedelta(days=delta_features), last_date)]\n",
    "\n",
    "def build_df_prediction(range_dates):\n",
    "    all_dfs = []\n",
    "    # prima ondata\n",
    "    for region in regions_to_train:\n",
    "        # filter ts by region\n",
    "        df_traffic_ts = df_traffic_predictions.loc[(df_traffic_predictions.index.get_level_values(1)==region), trafficKPIs].copy()\n",
    "        df_covid_ts = df_covid_predictions.loc[df_covid_predictions.index.get_level_values(1)==region, list(set(covidKPIs+targetCovid))].copy()\n",
    "        df_temperature_ts = df_temperature.loc[df_temperature.index.get_level_values(1)==region, temperatureKPIs].copy()\n",
    "\n",
    "        df_traffic_ts = df_traffic_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "        df_temperature_ts = df_temperature_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "\n",
    "        df_covid_ts.reset_index(inplace=True)\n",
    "        df_temperature_ts.reset_index(inplace=True)\n",
    "        df_traffic_ts.reset_index(inplace=True)\n",
    "\n",
    "        df_covid_ts = df_covid_ts.set_index('Date')\n",
    "        df_temperature_ts = df_temperature_ts.set_index('Date')\n",
    "        df_traffic_ts = df_traffic_ts.set_index('Date')\n",
    "\n",
    "        df_ts = pd.DataFrame()\n",
    "        features = []\n",
    "        targets = []\n",
    "        target_col = targetCovid[0]\n",
    "        df_target_ts = df_covid_ts.copy()\n",
    "\n",
    "        train_dates_intersection = df_traffic_ts.index.intersection(df_covid_ts.index)\n",
    "\n",
    "        train_dates = []\n",
    "        if len(temperatureKPIs) > 0:\n",
    "            train_dates_intersection = train_dates_intersection.isin(df_temperature_ts.index)\n",
    "        for date_val in train_dates_intersection:\n",
    "            if any(date_val in x for x in range_dates):\n",
    "                train_dates.append(date_val)\n",
    "\n",
    "        train_dates = pd.to_datetime(train_dates)\n",
    "\n",
    "        df_covid_ts, df_traffic_ts, df_temperature_ts = df_covid_ts.loc[df_covid_ts.index.isin(train_dates)], df_traffic_ts.loc[df_traffic_ts.index.isin(train_dates)], df_temperature_ts.loc[df_temperature_ts.index.isin(train_dates)]\n",
    "\n",
    "        for lag in lags_target:\n",
    "            target = \"target_{}\".format(lag)\n",
    "            targets.append(target)\n",
    "            df_ts[target] = df_target_ts.shift(-1*lag)[target_col]\n",
    "\n",
    "        for lag in lags:\n",
    "            lag_shift = lag+1\n",
    "            for col in trafficKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                #print(feature, df_traffic_ts.shift(lag_shift).loc[:, col])\n",
    "                df_ts[feature] = df_traffic_ts.copy().shift(lag_shift).loc[:, col]\n",
    "                features.append(feature)\n",
    "            for col in covidKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_covid_ts.copy().shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            for col in temperatureKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_temperature_ts.copy().shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "\n",
    "        df_ts = df_ts[targets+features]\n",
    "        df_ts.dropna(subset=features, inplace=True)\n",
    "        df_ts['Regione'] = region\n",
    "        df_ts = df_ts.reset_index().set_index(['Date', 'Regione'])\n",
    "        all_dfs.append(df_ts.copy())\n",
    "    return pd.concat(all_dfs), targets, features\n",
    "(df_train_prediction_PO, targets, features), (df_train_prediction_SO, _, _) = build_df_prediction(ranges_train_PO), build_df_prediction(ranges_train_SO)\n",
    "(df_test_prediction, _, _) = build_df_prediction(ranges_test_SO)\n",
    "TRAIN_ALSO_PO = True\n",
    "if TRAIN_ALSO_PO:\n",
    "    df_train_prediction = pd.concat([df_train_prediction_PO, df_train_prediction_SO])\n",
    "else:\n",
    "    df_train_prediction = df_train_prediction_SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'reg:squarederror'}\n",
    "models_regions = {r:{} for r in regions}\n",
    "\n",
    "def train_in_interval(interval):\n",
    "    for region in regions_to_train:\n",
    "        print(\"{}: {} -> {}\".format(region, min(interval), max(interval)))\n",
    "        df_ts = df_train_prediction.loc[df_train_prediction.index.get_level_values(1)==region]\n",
    "        df_ts = df_ts.reset_index().set_index('Date').drop(columns='Regione')\n",
    "        df_ts = df_ts.loc[(df_ts.index>=interval[0])&(df_ts.index < interval[1])]\n",
    "        for lag in lags_target:\n",
    "            target = \"target_{}\".format(lag)\n",
    "            df_ts_lag = df_ts.copy().drop(columns=[col for col in targets if (col not in features) and (col != target)]).dropna()\n",
    "            models_regions[region][lag] = XGBRegressor()\n",
    "            # print(\"DBG: {}, {}\".format(df_ts[features].shape, df_ts[target].shape))\n",
    "            models_regions[region][lag].fit(df_ts_lag[features].values, df_ts_lag[target])\n",
    "    return models_regions\n",
    "\n",
    "#models_regions = train_in_interval((start_train_po, divider_po), init_from_scratch=True)\n",
    "models_regions = train_in_interval((start_train_po, end_train_so))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates_region_every_n = {}\n",
    "test_dates_region_every_n = {}\n",
    "train_dates_region = {}\n",
    "test_dates_region = {}\n",
    "df_ts_test_region = {}\n",
    "\n",
    "def test_in_interval(interval):\n",
    "    print(\"TEST START\")\n",
    "                \n",
    "    df_results = pd.DataFrame() # lag, region, prediction, target; index = date\n",
    "    results_dict = []\n",
    "\n",
    "    for region in regions_to_train:\n",
    "        df_ts = df_test_prediction.loc[df_test_prediction.index.get_level_values(1)==region]\n",
    "        df_ts = df_ts.reset_index().set_index('Date').drop(columns='Regione')\n",
    "        df_ts = df_ts.loc[(df_ts.index>=interval[0])&(df_ts.index < interval[1])]\n",
    "        first_date, last_date = df_ts.index.min(), df_ts.index.max()\n",
    "        current_region_values = []\n",
    "        \n",
    "        test_dates_region[region] = pd.date_range(first_date, last_date)\n",
    "        df_ts_test_region[region] = df_ts\n",
    "        test_dates = test_dates_region[region].unique()\n",
    "        assert test_dates_region[region].shape[0]==len(test_dates), \"Something wrong\"\n",
    "        for idx_lag, lag in enumerate(lags_target):\n",
    "            target_col = targets[idx_lag]\n",
    "            walk_forward_df = df_train_prediction.copy().drop(columns=[col for col in targets if (col not in features) and (col != target_col)]).dropna()\n",
    "            current_df_ts = df_ts[features+[target_col]].copy().dropna()\n",
    "            test_dates = current_df_ts.index\n",
    "            print(\"{}, lag = {}: {} -> {}, {}\".format(region, lag, min(test_dates), max(test_dates), current_df_ts.shape))\n",
    "            for i, t in enumerate(test_dates):\n",
    "                features_covid = [col for col in features if \"R_mean\" in col]\n",
    "                current_df_ts = df_ts.loc[t:t+datetime.timedelta(days=0)]\n",
    "                \n",
    "                X_test_ts = current_df_ts[features]\n",
    "                #X_test_ts.sort_index(inplace=True)\n",
    "                #print(\"PREDICT: {}\".format(X_test_ts))\n",
    "\n",
    "                predictions = models_regions[region][lag].predict(X_test_ts.values)\n",
    "\n",
    "                X_test_fit, y_test_fit = X_test_ts, current_df_ts[target_col].values\n",
    "\n",
    "                #current_result = {\"date\": t + datetime.timedelta(days=lag), \"lag\": lag, \"region\": region, \"prediction\": predictions[0], \"target\": y_test_fit}\n",
    "                current_result = {\"date\": t + datetime.timedelta(days=lag), \"lag\": lag, \"region\": region, \"prediction\": predictions[0], \"target\": y_test_fit[0]}\n",
    "                \n",
    "                results_dict.append(current_result)\n",
    "                \n",
    "                walk_forward_df = walk_forward_df.append(current_df_ts)\n",
    "                models_regions[region][lag].fit(walk_forward_df[features].values, walk_forward_df[target_col])\n",
    "                # 1) retrain on entire\n",
    "                # 2) retrain on entire and add a window -> 05/12, lag=1 -> (01/10, 4/12); (11/10, 14/12)\n",
    "                # 3) LSTM\n",
    "    df_results = pd.DataFrame(results_dict)\n",
    "    df_results = df_results.dropna()\n",
    "    df_results.set_index(['date', 'region', 'lag'], inplace=True)\n",
    "    df_results['error']=(df_results['prediction']-df_results['target']).abs()\n",
    "    df_results['error_2'] = df_results['error']**2\n",
    "    return models_regions, df_results\n",
    "\n",
    "min_date, max_date = df_test_prediction.index.get_level_values(0).min(), df_test_prediction.index.get_level_values(0).max()\n",
    "models_regions, df_results = test_in_interval((min_date, max_date))\n",
    "\n",
    "\n",
    "def build_df_results_groupped(df_results):\n",
    "    return np.sqrt(df_results.groupby(level=['region', 'lag'])['error_2'].mean()).reset_index()\n",
    "\n",
    "df_results_mean = build_df_results_groupped(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name = \"XGBoost\"\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app_results = JupyterDash(name, external_stylesheets=external_stylesheets)\n",
    "\n",
    "app_results.layout = html.Div([\n",
    "html.Label(\n",
    "    [\n",
    "        \"Regione\",\n",
    "        dcc.Dropdown(id=\"regions\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in regions_to_train],\n",
    "                    value=[regions_to_train[0]],\n",
    "                    multi=True,\n",
    "                    clearable=True)\n",
    "    ]),\n",
    "\n",
    "html.Label(\n",
    "    [\n",
    "        \"Lag\",\n",
    "        dcc.Dropdown(id=\"lags\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in lags_target],\n",
    "                    value=lags_target[-1],\n",
    "                    clearable=True)\n",
    "    ]),\n",
    "\n",
    "html.Label(\n",
    "    [\n",
    "        \"Tipologia plot\",\n",
    "        dcc.Dropdown(id=\"plot_type\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in [\"Timeseries\", \"Errore assoluto\"]],\n",
    "                    value=\"Timeseries\",\n",
    "                    clearable=False)\n",
    "    ]),\n",
    "html.Div(dcc.Graph(id=name))])\n",
    "\n",
    "@app_results.callback(\n",
    "Output(name, \"figure\"), \n",
    "[Input(\"regions\", \"value\"), Input(\"lags\", \"value\"), Input(\"plot_type\", \"value\")])\n",
    "def display_rf_results(regions, lag, plot_type):\n",
    "\n",
    "    if isinstance(regions, str):\n",
    "        regions = [regions]\n",
    "\n",
    "    if regions is None:\n",
    "        regions = [regions_to_train[0]]\n",
    "\n",
    "    is_timeseries, is_timeseries_error = plot_type == \"Timeseries\", plot_type == \"Errore assoluto\"\n",
    "\n",
    "    R_colors = px.colors.qualitative.Dark24#['#FF0000', '#f56342', '#f57e42', '#f59642', '#f5a742', '#F6DE43', '#EF42D8', '#FA5F8D', '#D0114A']\n",
    "    y_hat_colors = px.colors.qualitative.Alphabet#['#0000FF', '#0062ff', '#008cff', '#00b3ff', '#00b7e0', '#00F572', '#01CA5F', '#02DEB2', '#011ABC']\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "    #df_plot = df_results.reset_index()\n",
    "    df_plot = df_results.loc[(df_results.index.get_level_values('region').isin(regions))&(df_results.index.get_level_values('lag')==lag)]\n",
    "    \n",
    "    for i, r in enumerate(regions):\n",
    "\n",
    "        current_df_results = df_plot.loc[(slice(None), r, lag)]\n",
    "        \n",
    "        if is_timeseries_error:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=current_df_results.index,\n",
    "                    y=current_df_results['error'],\n",
    "                    name=\"Y - {}\".format(r),\n",
    "                    marker=dict(\n",
    "                        color=R_colors[i]\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=current_df_results.index,\n",
    "                        y=current_df_results['prediction'],\n",
    "                        name=\"Prediction - {}\".format(r),\n",
    "                        marker=dict(\n",
    "                            color=y_hat_colors[i]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=current_df_results.index,\n",
    "                        y=current_df_results['target'],\n",
    "                        name=\"Target - {}\".format(r),\n",
    "                        marker=dict(\n",
    "                            color=R_colors[i]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    '''\n",
    "    # Add figure title\n",
    "    fig.update_layout(\n",
    "        title_text=\"{} vs {}\".format(trafficKPI, covidKPI)\n",
    "    )\n",
    "    \n",
    "    for dateRange in ranges_train:\n",
    "        fig = fill_with_areas(dateRange, fig, True)\n",
    "    '''\n",
    "    #for dateRange in ranges_test:\n",
    "    #    fig = fill_with_areas(dateRange, fig, False)\n",
    "\n",
    "    return fig\n",
    "\n",
    "#app_timeseries = build_app_timeseries(df_traffic_daily_SO, df_covid_SO)\n",
    "app_results.run_server(mode='inline', port=46004) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_results['error_2'] = df_results['error']**2\n",
    "df_results_mean = np.sqrt(df_results.groupby(level=['region', 'lag'])['error_2'].mean()).reset_index()\n",
    "\n",
    "col='error_2'\n",
    "fig = px.box(df_results_mean, x=\"lag\", y=col)\n",
    "\n",
    "means = df_results_mean.groupby(by=[\"lag\"]).mean()\n",
    "medians = df_results_mean.groupby(by=[\"lag\"]).median()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=means.index, y=means[col],\n",
    "                mode='lines',\n",
    "                name='Mean'))\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=\"Boxplot errors\",\n",
    "    yaxis=dict(\n",
    "        range=[0, df_results_mean.max()]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train during PO\n",
    "train_also_PO = True\n",
    "if train_also_PO:\n",
    "    print(\"PRIMA ONDATA\")\n",
    "    for region in regions_to_train:\n",
    "        df_train_po = df_train_prediction.loc[df_train_prediction_PO.index.get_level_values(1)==region]\n",
    "        df_train_po = df_train_po.set_index('Date')\n",
    "        \n",
    "        #df_traffic_ts = df_traffic_ts.loc[(df_traffic_ts.index >= divider_po)&(df_traffic_ts.index < divider_so)]\n",
    "        #df_covid_ts = df_covid_ts.loc[(df_covid_ts.index >= divider_po)&(df_covid_ts.index < divider_so)]\n",
    "        #df_temperature_ts = df_temperature_ts.loc[(df_temperature_ts.index >= divider_po)&(df_temperature_ts.index < divider_so)]\n",
    "        #print(\"1\", df_traffic_ts)\n",
    "        # create dataframe with last values\n",
    "        df_ts = pd.DataFrame()\n",
    "        features = []\n",
    "        targets = []\n",
    "        target_col = \"R_mean\"\n",
    "        df_target_ts = df_covid_ts.copy()\n",
    "        \n",
    "        # regions may have different dates for each dataset; for this reason I select them before by taking ...\n",
    "        #traffic_dates, covid_dates, temperature_dates = df_traffic_ts.index, df_covid_ts.index, df_temperature_ts.index\n",
    "        #train_dates_intersection = traffic_dates.isin(covid_dates)\n",
    "        train_dates_intersection = df_traffic_ts.index.intersection(df_covid_ts.index)\n",
    "        #df_traffic_ts = df_traffic_ts.loc[traffic_dates]\n",
    "        train_dates = []\n",
    "        if len(temperatureKPIs) > 0:\n",
    "            train_dates_intersection = train_dates_intersection.isin(df_temperature_ts.index)\n",
    "        for date_val in train_dates_intersection:\n",
    "            if any(date_val in x for x in ranges_train_PO):\n",
    "                train_dates.append(date_val)\n",
    "                \n",
    "        train_dates = pd.to_datetime(train_dates)\n",
    "        \n",
    "        df_covid_ts, df_traffic_ts, df_temperature_ts = df_covid_ts.loc[df_covid_ts.index.isin(train_dates)], df_traffic_ts.loc[df_traffic_ts.index.isin(train_dates)], df_temperature_ts.loc[df_temperature_ts.index.isin(train_dates)]\n",
    "        \n",
    "        for lag in lags_target:\n",
    "            target = \"target_{}\".format(lag)\n",
    "            targets.append(target)\n",
    "            df_ts[target] = df_target_ts.shift(-1*lag)[target_col]\n",
    "        \n",
    "        for lag in lags:\n",
    "            lag_shift = lag+1\n",
    "            for col in trafficKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                #print(feature, df_traffic_ts.shift(lag_shift).loc[:, col])\n",
    "                df_ts[feature] = df_traffic_ts.shift(lag_shift).loc[:, col]\n",
    "                features.append(feature)\n",
    "            for col in covidKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_covid_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            for col in temperatureKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_temperature_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "        \n",
    "        #print(\"PROVA1\", df_ts.head())\n",
    "\n",
    "        df_ts = df_ts[targets+features]\n",
    "        df_ts.dropna(inplace=True)\n",
    "        #df_ts = df_ts.reset_index(level='Regione')\n",
    "        print(\"Intervalli regione {}: {} -> {}\".format(region, df_ts.index.min(), df_ts.index.max()))\n",
    "        test_dates, train_dates = [], []\n",
    "        \n",
    "        for lag in lags_target:\n",
    "            target = \"target_{}\".format(lag)\n",
    "            targets_vals = df_ts[target].values\n",
    "            \n",
    "            xgtrain = DMatrix(df_ts[features].values, targets_vals)\n",
    "            model = train(params, xgtrain)\n",
    "            models_regions[region][lag] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then during SO\n",
    "train_dates_region_every_n = {}\n",
    "test_dates_region_every_n = {}\n",
    "train_dates_region = {}\n",
    "test_dates_region = {}\n",
    "df_ts_test_region = {}\n",
    "all_dfs = []\n",
    "#ranges_train_ts = [pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "print(\"SECONDA ONDATA\")\n",
    "\n",
    "for region in regions_to_train:\n",
    "    df_traffic_ts = df_traffic_predictions.loc[df_traffic_predictions.index.get_level_values(1)==region, trafficKPIs].copy()\n",
    "    df_covid_ts = df_covid_predictions.loc[df_covid_predictions.index.get_level_values(1)==region, covidKPIs].copy()\n",
    "    df_temperature_ts = df_temperature.loc[df_temperature.index.get_level_values(1)==region, temperatureKPIs].copy()\n",
    "\n",
    "    df_traffic_ts = df_traffic_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "    df_temperature_ts = df_temperature_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "\n",
    "    df_covid_ts.reset_index(inplace=True)\n",
    "    df_temperature_ts.reset_index(inplace=True)\n",
    "    df_traffic_ts.reset_index(inplace=True)\n",
    "\n",
    "    df_covid_ts = df_covid_ts.set_index('Date')\n",
    "    df_temperature_ts = df_temperature_ts.set_index('Date')\n",
    "    df_traffic_ts = df_traffic_ts.set_index('Date')\n",
    "    \n",
    "    #df_traffic_ts = df_traffic_ts.loc[(df_traffic_ts.index >= divider_so)]\n",
    "    #df_covid_ts = df_covid_ts.loc[(df_covid_ts.index >= divider_so)]\n",
    "    #df_temperature_ts = df_temperature_ts.loc[(df_temperature_ts.index >= divider_so)]\n",
    "\n",
    "    # create dataframe with last values\n",
    "    df_ts = pd.DataFrame()\n",
    "    features = []\n",
    "    targets = []\n",
    "    target_col = \"R_mean\"\n",
    "    df_target_ts = df_covid_ts.copy()\n",
    "\n",
    "    # regions may have different dates for each dataset; for this reason I select them before by taking ...\n",
    "    #traffic_dates, covid_dates, temperature_dates = df_traffic_ts.index, df_covid_ts.index, df_temperature_ts.index\n",
    "    #train_dates_intersection = traffic_dates.isin(covid_dates)\n",
    "    train_dates_intersection = df_traffic_ts.index.intersection(df_covid_ts.index)\n",
    "    df_traffic_ts = df_traffic_ts.loc[traffic_dates]\n",
    "    so_dates = []\n",
    "    dates_intersection = df_traffic_ts.index.intersection(df_covid_ts.index)\n",
    "    if len(temperatureKPIs) > 0:\n",
    "        dates_intersection = dates_intersection.isin(df_temperature_ts.index)\n",
    "    for date_val in dates_intersection:\n",
    "        if any(date_val in x for x in ranges_so):\n",
    "            so_dates.append(date_val)\n",
    "\n",
    "    so_dates = pd.to_datetime(so_dates)\n",
    "\n",
    "    df_covid_ts, df_traffic_ts, df_temperature_ts = df_covid_ts.loc[df_covid_ts.index.isin(so_dates)], df_traffic_ts.loc[df_traffic_ts.index.isin(so_dates)], df_temperature_ts.loc[df_temperature_ts.index.isin(so_dates)]\n",
    "\n",
    "    for lag in lags_target:\n",
    "        target = \"target_{}\".format(lag)\n",
    "        targets.append(target)\n",
    "        df_ts[target] = df_target_ts.shift(-1*lag)[target_col]\n",
    "    for lag in lags:\n",
    "        lag_shift = lag+1\n",
    "        for col in trafficKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            #print(feature, df_traffic_ts.shift(lag_shift).loc[:, col])\n",
    "            df_ts[feature] = df_traffic_ts.shift(lag_shift).loc[:, col]\n",
    "            features.append(feature)\n",
    "        for col in covidKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_covid_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "        for col in temperatureKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_temperature_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "            \n",
    "    df_ts = df_ts[targets+features]\n",
    "    df_ts.dropna(inplace=True)\n",
    "    all_dfs.append(df_ts.copy())\n",
    "    #df_ts = df_ts.reset_index(level='Regione')\n",
    "    print(\"Intervalli regione {}: {} -> {}\".format(region, df_ts.index.min(), df_ts.index.max()))\n",
    "    test_dates, train_dates = [], []\n",
    "    # filter ts by region\n",
    "    \n",
    "    for date_val in df_ts.index.unique():\n",
    "        if any(date_val in x for x in ranges_train_SO):\n",
    "            train_dates.append(date_val)\n",
    "        else:\n",
    "            test_dates.append(date_val)\n",
    "            \n",
    "    df_ts_train, df_ts_test = df_ts.loc[train_dates], df_ts.loc[test_dates]\n",
    "    \n",
    "    test_dates_every_n = pd.date_range(start=test_dates[0], end=test_dates[-1], freq=\"{}D\".format(farsightness)).to_pydatetime()\n",
    "    test_dates_region_every_n[region] = test_dates_every_n\n",
    "    train_dates_region[region], test_dates_region[region] = train_dates, test_dates\n",
    "    df_ts_test_region[region] = df_ts_test\n",
    "    \n",
    "    for lag in lags_target:\n",
    "        targets_vals = df_ts[target].values\n",
    "        xgtrain = DMatrix(df_ts_train[features].values, targets_vals)\n",
    "        try:\n",
    "            models_regions[region][lag] = train(params, xgtrain, xgb_model=models_regions[region])\n",
    "        except:\n",
    "            model = train(params, xgtrain)\n",
    "            models_regions[region][lag] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame() # lag, region, prediction, target; index = date\n",
    "results_dict = []\n",
    "\n",
    "for r in regions_to_train:\n",
    "    for lag in lags_target:\n",
    "        test_predictions[r][lag] = np.array([])\n",
    "        test_targets[r][lag] = np.array([])\n",
    "\n",
    "for region in regions_to_train:\n",
    "    test_dates = test_dates_region[region]\n",
    "    df_ts_test = df_ts_test_region[region]\n",
    "    print(\"{}: {}\".format(region, df_ts_test.shape))\n",
    "    for i, t in enumerate(test_dates):\n",
    "        X_test_ts = df_ts_test.loc[t, features]\n",
    "        X_test_ts.sort_index(inplace=True)\n",
    "        \n",
    "        for lag in lags_target:\n",
    "            predictions = models_regions[region][lag].predict(DMatrix(X_test_ts.to_numpy().reshape(1, -1)))\n",
    "            \n",
    "            #test_predictions[r][lag] = np.append(test_predictions[r][lag], predictions)\n",
    "            \n",
    "            X_test_fit, y_test_fit = X_test_ts, df_ts_test.loc[t, targets[lag]]\n",
    "            #test_targets[r][lag] = np.append(test_targets[r][lag], y_test_fit)\n",
    "            results_dict.append({\"date\": t + datetime.timedelta(days=lag), \"lag\": lag, \"region\": region, \"prediction\": predictions[0], \"target\": y_test_fit})\n",
    "\n",
    "            if i < len(test_dates)-1:\n",
    "                xgtrain = DMatrix(X_test_fit.to_numpy().reshape(1, -1), y_test_fit.reshape(1, -1))\n",
    "                models_regions[region][lag] = train(params, xgtrain, xgb_model=models_regions[region][lag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"XGBoost\"\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app_results = JupyterDash(name, external_stylesheets=external_stylesheets)\n",
    "\n",
    "app_results.layout = html.Div([\n",
    "html.Label(\n",
    "    [\n",
    "        \"Regione\",\n",
    "        dcc.Dropdown(id=\"regions\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in regions_to_train],\n",
    "                    value=[\"Lombardia\"],\n",
    "                    multi=True,\n",
    "                    clearable=True)\n",
    "    ]),\n",
    "\n",
    "html.Label(\n",
    "    [\n",
    "        \"Lag\",\n",
    "        dcc.Dropdown(id=\"lags\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in lags_target],\n",
    "                    value=lags_target[-1],\n",
    "                    clearable=True)\n",
    "    ]),\n",
    "\n",
    "html.Label(\n",
    "    [\n",
    "        \"Tipologia plot\",\n",
    "        dcc.Dropdown(id=\"plot_type\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in [\"Timeseries\", \"Errore assoluto\"]],\n",
    "                    value=\"Timeseries\",\n",
    "                    clearable=False)\n",
    "    ]),\n",
    "html.Div(dcc.Graph(id=name))])\n",
    "\n",
    "@app_results.callback(\n",
    "Output(name, \"figure\"), \n",
    "[Input(\"regions\", \"value\"), Input(\"lags\", \"value\"), Input(\"plot_type\", \"value\")])\n",
    "def display_rf_results(regions, lag, plot_type):\n",
    "\n",
    "    if isinstance(regions, str):\n",
    "        regions = [regions]\n",
    "\n",
    "    if regions is None:\n",
    "        regions = ['Lombardia']\n",
    "\n",
    "    is_timeseries, is_timeseries_error = plot_type == \"Timeseries\", plot_type == \"Errore assoluto\"\n",
    "\n",
    "    R_colors = px.colors.qualitative.Dark24#['#FF0000', '#f56342', '#f57e42', '#f59642', '#f5a742', '#F6DE43', '#EF42D8', '#FA5F8D', '#D0114A']\n",
    "    y_hat_colors = px.colors.qualitative.Alphabet#['#0000FF', '#0062ff', '#008cff', '#00b3ff', '#00b7e0', '#00F572', '#01CA5F', '#02DEB2', '#011ABC']\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "    #df_plot = df_results.reset_index()\n",
    "    df_plot = df_results.loc[(df_results.index.get_level_values('region').isin(regions))&(df_results.index.get_level_values('lag')==lag)]\n",
    "    \n",
    "    for i, r in enumerate(regions):\n",
    "\n",
    "        current_df_results = df_plot.loc[(slice(None), r, lag)]\n",
    "        \n",
    "        if is_timeseries_error:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=current_df_results.index,\n",
    "                    y=current_df_results['error'],\n",
    "                    name=\"Y - {}\".format(r),\n",
    "                    marker=dict(\n",
    "                        color=R_colors[i]\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=current_df_results.index,\n",
    "                        y=current_df_results['prediction'],\n",
    "                        name=\"Prediction - {}\".format(r),\n",
    "                        marker=dict(\n",
    "                            color=y_hat_colors[i]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=current_df_results.index,\n",
    "                        y=current_df_results['target'],\n",
    "                        name=\"Target - {}\".format(r),\n",
    "                        marker=dict(\n",
    "                            color=R_colors[i]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    '''\n",
    "    # Add figure title\n",
    "    fig.update_layout(\n",
    "        title_text=\"{} vs {}\".format(trafficKPI, covidKPI)\n",
    "    )\n",
    "    \n",
    "    for dateRange in ranges_train:\n",
    "        fig = fill_with_areas(dateRange, fig, True)\n",
    "    '''\n",
    "    #for dateRange in ranges_test:\n",
    "    #    fig = fill_with_areas(dateRange, fig, False)\n",
    "\n",
    "    return fig\n",
    "\n",
    "#app_timeseries = build_app_timeseries(df_traffic_daily_SO, df_covid_SO)\n",
    "app_results.run_server(mode='inline', port=46004) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['error_2'] = df_results['error']**2\n",
    "df_results_mean = np.sqrt(df_results.groupby(level=['region', 'lag'])['error_2'].mean()).reset_index()\n",
    "\n",
    "col='error_2'\n",
    "fig = px.box(df_results_mean, x=\"lag\", y=col)\n",
    "\n",
    "means = df_results_mean.groupby(by=[\"lag\"]).mean()\n",
    "medians = df_results_mean.groupby(by=[\"lag\"]).median()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=means.index, y=means[col],\n",
    "                mode='lines',\n",
    "                name='Mean'))\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=\"Boxplot errors\",\n",
    "    yaxis=dict(\n",
    "        range=[0, df_results_mean.max()]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO qui devo reintegrare nella parte di supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farsightness = 7\n",
    "lags_range_covid = range(farsightness, 12, 2)#[7, 9, 11]#range(10, 20, 5)\n",
    "lags_range_traffic = range(farsightness, 12, 2)#range(10, 20, 5)\n",
    "lags_range_temperature = []\n",
    "covisPredictionKPIs = ['R_mean']\n",
    "tempPredictionKPIs = []#['prec', 'tmin']\n",
    "# Feature selection: \n",
    "# - lags (CV)                                -> (tuning) -> first, compare correlation; then select lags range that give best results in random\n",
    "# - covid: R_mean, terapie_intensive;        -> add columns properly -> ok\n",
    "# - polynomial                               -> for linear regression model, add features ^2, ^3 ...\n",
    "# - differentiate lags for type of feature   -> covid: (10, 20); temperature: (10, 16); -> (tuning)\n",
    "# - rolling avg                              -> target + features; -> not improvement\n",
    "trafficPredictionKPIs = [t for t in trafficKPIs if \"smooth\" in t]\n",
    "df = pd.DataFrame()\n",
    "features_covid, features_traffic, features_temp = [], [], []\n",
    "\n",
    "rolling_avg_k = 1\n",
    "df_traffic_predictions_roll = df_traffic_predictions#[trafficPredictionKPIs].rolling(rolling_avg_k).mean()\n",
    "df_temperature_roll = df_temperature#[tempPredictionKPIs].rolling(rolling_avg_k).mean()\n",
    "df_covid_roll = df_covid_predictions#[covisPredictionKPIs].rolling(rolling_avg_k).mean()\n",
    "    \n",
    "for lag in lags_range_covid:\n",
    "    df_covid_shift = df_covid_roll.sort_index(level=[1, 0]).groupby(level=1).shift(lag)\n",
    "    for covidKPI in covisPredictionKPIs:\n",
    "        kpi = '{}_{}'.format(covidKPI, lag)\n",
    "        df[kpi] = df_covid_shift[covidKPI]\n",
    "        features_covid.append(kpi)\n",
    "        \n",
    "for lag in lags_range_traffic:\n",
    "    df_traffic_shift = df_traffic_predictions_roll.sort_index(level=[1, 0]).groupby(level=1).shift(lag)\n",
    "    for trafficKPI in trafficPredictionKPIs:\n",
    "        kpi = '{}_{}'.format(trafficKPI, lag)\n",
    "        df[kpi] = df_traffic_shift[trafficKPI]\n",
    "        features_traffic.append(kpi)\n",
    "        \n",
    "for lag in lags_range_temperature:\n",
    "    df_temperature_shift = df_temperature_roll.sort_index(level=[1, 0]).groupby(level=1).shift(lag)\n",
    "    for meteoKPI in tempPredictionKPIs:\n",
    "        kpi = '{}_{}'.format(meteoKPI, lag)\n",
    "        df[kpi] = df_temperature_shift[meteoKPI]\n",
    "        features_temp.append(kpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_covid_roll, left_index=True, right_index=True)\n",
    "#df.fillna(method='ffill', inplace=True)\n",
    "features, targets = features_covid+features_traffic+features_temp, ['R_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = features+targets\n",
    "df = df[columns_to_select]\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, [col for col in df.columns if \"over\" in col]].head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, [col for col in df.columns if \"mean\" in col]].head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider_po, divider_so = pd.to_datetime('2020-08-01'), pd.to_datetime('2020-10-01')\n",
    "ranges_train = [pd.date_range(pd.to_datetime('2020-03-01'), pd.to_datetime('2020-05-01')), pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "#ranges_train = [pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-12-31'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "#divider_train_start, divider_train_end = pd.to_datetime('2020-05-01'), pd.to_datetime('2020-11-01')#divider_so, pd.to_datetime('2020-12-10')\n",
    "#ranges_train = [pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-12-30'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "\n",
    "only_so = False\n",
    "if only_so:\n",
    "    df = df[(df.index.get_level_values(0) >= divider_so)]\n",
    "else:\n",
    "    df = df[(df.index.get_level_values(0) < divider_po) | (df.index.get_level_values(0) >= divider_so)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[features], df[targets]\n",
    "train_dates, test_dates = [], []\n",
    "for date_val in X.index.get_level_values(0).unique():\n",
    "    if any(date_val in x for x in ranges_train):\n",
    "        train_dates.append(date_val)\n",
    "    else:\n",
    "        test_dates.append(date_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_splits = True\n",
    "X, y = df[features], df[targets]\n",
    "\n",
    "dates, regions_df = X.reset_index()['Date'], X.reset_index()['Regione']\n",
    "if do_splits:\n",
    "    is_rf = True\n",
    "    is_gbr = False\n",
    "    is_gaussian = False\n",
    "    is_linear = False\n",
    "    is_mlp = False\n",
    "\n",
    "    all_regions_prediction = regions\n",
    "    dict_regions = {region: i for i, region in enumerate(all_regions_prediction)}\n",
    "\n",
    "    splits = {'Random': {}, 'Per periodo': {}, 'Per regione': {}}\n",
    "\n",
    "    splits['Random']['X_train'], splits['Random']['X_test'], splits['Random']['y_train'], splits['Random']['y_test'] = \\\n",
    "                train_test_split(X, y, test_size = 0.3, random_state = 123)   \n",
    "    splits['Random']['X'] = X.copy()\n",
    "    \n",
    "    idxs_train, idxs_test = X.index.get_level_values(0).intersection(pd.Series(train_dates)), X.index.get_level_values(0).intersection(pd.Series(test_dates))\n",
    "    splits['Per periodo']['X_train'], splits['Per periodo']['X_test'], splits['Per periodo']['y_train'], \\\n",
    "        splits['Per periodo']['y_test'] = X.loc[idxs_train], X.loc[idxs_test], y.loc[idxs_train], y.loc[idxs_test]\n",
    "   \n",
    "    splits['Per periodo']['X'] = X.copy()\n",
    "    splits['Per periodo']['X_train']['Regione'], splits['Per periodo']['X_test']['Regione'] = [dict_regions[r] for r in splits['Per periodo']['X_train'].index.get_level_values(1).to_list()], [dict_regions[r] for r in splits['Per periodo']['X_test'].index.get_level_values(1).to_list()]\n",
    "    \n",
    "    splits['Per periodo']['X']['Regione']=[dict_regions[r] for r in X.index.get_level_values(1).to_list()]\n",
    "\n",
    "    regions_train, regions_test = train_test_split(all_regions_prediction, test_size = 0.3, random_state = 1)\n",
    "    idx_train, idx_test = X.index.get_level_values(1).isin(regions_train), X.index.get_level_values(1).isin(regions_test)\n",
    "    splits['Per regione']['X_train'], splits['Per regione']['X_test'], splits['Per regione']['y_train'], splits['Per regione']['y_test'] = \\\n",
    "        X[idx_train], X[idx_test], y[idx_train], y[idx_test]\n",
    "    #splits['Per regione']['X_train']['Regione'], splits['Per regione']['X_test']['Regione'] = [dict_regions[r] for r in splits['Per regione']['X_train'].index.get_level_values(1).to_list()], [dict_regions[r] for r in splits['Per regione']['X_test'].index.get_level_values(1).to_list()]\n",
    "    splits['Per regione']['X'] = X.copy()\n",
    "    #splits['Per regione']['X']['Regione'] = [dict_regions[r] for r in X.index.get_level_values(1).to_list()]\n",
    "\n",
    "    for key in splits.keys():\n",
    "        if is_rf:\n",
    "            model = RandomForestRegressor(n_estimators=200)\n",
    "        elif is_gbr:\n",
    "            model = XGBRegressor()\n",
    "        elif is_gaussian:\n",
    "            model = GaussianProcessRegressor()\n",
    "        elif is_mlp:\n",
    "            model = MLPRegressor(hidden_layer_sizes=(64, 32))\n",
    "        else:\n",
    "            model = LinearRegression()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = splits[key]['X_train'], splits[key]['X_test'], splits[key]['y_train'], splits[key]['y_test']\n",
    "        X = splits[key]['X']\n",
    "        #print(X_train.shape, X_test.shape, X.shape)\n",
    "        if key == 'Per periodo':\n",
    "            print(\"X: {}\".format(X_train.head()))\n",
    "            print(\"y: {}\".format(y_train.head()))\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X).squeeze()\n",
    "        predictions_test = model.predict(X_test)\n",
    "        rmse = np.sqrt(MSE(y_test, predictions_test))\n",
    "        splits[key]['rmse'] = rmse\n",
    "        splits[key]['r2'] = r2_score(y_test, predictions_test)\n",
    "        splits[key]['model'] = model\n",
    "\n",
    "        df_preds = pd.DataFrame({'y_hat': predictions, 'Date': dates, 'Regione': regions_df})\n",
    "        df_preds = df_preds.set_index(['Date', 'Regione'])\n",
    "\n",
    "        splits[key]['results'] = pd.merge(y, df_preds, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_splits:\n",
    "    name = \"Random Forest\"\n",
    "    external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "    app_timeseries = JupyterDash(name, external_stylesheets=external_stylesheets)\n",
    "\n",
    "    regions_select = list(all_regions_prediction)\n",
    "    regions_select.append(\"Tutti\")\n",
    "\n",
    "    app_timeseries.layout = html.Div([\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Regione\",\n",
    "            dcc.Dropdown(id=\"regions\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in regions_select],\n",
    "                        value=\"Lombardia\",\n",
    "                        multi=True,\n",
    "                        clearable=True)\n",
    "        ],\n",
    "    ),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Tipologia plot\",\n",
    "            dcc.Dropdown(id=\"plot_type\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in [\"Timeseries\", \"Errore assoluto\", \"RMSE\", \"R2\"]],\n",
    "                        value=\"Timeseries\",\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Tipologia split\",\n",
    "            dcc.Dropdown(id=\"split_type\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in list(splits.keys())],\n",
    "                        value=list(splits.keys())[1],\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "\n",
    "        html.Label(\n",
    "                    [\"Rolling average window \",\n",
    "                    html.Br(),\n",
    "                    dcc.Input(\n",
    "                        id='rolling_avg',\n",
    "                        type='number',\n",
    "                        value=1\n",
    "                    )]\n",
    "        ),\n",
    "    html.Div(dcc.Graph(id=name))])\n",
    "\n",
    "    @app_timeseries.callback(\n",
    "    Output(name, \"figure\"), \n",
    "    [Input(\"regions\", \"value\"), Input(\"plot_type\", \"value\"), Input(\"split_type\", \"value\"), Input(\"rolling_avg\", \"value\")])\n",
    "    def display_rf_results(regions, plot_type, split_type, roll_avg):\n",
    "\n",
    "        if isinstance(regions, str):\n",
    "            regions = [regions]\n",
    "\n",
    "        if regions is None:\n",
    "            regions = ['Tutti']\n",
    "\n",
    "        if plot_type is None:\n",
    "            plot_type = \"Timeseries\"\n",
    "\n",
    "        if roll_avg is None or roll_avg <= 0:\n",
    "            roll_avg = 1\n",
    "\n",
    "        if \"Tutti\" in regions:\n",
    "            regions = all_regions_prediction\n",
    "        \n",
    "        if isinstance(splits[split_type]['results'], dict):\n",
    "            #print(\"MEDIA\")\n",
    "            df_results = splits[split_type]['results']['mean']\n",
    "        else:\n",
    "            #print(\"NON MEDIA\")\n",
    "            df_results = splits[split_type]['results']\n",
    "\n",
    "        is_r2, is_rmse, is_timeseries, is_timeseries_error = plot_type == \"R2\", plot_type == \"RMSE\", plot_type == \"Timeseries\", plot_type == \"Errore assoluto\"\n",
    "\n",
    "        R_colors = px.colors.qualitative.Dark24#['#FF0000', '#f56342', '#f57e42', '#f59642', '#f5a742', '#F6DE43', '#EF42D8', '#FA5F8D', '#D0114A']\n",
    "        y_hat_colors = px.colors.qualitative.Alphabet#['#0000FF', '#0062ff', '#008cff', '#00b3ff', '#00b7e0', '#00F572', '#01CA5F', '#02DEB2', '#011ABC']\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "\n",
    "        for i, r in enumerate(regions):\n",
    "\n",
    "            current_df_results = df_results[df_results.index.get_level_values(1) == r]\n",
    "            current_df_results_so = current_df_results[current_df_results.index.get_level_values(0) >= divider_so]\n",
    "            x_vals_so = current_df_results_so.index.get_level_values(0)\n",
    "\n",
    "            if current_df_results_so.shape[0] > 0:\n",
    "                error_so = np.abs(current_df_results_so['R_mean']-current_df_results_so['y_hat'])\n",
    "                \n",
    "                if is_timeseries_error:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=error_so,\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                    # TODO draw lines\n",
    "                    #fig.update_yaxes(range=[0, 1])\n",
    "                elif is_rmse or is_r2:\n",
    "                    if is_rmse:\n",
    "                        constant_so = np.sqrt(MSE(current_df_results_so['R_mean'], current_df_results_so['y_hat']))\n",
    "                    else:\n",
    "                        constant_so = r2_score(current_df_results_so['R_mean'], current_df_results_so['y_hat'])\n",
    "                    \n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                                x=x_vals_so,\n",
    "                                y=np.repeat(constant_so, len(x_vals_so)),\n",
    "                                name=\"Y - {}\".format(r),\n",
    "                                marker=dict(\n",
    "                                    color=y_hat_colors[i]\n",
    "                                ),\n",
    "                                showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=current_df_results_so['R_mean'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=current_df_results_so['y_hat'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y_hat - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=y_hat_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "\n",
    "        # Add figure title\n",
    "        fig.update_layout(\n",
    "            title_text=\"{} vs {}\".format(trafficKPI, covidKPI)\n",
    "        )\n",
    "\n",
    "        for dateRange in ranges_train:\n",
    "            fig = fill_with_areas(dateRange, fig, True)\n",
    "            \n",
    "        #for dateRange in ranges_test:\n",
    "        #    fig = fill_with_areas(dateRange, fig, False)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    #app_timeseries = build_app_timeseries(df_traffic_daily_SO, df_covid_SO)\n",
    "    app_timeseries.run_server(mode='inline', port=46002) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if do_splits:\n",
    "    name = \"Random Forest\"\n",
    "    external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "    app_timeseries = JupyterDash(name, external_stylesheets=external_stylesheets)\n",
    "\n",
    "    regions_select = list(all_regions_prediction)\n",
    "    regions_select.append(\"Tutti\")\n",
    "\n",
    "    app_timeseries.layout = html.Div([\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Regione\",\n",
    "            dcc.Dropdown(id=\"regions\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in regions_select],\n",
    "                        value=\"Lombardia\",\n",
    "                        multi=True,\n",
    "                        clearable=True)\n",
    "        ],\n",
    "    ),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Tipologia plot\",\n",
    "            dcc.Dropdown(id=\"plot_type\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in [\"Timeseries\", \"Errore assoluto\", \"RMSE\", \"R2\"]],\n",
    "                        value=\"Timeseries\",\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Tipologia split\",\n",
    "            dcc.Dropdown(id=\"split_type\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in list(splits.keys())],\n",
    "                        value=list(splits.keys())[1],\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "\n",
    "        html.Label(\n",
    "                    [\"Rolling average window \",\n",
    "                    html.Br(),\n",
    "                    dcc.Input(\n",
    "                        id='rolling_avg',\n",
    "                        type='number',\n",
    "                        value=1\n",
    "                    )]\n",
    "        ),\n",
    "    html.Div(dcc.Graph(id=name))])\n",
    "\n",
    "    @app_timeseries.callback(\n",
    "    Output(name, \"figure\"), \n",
    "    [Input(\"regions\", \"value\"), Input(\"plot_type\", \"value\"), Input(\"split_type\", \"value\"), Input(\"rolling_avg\", \"value\")])\n",
    "    def display_rf_results(regions, plot_type, split_type, roll_avg):\n",
    "\n",
    "        if isinstance(regions, str):\n",
    "            regions = [regions]\n",
    "\n",
    "        if regions is None:\n",
    "            regions = ['Tutti']\n",
    "\n",
    "        if plot_type is None:\n",
    "            plot_type = \"Timeseries\"\n",
    "\n",
    "        if roll_avg is None or roll_avg <= 0:\n",
    "            roll_avg = 1\n",
    "\n",
    "        if \"Tutti\" in regions:\n",
    "            regions = all_regions_prediction\n",
    "        \n",
    "        if isinstance(splits[split_type]['results'], dict):\n",
    "            #print(\"MEDIA\")\n",
    "            df_results = splits[split_type]['results']['mean']\n",
    "        else:\n",
    "            #print(\"NON MEDIA\")\n",
    "            df_results = splits[split_type]['results']\n",
    "\n",
    "        is_r2, is_rmse, is_timeseries, is_timeseries_error = plot_type == \"R2\", plot_type == \"RMSE\", plot_type == \"Timeseries\", plot_type == \"Errore assoluto\"\n",
    "\n",
    "        R_colors = px.colors.qualitative.Dark24#['#FF0000', '#f56342', '#f57e42', '#f59642', '#f5a742', '#F6DE43', '#EF42D8', '#FA5F8D', '#D0114A']\n",
    "        y_hat_colors = px.colors.qualitative.Alphabet#['#0000FF', '#0062ff', '#008cff', '#00b3ff', '#00b7e0', '#00F572', '#01CA5F', '#02DEB2', '#011ABC']\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "\n",
    "        for i, r in enumerate(regions):\n",
    "\n",
    "            current_df_results = df_results[df_results.index.get_level_values(1) == r]\n",
    "            current_df_results_po = current_df_results[current_df_results.index.get_level_values(0) < divider_po]\n",
    "            current_df_results_so = current_df_results[current_df_results.index.get_level_values(0) >= divider_so]\n",
    "            x_vals_po, x_vals_so = current_df_results_po.index.get_level_values(0), current_df_results_so.index.get_level_values(0)\n",
    "\n",
    "            if current_df_results_po.shape[0] > 0 and current_df_results_so.shape[0] > 0:\n",
    "                error_po = np.abs(current_df_results_po['R_mean']-current_df_results_po['y_hat'])\n",
    "                error_so = np.abs(current_df_results_so['R_mean']-current_df_results_so['y_hat'])\n",
    "                \n",
    "                if is_timeseries_error:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_po,\n",
    "                            y=error_po,\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=error_so,\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                    # TODO draw lines\n",
    "                    #fig.update_yaxes(range=[0, 1])\n",
    "                elif is_rmse or is_r2:\n",
    "                    if is_rmse:\n",
    "                        constant_po, constant_so = np.sqrt(MSE(current_df_results_po['R_mean'], current_df_results_po['y_hat'])), np.sqrt(MSE(current_df_results_so['R_mean'], current_df_results_so['y_hat']))\n",
    "                    else:\n",
    "                        constant_po, constant_so = r2_score(current_df_results_po['R_mean'], current_df_results_po['y_hat']), r2_score(current_df_results_so['R_mean'], current_df_results_so['y_hat'])\n",
    "                    \n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                                x=x_vals_po,\n",
    "                                y=np.repeat(constant_po, len(x_vals_po)),\n",
    "                                name=\"RMSE {}\".format(r),\n",
    "                                marker=dict(\n",
    "                                    color=y_hat_colors[i]\n",
    "                                ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                                x=x_vals_so,\n",
    "                                y=np.repeat(constant_so, len(x_vals_so)),\n",
    "                                name=\"Y - {}\".format(r),\n",
    "                                marker=dict(\n",
    "                                    color=y_hat_colors[i]\n",
    "                                ),\n",
    "                                showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_po,\n",
    "                            y=current_df_results_po['R_mean'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_po,\n",
    "                            y=current_df_results_po['y_hat'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y_hat - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=y_hat_colors[i]\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=current_df_results_so['R_mean'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=current_df_results_so['y_hat'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y_hat - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=y_hat_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "\n",
    "        # Add figure title\n",
    "        fig.update_layout(\n",
    "            title_text=\"{} vs {}\".format(trafficKPI, covidKPI)\n",
    "        )\n",
    "\n",
    "        for dateRange in ranges_train:\n",
    "            fig = fill_with_areas(dateRange, fig, True)\n",
    "            \n",
    "        #for dateRange in ranges_test:\n",
    "        #    fig = fill_with_areas(dateRange, fig, False)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    #app_timeseries = build_app_timeseries(df_traffic_daily_SO, df_covid_SO)\n",
    "    app_timeseries.run_server(mode='inline', port=46000) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[features], df[targets]\n",
    "\n",
    "dates, regions_df = X.reset_index()['Date'], X.reset_index()['Regione']\n",
    "do_splits = True\n",
    "min_lag, max_lag = -5, 5  # wrt current shift; so we are predicting output in range (shift+min_lag, shift+max_lag)\n",
    "lag_outputs = range(min_lag, max_lag)\n",
    "if do_splits:\n",
    "    is_rf = False\n",
    "    is_gbr = False\n",
    "    is_gaussian = False\n",
    "    is_linear = False\n",
    "    is_mlp = True\n",
    "    all_regions_prediction = regions\n",
    "    dict_regions = {region: i for i, region in enumerate(all_regions_prediction)}\n",
    "\n",
    "    splits = {'Random': {}, 'Per periodo': {}, 'Per regione': {}}\n",
    "\n",
    "    splits['Random']['X_train'], splits['Random']['X_test'], splits['Random']['y_train'], splits['Random']['y_test'] = \\\n",
    "                train_test_split(X, y, test_size = 0.3, random_state = 123)   \n",
    "    splits['Random']['X'] = X.copy()\n",
    "    \n",
    "    splits['Per periodo']['X'] = X.copy()\n",
    "    idxs_train, idxs_test = X.index.get_level_values(0).intersection(pd.Series(train_dates)), X.index.get_level_values(0).intersection(pd.Series(test_dates))\n",
    "    splits['Per periodo']['X_train'], splits['Per periodo']['X_test'], splits['Per periodo']['y_train'], \\\n",
    "        splits['Per periodo']['y_test'] = X.loc[idxs_train], X.loc[idxs_test], y.loc[idxs_train], y.loc[idxs_test]\n",
    "   \n",
    "    splits['Per periodo']['X_train']['Regione'], splits['Per periodo']['X_test']['Regione'] = [dict_regions[r] for r in splits['Per periodo']['X_train'].index.get_level_values(1).to_list()], [dict_regions[r] for r in splits['Per periodo']['X_test'].index.get_level_values(1).to_list()]\n",
    "    \n",
    "    splits['Per periodo']['X']['Regione']=[dict_regions[r] for r in X.index.get_level_values(1).to_list()]\n",
    "\n",
    "    regions_train, regions_test = train_test_split(all_regions_prediction, test_size = 0.3, random_state = 1)\n",
    "    idx_train, idx_test = X.index.get_level_values(1).isin(regions_train), X.index.get_level_values(1).isin(regions_test)\n",
    "    splits['Per regione']['X_train'], splits['Per regione']['X_test'], splits['Per regione']['y_train'], splits['Per regione']['y_test'] = \\\n",
    "        X[idx_train], X[idx_test], y[idx_train], y[idx_test]\n",
    "    \n",
    "    splits['Per regione']['X'] = X.copy()\n",
    "    \n",
    "    for key in splits.keys():\n",
    "        if is_rf:\n",
    "            models = [RandomForestRegressor(n_estimators=200) for _ in lag_outputs]\n",
    "        elif is_gbr:\n",
    "            models = [XGBRegressor() for _ in lag_outputs]\n",
    "        elif is_gaussian:\n",
    "            models = [GaussianProcessRegressor() for _ in lag_outputs]\n",
    "        elif is_mlp:\n",
    "            models = [MLPRegressor(hidden_layer_sizes=(64, 32)) for _ in lag_outputs]\n",
    "        else:\n",
    "            models = [LinearRegression() for _ in lag_outputs]\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = splits[key]['X_train'], splits[key]['X_test'], splits[key]['y_train'], splits[key]['y_test']\n",
    "        X = splits[key]['X']\n",
    "        splits[key]['models'] = []\n",
    "        splits[key]['rmse'] = []\n",
    "        splits[key]['results'] = {}\n",
    "        df_all_results = []\n",
    "        for i, lag in enumerate(lag_outputs):\n",
    "            current_y = y_train.groupby('Regione').shift(lag)#.sort_values(by='Date')\n",
    "            current_X = X_train.copy()#.sort_values(by='Date')\n",
    "            #current_X = current_X.loc[current_X.index.intersection(current_y.index)]\n",
    "            #current_X, current_y = current_X.dropna(), current_y.dropna()\n",
    "            #print(current_X.shape, current_y.shape)\n",
    "            models[i].fit(current_X, current_y)\n",
    "            predictions = models[i].predict(X).squeeze()\n",
    "            rmse = np.sqrt(MSE(y_test, models[i].predict(X_test)))\n",
    "            splits[key]['rmse'].append(rmse)\n",
    "\n",
    "            df_preds = pd.DataFrame({'y_hat': predictions, 'Date': dates, 'Regione': regions_df})\n",
    "            df_preds['lag'] = lag\n",
    "            df_preds = df_preds.set_index(['lag', 'Date', 'Regione'])\n",
    "            df_all_results.append(df_preds)\n",
    "        \n",
    "        splits[key]['models'] = models\n",
    "        splits[key]['results']['all_results'] = pd.concat(df_all_results)\n",
    "        #print(splits[key]['results']['all_results'].loc[(splits[key]['results']['all_results'].index.get_level_values(1)==pd.to_datetime('2020-10-01')) & (splits[key]['results']['all_results'].index.get_level_values(2)=='Lombardia')])\n",
    "        #splits[key]['all_results'] = df_all_results\n",
    "        # TODO dovrebbe già ignorare i nan\n",
    "        df_preds = splits[key]['results']['all_results'].groupby(['Date', 'Regione']).mean()#.set_index(['Date', 'Regione'])\n",
    "        #print(df_preds.loc[(df_preds.index.get_level_values(0)==pd.to_datetime('2020-10-01')) & (df_preds.index.get_level_values(1)=='Lombardia')])\n",
    "        #print(y.shape, df_preds.shape)\n",
    "        splits[key]['results']['mean'] = pd.merge(y, df_preds, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_splits:\n",
    "    name = \"Random Forest\"\n",
    "    external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "    app_timeseries = JupyterDash(name, external_stylesheets=external_stylesheets)\n",
    "\n",
    "    regions_select = list(all_regions_prediction)\n",
    "    regions_select.append(\"Tutti\")\n",
    "\n",
    "    app_timeseries.layout = html.Div([\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Regione\",\n",
    "            dcc.Dropdown(id=\"regions\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in regions_select],\n",
    "                        value=\"Lombardia\",\n",
    "                        multi=True,\n",
    "                        clearable=True)\n",
    "        ],\n",
    "    ),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Tipologia plot\",\n",
    "            dcc.Dropdown(id=\"plot_type\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in [\"Timeseries\", \"Errore assoluto\", \"RMSE\"]],\n",
    "                        value=\"Timeseries\",\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Tipologia split\",\n",
    "            dcc.Dropdown(id=\"split_type\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in list(splits.keys())],\n",
    "                        value=list(splits.keys())[1],\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "\n",
    "        html.Label(\n",
    "                    [\"Rolling average window \",\n",
    "                    html.Br(),\n",
    "                    dcc.Input(\n",
    "                        id='rolling_avg',\n",
    "                        type='number',\n",
    "                        value=1\n",
    "                    )]\n",
    "        ),\n",
    "    html.Div(dcc.Graph(id=name))])\n",
    "\n",
    "    @app_timeseries.callback(\n",
    "    Output(name, \"figure\"), \n",
    "    [Input(\"regions\", \"value\"), Input(\"plot_type\", \"value\"), Input(\"split_type\", \"value\"), Input(\"rolling_avg\", \"value\")])\n",
    "    def display_rf_results(regions, plot_type, split_type, roll_avg):\n",
    "\n",
    "        if isinstance(regions, str):\n",
    "            regions = [regions]\n",
    "\n",
    "        if regions is None:\n",
    "            regions = ['Tutti']\n",
    "\n",
    "        if plot_type is None:\n",
    "            plot_type = \"Timeseries\"\n",
    "\n",
    "        if roll_avg is None or roll_avg <= 0:\n",
    "            roll_avg = 1\n",
    "\n",
    "        if \"Tutti\" in regions:\n",
    "            regions = all_regions_prediction\n",
    "        \n",
    "        if isinstance(splits[split_type]['results'], dict):\n",
    "            print(\"MEDIA\")\n",
    "            df_results = splits[split_type]['results']['mean']\n",
    "        else:\n",
    "            print(\"NON MEDIA\")\n",
    "            df_results = splits[split_type]['results']\n",
    "\n",
    "        is_rmse, is_timeseries, is_timeseries_error = plot_type == \"RMSE\", plot_type == \"Timeseries\", plot_type == \"Errore assoluto\"\n",
    "\n",
    "        R_colors = px.colors.qualitative.Dark24#['#FF0000', '#f56342', '#f57e42', '#f59642', '#f5a742', '#F6DE43', '#EF42D8', '#FA5F8D', '#D0114A']\n",
    "        y_hat_colors = px.colors.qualitative.Alphabet#['#0000FF', '#0062ff', '#008cff', '#00b3ff', '#00b7e0', '#00F572', '#01CA5F', '#02DEB2', '#011ABC']\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "\n",
    "        for i, r in enumerate(regions):\n",
    "\n",
    "            current_df_results = df_results[df_results.index.get_level_values(1) == r]\n",
    "            current_df_results_po = current_df_results[current_df_results.index.get_level_values(0) < divider_po]\n",
    "            current_df_results_so = current_df_results[current_df_results.index.get_level_values(0) >= divider_so]\n",
    "            x_vals_po, x_vals_so = current_df_results_po.index.get_level_values(0), current_df_results_so.index.get_level_values(0)\n",
    "\n",
    "            if current_df_results_po.shape[0] > 0 and current_df_results_so.shape[0] > 0:\n",
    "                error_po = np.abs(current_df_results_po['R_mean']-current_df_results_po['y_hat'])\n",
    "                error_so = np.abs(current_df_results_so['R_mean']-current_df_results_so['y_hat'])\n",
    "                rmse_po, rmse_so = np.sqrt(MSE(current_df_results_po['R_mean'], current_df_results_po['y_hat'])), np.sqrt(MSE(current_df_results_so['R_mean'], current_df_results_so['y_hat']))\n",
    "\n",
    "                if is_timeseries_error:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_po,\n",
    "                            y=error_po,\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=error_so,\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                    # TODO draw lines\n",
    "                    #fig.update_yaxes(range=[0, 1])\n",
    "                elif is_rmse:\n",
    "\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                                x=x_vals_po,\n",
    "                                y=np.repeat(rmse_po, len(x_vals_po)),\n",
    "                                name=\"RMSE {}\".format(r),\n",
    "                                marker=dict(\n",
    "                                    color=y_hat_colors[i]\n",
    "                                ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                                x=x_vals_so,\n",
    "                                y=np.repeat(rmse_so, len(x_vals_so)),\n",
    "                                name=\"Y - {}\".format(r),\n",
    "                                marker=dict(\n",
    "                                    color=y_hat_colors[i]\n",
    "                                ),\n",
    "                                showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_po,\n",
    "                            y=current_df_results_po['R_mean'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_po,\n",
    "                            y=current_df_results_po['y_hat'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y_hat - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=y_hat_colors[i]\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=current_df_results_so['R_mean'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=R_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_vals_so,\n",
    "                            y=current_df_results_so['y_hat'].rolling(roll_avg).mean(),\n",
    "                            name=\"Y_hat - {}\".format(r),\n",
    "                            marker=dict(\n",
    "                                color=y_hat_colors[i]\n",
    "                            ),\n",
    "                            showlegend=False,\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "\n",
    "        # Add figure title\n",
    "        fig.update_layout(\n",
    "            title_text=\"{} vs {}\".format(trafficKPI, covidKPI)\n",
    "        )\n",
    "\n",
    "        for dateRange in ranges_train:\n",
    "            fig = fill_with_areas(dateRange, fig, True)\n",
    "            \n",
    "        #for dateRange in ranges_test:\n",
    "        #    fig = fill_with_areas(dateRange, fig, False)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    #app_timeseries = build_app_timeseries(df_traffic_daily_SO, df_covid_SO)\n",
    "    app_timeseries.run_server(mode='inline', port=46000) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO provare senza meteo -> peggiora\n",
    "# TODO provare senza mobilità -> ovviamente peggiora\n",
    "# TODO provare a fornire una serie di dati di traffico (ultimi 10 istanti, non solo quello di 15 giorni prima) -> migliora\n",
    "# TODO provare a fornire dati di covid in input -> migliora\n",
    "# TODO aggiungere altre regioni -> ok\n",
    "# TODO generalization over PO - SO: give region in input as categorical -> OK\n",
    "# TODO try more models: SVM, Polynomial, MLP\n",
    "# TODO try with rolling avg as target\n",
    "# TODO get temperatures for rest of regions\n",
    "# TODO try more COVID features\n",
    "# TODO select best lag interval for features -> cross-validation\n",
    "# TODO validate r_mean values eventually checking other methodologies\n",
    "# TODO classification into zone (gialla, arancio, rossa) -> \n",
    "# -> parlare con Andrea\n",
    "# rolling av = 3 before training ->\n",
    "# TODO correlation with R_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits['Per periodo']['X'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits['Per periodo']['model'].get_score(importance_type='gain')\n",
    "importances = splits['Per periodo']['model'].feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in splits['Per periodo']['model'].estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "indices = indices[:30]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(splits['Per periodo']['X'].shape[1]):\n",
    "    pass# print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], splits['Per periodo']['X'].columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices)), [splits['Per periodo']['X_train'].columns[i]for i in indices], rotation='vertical')\n",
    "#plt.xlim([-1, X.shape[1]+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_rf = True\n",
    "is_gbr = False\n",
    "is_gaussian = False\n",
    "is_linear = False\n",
    "\n",
    "\n",
    "X, y = df[features], df[targets]\n",
    "\n",
    "dates, regions_df = X.reset_index()['Date'], X.reset_index()['Regione']\n",
    "all_regions_prediction = df_temperature['Regione'].unique()\n",
    "dict_regions = {region: i for i, region in enumerate(all_regions_prediction)}\n",
    "\n",
    "# TODO ora plotto semplicemente per regione. Sarebbe figo testare la validità quando generalizzando sulle regioni, oppure sul periodo prendendo prima ondata per tutte\n",
    "splits = {'Random': {}, 'Per periodo': {}, 'Per regione': {}}\n",
    "\n",
    "splits['Random']['X_train'], splits['Random']['X_test'], splits['Random']['y_train'], splits['Random']['y_test'] = \\\n",
    "            train_test_split(X, y, test_size = 0.3, random_state = 123)   \n",
    "splits['Random']['X'] = X.copy()\n",
    "\n",
    "splits['Per periodo']['X_train'], splits['Per periodo']['X_test'], splits['Per periodo']['y_train'], splits['Per periodo']['y_test'] = X[(divider_train_start<=X.index.get_level_values(0)) & (X.index.get_level_values(0)< divider_train_end)], X[X.index.get_level_values(0)>=divider_train_end], y[(divider_train_start<=y.index.get_level_values(0)) & (y.index.get_level_values(0)< divider_train_end)], y[y.index.get_level_values(0)>=divider_train_end]\n",
    "splits['Per periodo']['X'] = X.copy()\n",
    "splits['Per periodo']['X_train']['Regione'], splits['Per periodo']['X_test']['Regione'] = [dict_regions[r] for r in splits['Per periodo']['X_train'].index.get_level_values(1).to_list()], [dict_regions[r] for r in splits['Per periodo']['X_test'].index.get_level_values(1).to_list()]\n",
    "splits['Per periodo']['X']['Regione']=[dict_regions[r] for r in X.index.get_level_values(1).to_list()]\n",
    "\n",
    "regions_train, regions_test = train_test_split(all_regions_prediction, test_size = 0.3, random_state = 1)\n",
    "idx_train, idx_test = X.index.get_level_values(1).isin(regions_train), X.index.get_level_values(1).isin(regions_test)\n",
    "splits['Per regione']['X_train'], splits['Per regione']['X_test'], splits['Per regione']['y_train'], splits['Per regione']['y_test'] = \\\n",
    "    X[idx_train], X[idx_test], y[idx_train], y[idx_test]\n",
    "#splits['Per regione']['X_train']['Regione'], splits['Per regione']['X_test']['Regione'] = [dict_regions[r] for r in splits['Per regione']['X_train'].index.get_level_values(1).to_list()], [dict_regions[r] for r in splits['Per regione']['X_test'].index.get_level_values(1).to_list()]\n",
    "splits['Per regione']['X'] = X.copy()\n",
    "#splits['Per regione']['X']['Regione'] = [dict_regions[r] for r in X.index.get_level_values(1).to_list()]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    for key in splits.keys():\n",
    "        if is_rf:\n",
    "            model = RandomForestRegressor(n_estimators=200)\n",
    "        elif is_gbr:\n",
    "            model = XGBRegressor()\n",
    "        elif is_gaussian:\n",
    "            model = GaussianProcessRegressor()\n",
    "        else:\n",
    "            model = LinearRegression()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = splits[key]['X_train'], splits[key]['X_test'], splits[key]['y_train'], splits[key]['y_test']\n",
    "        X = splits[key]['X']\n",
    "        #print(X_train.shape, X_test.shape, X.shape)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X).squeeze()\n",
    "        rmse = np.sqrt(MSE(y_test, model.predict(X_test)))\n",
    "        splits[key]['rmse'] = rmse\n",
    "        splits[key]['model'] = model\n",
    "\n",
    "        df_preds = pd.DataFrame({'y_hat': predictions, 'Date': dates, 'Regione': regions_df})\n",
    "        df_preds = df_preds.set_index(['Date', 'Regione'])\n",
    "\n",
    "        splits[key]['results'] = pd.merge(y, df_preds, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['Regione'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates, regions_df = X.reset_index()['Date'], X.reset_index()['Regione']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_splits = True\n",
    "if do_splits:\n",
    "\n",
    "    \n",
    "    all_regions_prediction = regions\n",
    "    dict_regions = {region: i for i, region in enumerate(all_regions_prediction)}\n",
    "\n",
    "    splits = {'Per periodo': {}}\n",
    "    # 01/10 -> 31/01/2021\n",
    "    # 01/10 -> 31/12 -> 07/10: X = 06, 05, 04, 03, 02, 01 -> model.fit(X,y)\n",
    "    # -> amIDuringTrain -> +=1 + loop train \n",
    "    # -> otherwise -> X = {05, 04}... U {predicted} + loop train\n",
    "\n",
    "    idxs_train, idxs_test = X.index.get_level_values(0).intersection(pd.Series(train_dates)), X.index.get_level_values(0).intersection(pd.Series(test_dates))\n",
    "    splits['Per periodo']['X_train'], splits['Per periodo']['X_test'], splits['Per periodo']['y_train'], \\\n",
    "        splits['Per periodo']['y_test'] = X.loc[idxs_train], X.loc[idxs_test], y.loc[idxs_train], y.loc[idxs_test]\n",
    "   \n",
    "    splits['Per periodo']['X'] = X.copy()\n",
    "    splits['Per periodo']['X_train']['Regione'], splits['Per periodo']['X_test']['Regione'] = [dict_regions[r] for r in splits['Per periodo']['X_train'].index.get_level_values(1).to_list()], [dict_regions[r] for r in splits['Per periodo']['X_test'].index.get_level_values(1).to_list()]\n",
    "    \n",
    "    splits['Per periodo']['X']['Regione']=[dict_regions[r] for r in X.index.get_level_values(1).to_list()]\n",
    "\n",
    "    for key in splits.keys():\n",
    "        model = XGBRegressor()\n",
    "\n",
    "        #X_train, X_test, y_train, y_test = splits[key]['X_train'], splits[key]['X_test'], splits[key]['y_train'], splits[key]['y_test']\n",
    "        current_X = splits[key]['X']\n",
    "        current_y = y.copy()\n",
    "        #current_y = splits[key]['y']\n",
    "        #print(X_train.shape, X_test.shape, X.shape)\n",
    "        #model.fit(X_train, y_train)\n",
    "        start = 7\n",
    "        current_X['error_last_week'] = np.nan\n",
    "        start_date, end_date = X.index.get_level_values(0).min(), X.index.get_level_values(0).max()\n",
    "        ranges = pd.date_range(start_date, end_date, freq=\"14D\")[1:]\n",
    "        \n",
    "        # i = 1: current_train_y = y[i-1]\n",
    "        # i = 1: current_X -> error y[i]\n",
    "        for date in ranges:\n",
    "            current_train_x, current_train_y = current_X.loc[current_X.index.get_level_values(0)<date], current_y.loc[current_y.index.get_level_values(0)<date]['R_mean']\n",
    "            previous_y = np.nan\n",
    "            #for idx in range(current_train_x.shape[0]):\n",
    "            #x_current, y_current = current_train_x.iloc[idx], current_train_y.iloc[idx]\n",
    "            #if previous_y is np.nan:\n",
    "            #    error = 0\n",
    "            #else:\n",
    "            #    error = previous_y - y_current\n",
    "            if date == ranges[0]:\n",
    "                y_hat = np.zeros(current_train_x.shape[0])\n",
    "            else:\n",
    "                #print(current_train_x['error'].isna().sum())\n",
    "                y_hat = model.predict(current_train_x)\n",
    "            # k = 1, 2, ..., -> \n",
    "            # t = tn, error??? e[n] = y[n]-y_hat[n], e[n] = y[n-week]-y_hat[n-week]\n",
    "            # \n",
    "            df_shift = pd.DataFrame({\"R_mean\":current_train_y})#current_train_y.copy()\n",
    "            df_shift['y_hat'] = y_hat\n",
    "            df_shift = df_shift.shift(7)\n",
    "            current_train_x['error_last_week'] = np.power(df_shift['R_mean'] - df_shift['y_hat'], 2)#np.power(current_train_y - y_hat, 2)#np.sqrt(MSE(current_train_y, y_hat))\n",
    "            model.fit(current_train_x, current_train_y)\n",
    "            current_X.loc[current_train_x['error_last_week'].index, 'error_last_week'] = current_train_x['error_last_week']\n",
    "            #last_error = current_train_x['error']\n",
    "            \n",
    "        '''\n",
    "        start_date, end_date = X_test.index.get_level_values(0).min(), X_test.index.get_level_values(0).max()\n",
    "        ranges = pd.date_range(start_date, end_date, freq=\"7D\")[1:]\n",
    "        \n",
    "        for date in ranges:\n",
    "            current_test_x = X_test.loc[X_test.index.get_level_values(0)<date]\n",
    "            last_week_errors = last_error.loc[last_error.index.get_level_values(0) > date - timedelta(days=7)]\n",
    "            current_test_x['error'] = last_week_errors\n",
    "            y_test = model.predict(current_test_x)\n",
    "            last_week_errors = y_test - \n",
    "            # previous_y = y_train#[-1]\n",
    "            # \n",
    "            #current_test_x['error'] = np.pow(current_train_y - y_hat, 2)\n",
    "            #y_hat = model.predict(current_test_x)\n",
    "            #current_train_x['error'] = current_train_y - y_hat\n",
    "            \n",
    "            for idx in range(current_train_x.shape[0]):\n",
    "                x_current = current_train_x[idx]\n",
    "                y_hat = model.predict(x_current)\n",
    "                error = previous_y - y_hat\n",
    "                x_current['error'] = error\n",
    "                model.fit(x_current, y_current)\n",
    "                previous_y = y_current\n",
    "            \n",
    "        '''\n",
    "        '''\n",
    "        predictions = model.predict(X).squeeze()\n",
    "        predictions_test = model.predict(X_test)\n",
    "        rmse = np.sqrt(MSE(y_test, predictions_test))\n",
    "        splits[key]['rmse'] = rmse\n",
    "        splits[key]['r2'] = r2_score(y_test, predictions_test)\n",
    "        splits[key]['model'] = model\n",
    "\n",
    "        df_preds = pd.DataFrame({'y_hat': predictions, 'Date': dates, 'Regione': regions_df})\n",
    "        df_preds = df_preds.set_index(['Date', 'Regione'])\n",
    "\n",
    "        splits[key]['results'] = pd.merge(y, df_preds, left_index=True, right_index=True)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(current_X)\n",
    "current_y[\"y_hat\"]=y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at time t: (state = {errors_from_last_week}, mobility_time_t_minus_7, ...) -> covid_time_t\n",
    "current_X.loc[current_X.index.get_level_values(0)>=pd.to_datetime('2021-01-19')]['error_last_week'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in regions:\n",
    "    df_region = current_y.xs(r, level=1)\n",
    "    predictions, real_values = df_region['y_hat'], df_region['R_mean']#.plot()\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "                x=df_region.index,\n",
    "                y=predictions,\n",
    "                line=dict(color='rgb(255,0,0)'),\n",
    "                mode='lines',\n",
    "                name=\"Prediction\"\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "                x=df_region.index,\n",
    "                y=real_values,\n",
    "                line=dict(color='rgb(0,0,255)'),\n",
    "                mode='lines',\n",
    "                name=\"Target\"\n",
    "            )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_X = splits[key]['X']\n",
    "current_y = y.copy()\n",
    "#model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_y['error'] = (current_y['R_mean'] - current_y['y_hat'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_y.loc[abs(current_y.error-0.003474) <= 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranges=ranges\n",
    "current_X_lombardia, current_y_lombardia = current_X.loc[current_X.index.get_level_values(1)==\"Lombardia\"], current_y.loc[current_y.index.get_level_values(1)==\"Lombardia\"]\n",
    "last_length = 0\n",
    "model = XGBRegressor()\n",
    "for i, date in enumerate(test_ranges):\n",
    "    current_train_x, current_train_y = current_X_lombardia.loc[current_X_lombardia.index.get_level_values(0)<date], current_y_lombardia.loc[current_y_lombardia.index.get_level_values(0)<date]['R_mean']\n",
    "    if current_train_x.shape[0] > last_length:\n",
    "        last_length = current_train_x.shape[0]\n",
    "        current_train_x.sort_index(level=0, inplace=True)\n",
    "        current_train_y.sort_index(level=0, inplace=True)\n",
    "        #for idx in range(current_train_x.shape[0]):\n",
    "        #x_current, y_current = current_train_x.iloc[idx], current_train_y.iloc[idx]\n",
    "        #if previous_y is np.nan:\n",
    "        #    error = 0\n",
    "        #else:\n",
    "        #    error = previous_y - y_current\n",
    "        print(\"{}/{} -> {}\".format(i+1, len(test_ranges), date))\n",
    "        if date == ranges[0]:\n",
    "            y_hat = np.zeros(current_train_x.shape[0])\n",
    "        else:\n",
    "            #print(current_train_x['error'].isna().sum())\n",
    "            y_hat = model.predict(current_train_x)\n",
    "        # k = 1, 2, ..., -> \n",
    "        # t = tn, error??? e[n] = y[n]-y_hat[n], e[n] = y[n-week]-y_hat[n-week]\n",
    "        # \n",
    "        df_shift = pd.DataFrame({\"R_mean\":current_train_y})#current_train_y.copy()\n",
    "        df_shift['y_hat'] = y_hat\n",
    "        df_shift = df_shift.shift(7)\n",
    "        #current_train_x['error_last_week'] = np.power(df_shift['R_mean'] - df_shift['y_hat'], 2)#np.power(current_train_y - y_hat, 2)#np.sqrt(MSE(current_train_y, y_hat))\n",
    "        model.fit(current_train_x, current_train_y)\n",
    "        #current_X_lombardia.loc[current_train_x['error_last_week'].index, 'error_last_week'] = current_train_x['error_last_week']\n",
    "\n",
    "        #print(\"Num. of Y hat: {}\".format(y_hat.shape))\n",
    "        #print(\"error_last_week: {}\".format(current_train_x['error_last_week'].index.get_level_values(0).max()))\n",
    "        #df_plot = pd.DataFrame({\"prediction\": y_hat, \"target\": current_train_y})\n",
    "\n",
    "        #predictions, real_values = df_region['y_hat'], df_region['R_mean']#.plot()\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                    x=current_train_y.index.get_level_values(0),\n",
    "                    y=y_hat,\n",
    "                    line=dict(color='rgb(255,0,0)'),\n",
    "                    mode='lines',\n",
    "                    name=\"Prediction\"\n",
    "                )\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                    x=current_train_y.index.get_level_values(0),\n",
    "                    y=current_train_y,\n",
    "                    line=dict(color='rgb(0,0, 255)'),\n",
    "                    mode='lines',\n",
    "                    name=\"Prediction\"\n",
    "                )\n",
    "        )\n",
    "        fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_X_lombardia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_X_lombardia, current_y_lombardia = X.loc[X.index.get_level_values(1)==\"Lombardia\"], y.loc[y.index.get_level_values(1)==\"Lombardia\"]\n",
    "last_length = 0\n",
    "\n",
    "current_X_lombardia = current_X_lombardia.sort_index()\n",
    "current_y_lombardia = current_y_lombardia.sort_index()\n",
    "\n",
    "train_dates, test_dates = [], []\n",
    "ranges_train_ts = [pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "\n",
    "for date_val in current_X_lombardia.index.get_level_values(0).unique():\n",
    "    if any(date_val in x for x in ranges_train_ts):\n",
    "        train_dates.append(date_val)\n",
    "    else:\n",
    "        test_dates.append(date_val)\n",
    "\n",
    "idxs_train, idxs_test = current_X_lombardia.index.get_level_values(0).intersection(pd.Series(train_dates)), current_X_lombardia.index.get_level_values(0).intersection(pd.Series(test_dates))\n",
    "\n",
    "X_train_lom, X_test_lom = current_X_lombardia.loc[idxs_train], current_X_lombardia.loc[idxs_test]\n",
    "y_train_lom = current_y_lombardia.loc[idxs_train]\n",
    "y_train_lom = y_train_lom.sort_index(level=0)\n",
    "X_train_lom = X_train_lom.sort_index(level=0)\n",
    "#print(X_train_lom.head())\n",
    "X_train_lom['Rmean_1'] = y_train_lom.shift(1)\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train_lom, y_train_lom)\n",
    "\n",
    "y_hat = model.predict(X_train_lom)\n",
    "\n",
    "df_plot = y_train_lom\n",
    "df_plot = df_plot.sort_index(level=0)\n",
    "df_plot['y_hat'] = y_hat\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "df_plot.sort_index(inplace=True)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "            x=df_plot.index.get_level_values(0),\n",
    "            y=df_plot['y_hat'],\n",
    "            line=dict(color='rgb(255,0,0)'),\n",
    "            mode='lines',\n",
    "            name=\"Prediction\"\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "            x=df_plot.index.get_level_values(0),\n",
    "            y=df_plot['R_mean'],\n",
    "            line=dict(color='rgb(0,0, 255)'),\n",
    "            mode='lines',\n",
    "            name=\"Real values\"\n",
    "        )\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "#test_dates = X_test_lom.index.get_level_values(0).sort_values()\n",
    "\n",
    "last_output = y_train_lom.xs(train_dates[-1], level=0)\n",
    "test_dates = [t for t in test_dates if t > divider_so]\n",
    "\n",
    "for date in test_dates:\n",
    "    current_X_test = X_test_lom.xs(date, level=0)\n",
    "    current_X_test['Rmean_1'] = last_output\n",
    "    #print(current_X_test)\n",
    "    prediction = model.predict(current_X_test)\n",
    "    y_hat = np.append(y_hat, prediction)\n",
    "    last_output = prediction\n",
    "    # now train \n",
    "    \n",
    "# X = {mobility_t_1, mobility_t_2, mobility_t_3, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_lom = current_y_lombardia.loc[idxs_test]\n",
    "#y_test_lom = y_test_lom.sort_index(level=0)\n",
    "#print(y_hat.shape, y_train_lom.shape, y_test_lom.shape)\n",
    "#print(y_train_lom.index.get_level_values(0))\n",
    "#print(pd.concat([y_train_lom.to_frame(), y_test_lom.to_frame()]))\n",
    "df_plot = current_y_lombardia.loc[current_y_lombardia.index.get_level_values(0) >= pd.to_datetime('2020-10-01')]\n",
    "df_plot = df_plot.sort_index(level=0)\n",
    "df_plot['y_hat'] = y_hat\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_rmse = min(test_dates)\n",
    "idx_rmse = df_plot.index.get_level_values(0) >= start_date_rmse\n",
    "RMSE = np.sqrt(MSE(df_plot.loc[idx_rmse, 'y_hat'], df_plot.loc[idx_rmse, 'R_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = r2_score(df_plot.loc[idx_rmse, 'y_hat'], df_plot.loc[idx_rmse, 'R_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "df_plot.sort_index(level=0, inplace=True)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "            x=df_plot.index.get_level_values(0),\n",
    "            y=df_plot['y_hat'],\n",
    "            line=dict(color='rgb(255,0,0)'),\n",
    "            mode='lines',\n",
    "            name=\"Prediction\"\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "            x=df_plot.index.get_level_values(0),\n",
    "            y=df_plot['R_mean'],\n",
    "            line=dict(color='rgb(0,0, 255)'),\n",
    "            mode='lines',\n",
    "            name=\"Real values\"\n",
    "        )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO non da risultati migliori; farlo su tutte le regioni? Bisogna cambiare il loop. Prima, fare train su tutte le regioni; poi fare il loop per regione\n",
    "# TODO fare training settimana per settimana in fase di testing, oltre che test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dates, test_dates = [], []\n",
    "ranges_train_ts = [pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "\n",
    "for date_val in current_X_lombardia.index.get_level_values(0).unique():\n",
    "    if any(date_val in x for x in ranges_train_ts):\n",
    "        train_dates.append(date_val)\n",
    "    else:\n",
    "        test_dates.append(date_val)\n",
    "\n",
    "idxs_train, idxs_test = current_X_lombardia.index.get_level_values(0).intersection(pd.Series(train_dates)), current_X_lombardia.index.get_level_values(0).intersection(pd.Series(test_dates))\n",
    "\n",
    "df_traffic_ts = df_traffic_predictions.loc[idxs_train.union(idxs_test)]\n",
    "df_covid_ts = df_covid_predictions.loc[idxs_train.union(idxs_test)]\n",
    "df_temperature_ts = df_temperature.loc[idxs_train.union(idxs_test)]\n",
    "# region\n",
    "df_traffic_ts = df_traffic_ts.loc[df_traffic_ts.index.get_level_values(1)==\"Lombardia\"]\n",
    "df_covid_ts = df_covid_ts.loc[df_covid_ts.index.get_level_values(1)==\"Lombardia\"]\n",
    "df_temperature_ts = df_temperature_ts.loc[df_temperature_ts.index.get_level_values(1)==\"Lombardia\"]\n",
    "#print(\"SHAPE: {}\".format(df_traffic_ts.shape))\n",
    "farsightness = 14\n",
    "delta_features = 14\n",
    "lags = range(delta_features) # 1 -> 0; 2 ->\n",
    "df_ts = pd.DataFrame()\n",
    "trafficKPIs = [col for col in df_traffic_ts.columns if \"smooth\" in col]\n",
    "covidKPIs = [col for col in df_covid_ts.columns if \"mean\" in col and \"delta\" not in col]\n",
    "temperatureKPIs = [col for col in df_temperature_ts.columns if \"min\" in col]\n",
    "features = []\n",
    "targets = []\n",
    "target_col = \"R_mean\"\n",
    "for lag in lags:\n",
    "    lag_shift = lag+1\n",
    "    for col in trafficKPIs:\n",
    "        feature = \"{}_{}\".format(col, lag_shift)\n",
    "        df_ts[feature] = df_traffic_ts.shift(lag_shift)[col]\n",
    "        features.append(feature)\n",
    "    for col in covidKPIs:\n",
    "        feature = \"{}_{}\".format(col, lag_shift)\n",
    "        df_ts[feature] = df_covid_ts.shift(lag_shift)[col]\n",
    "        features.append(feature)\n",
    "    for col in temperatureKPIs:\n",
    "        feature = \"{}_{}\".format(col, lag_shift)\n",
    "        df_ts[feature] = df_temperature_ts.shift(lag_shift)[col]\n",
    "        features.append(feature)\n",
    "    target = \"target_{}\".format(lag)\n",
    "    targets.append(target)\n",
    "    df_ts[target] = df_covid_ts.shift(-1*lag)[target_col]\n",
    "    \n",
    "df_ts.dropna(inplace=True)\n",
    "df_ts = df_ts.reset_index(level='Regione')\n",
    "df_ts = df_ts[targets+features]\n",
    "test_dates, train_dates = [], []\n",
    "for date_val in df_ts.index.unique():\n",
    "    if any(date_val in x for x in ranges_train_ts):\n",
    "        train_dates.append(date_val)\n",
    "    else:\n",
    "        test_dates.append(date_val)\n",
    "\n",
    "test_dates = [t for t in test_dates if t > divider_so]\n",
    "\n",
    "df_ts_train, df_ts_test = df_ts.loc[train_dates], df_ts.loc[test_dates]\n",
    "\n",
    "#print(\"TRAIN: \", df_ts_train.head(3))\n",
    "#print(\"TEST: \", df_ts_test.head(3))\n",
    "\n",
    "model = MultiOutputRegressor(XGBRegressor())#.fit(X, y)\n",
    "#df_ts_train = df_ts_train.resample('{}D'.format(farsightness))\n",
    "train_dates_every_n = pd.date_range(start=train_dates[0], end=train_dates[-1], freq=\"{}D\".format(farsightness))\n",
    "df_ts_train = df_ts_train.loc[train_dates_every_n]\n",
    "print(df_ts_train.head())\n",
    "model.fit(df_ts_train[features], df_ts_train[targets])\n",
    "\n",
    "y_hat = model.predict(df_ts_train[features])\n",
    "print(y_hat.shape)\n",
    "'''\n",
    "\n",
    "df_plot = y_train_lom\n",
    "df_plot = df_plot.sort_index(level=0)\n",
    "df_plot['y_hat'] = y_hat\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "df_plot.sort_index(inplace=True)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "            x=df_plot.index.get_level_values(0),\n",
    "            y=df_plot['y_hat'],\n",
    "            line=dict(color='rgb(255,0,0)'),\n",
    "            mode='lines',\n",
    "            name=\"Prediction\"\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "            x=df_plot.index.get_level_values(0),\n",
    "            y=df_plot['R_mean'],\n",
    "            line=dict(color='rgb(0,0, 255)'),\n",
    "            mode='lines',\n",
    "            name=\"Real values\"\n",
    "        )\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "#test_dates = X_test_lom.index.get_level_values(0).sort_values()\n",
    "\n",
    "last_output = y_train_lom.xs(train_dates[-1], level=0)\n",
    "\n",
    "for date in test_dates:\n",
    "    current_X_test = X_test_lom.xs(date, level=0)\n",
    "    current_X_test['Rmean_1'] = last_output\n",
    "    #print(current_X_test)\n",
    "    prediction = model.predict(current_X_test)\n",
    "    y_hat = np.append(y_hat, prediction)\n",
    "    last_output = prediction\n",
    "    # now train \n",
    "'''\n",
    "# X = {mobility_t_1, mobility_t_2, mobility_t_3, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_dates_every_n = pd.date_range(start=test_dates[0], end=test_dates[-1], freq=\"{}D\".format(farsightness))\n",
    "test_predictions = np.array([])\n",
    "for i, t in enumerate(test_dates_every_n):\n",
    "    if i < len(test_dates_every_n)-1:\n",
    "        next_t = test_dates_every_n[i+1]\n",
    "        print(\"{} -> {}\".format(t, next_t))\n",
    "        X_test_ts = df_ts_test.loc[t, features]\n",
    "        print(X_test_ts)\n",
    "        predictions = model.predict(X_test_ts.to_numpy().reshape(1, -1))\n",
    "        test_predictions = np.append(test_predictions, predictions)\n",
    "        # 2 weeks later: today = next_t\n",
    "        # dates_fit = pd.date_range(t, next_t)\n",
    "        # 2020-10-31 -> 2020-11-14\n",
    "        # 01/11: target = {01/11, 02/11, 03/11, ..., 14/11}\n",
    "        X_test_fit, y_test_fit = df_ts_test.loc[t, features], df_ts_test.loc[t, targets]\n",
    "        model.fit(X_test_fit.to_numpy().reshape(1, -1), y_test_fit.to_numpy().reshape(1,-1))\n",
    "        #X_test_fit, y_test_fit = df_ts_test.loc[dates_fit, features], df_ts_test.loc[dates_fit, targets]\n",
    "        #model.fit(X_test_fit, y_test_fit)\n",
    "        print(\"FIT ON {} -> {}; {}\".format(dates_fit[0], dates_fit[-1], X_test_fit.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on single region\n",
    "df_plot = pd.DataFrame({'target': df_ts_test.iloc[0:test_predictions.shape[0]]['target_0']})\n",
    "df_plot['y_hat'] = test_predictions\n",
    "df_plot['error'] = (df_plot['y_hat']-df_plot['target']).abs()\n",
    "print(np.sqrt(MSE(df_plot['y_hat'], df_plot['target'])))\n",
    "print(r2_score(df_plot['y_hat'], df_plot['target']))\n",
    "df_plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates, test_dates = [], []\n",
    "ranges_train_ts = [pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-12-01'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "\n",
    "model = MultiOutputRegressor(RandomForestRegressor())\n",
    "farsightness = 7\n",
    "delta_features = 7\n",
    "lags = range(delta_features)\n",
    "\n",
    "trafficKPIs = []#[col for col in df_traffic_predictions.columns if \"smooth\" in col]\n",
    "covidKPIs = [col for col in df_covid_predictions.columns if \"mean\" in col and \"delta\" not in col]\n",
    "temperatureKPIs = []# [col for col in df_temperature.columns if \"min\" in col]\n",
    "\n",
    "params = {'objective': 'reg:linear'}\n",
    "\n",
    "# train during PO\n",
    "train_also_PO = True\n",
    "if train_also_PO:\n",
    "    print(\"ALSO TRAIN DURING PO\")\n",
    "    for region in regions:\n",
    "        # filter ts by region\n",
    "        df_traffic_ts = df_traffic_predictions.loc[df_traffic_predictions.index.get_level_values(1)==region]\n",
    "        df_covid_ts = df_covid_predictions.loc[df_covid_predictions.index.get_level_values(1)==region]\n",
    "        df_temperature_ts = df_temperature.loc[df_temperature.index.get_level_values(1)==region]\n",
    "        # create dataframe with last values\n",
    "        df_ts = pd.DataFrame()\n",
    "        features = []\n",
    "        targets = []\n",
    "        target_col = \"R_mean\"\n",
    "        for lag in lags:\n",
    "            lag_shift = lag+1\n",
    "            for col in trafficKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_traffic_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            for col in covidKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_covid_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            for col in temperatureKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_temperature_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            target = \"target_{}\".format(lag)\n",
    "            targets.append(target)\n",
    "            df_ts[target] = df_covid_ts.shift(-1*lag)[target_col]\n",
    "\n",
    "        df_ts = df_ts[targets+features]\n",
    "        df_ts.dropna(inplace=True)\n",
    "        all_dfs.append(df_ts.copy())\n",
    "        df_ts = df_ts.reset_index(level='Regione')\n",
    "        test_dates, train_dates = [], []\n",
    "\n",
    "        for date_val in df_ts.index.unique():\n",
    "            if any(date_val in x for x in ranges_train_ts):\n",
    "                train_dates.append(date_val)\n",
    "\n",
    "        df_ts_train = df_ts.loc[train_dates]\n",
    "        xgtrain = xgb.DMatrix(train.values, target.values)\n",
    "        xgtest = xgb.DMatrix(test.values)\n",
    "        model.fit(df_ts_train[features], df_ts_train[targets])\n",
    "    \n",
    "# then during SO\n",
    "train_dates_region_every_n = {}\n",
    "test_dates_region_every_n = {}\n",
    "train_dates_region = {}\n",
    "test_dates_region = {}\n",
    "df_ts_test_region = {}\n",
    "all_dfs = []\n",
    "\n",
    "for region in regions:\n",
    "    # filter ts by region\n",
    "    df_traffic_ts = df_traffic_predictions.loc[df_traffic_predictions.index.get_level_values(1)==region]\n",
    "    df_covid_ts = df_covid_predictions.loc[df_covid_predictions.index.get_level_values(1)==region]\n",
    "    df_temperature_ts = df_temperature.loc[df_temperature.index.get_level_values(1)==region]\n",
    "    # create dataframe with last values\n",
    "    df_ts = pd.DataFrame()\n",
    "    features = []\n",
    "    targets = []\n",
    "    target_col = \"R_mean\"\n",
    "    for lag in lags:\n",
    "        lag_shift = lag+1\n",
    "        for col in trafficKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_traffic_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "        for col in covidKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_covid_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "        for col in temperatureKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_temperature_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "        target = \"target_{}\".format(lag)\n",
    "        targets.append(target)\n",
    "        df_ts[target] = df_covid_ts.shift(-1*lag)[target_col]\n",
    "\n",
    "    df_ts = df_ts[targets+features]\n",
    "    df_ts.dropna(inplace=True)\n",
    "    all_dfs.append(df_ts.copy())\n",
    "    df_ts = df_ts.reset_index(level='Regione')\n",
    "    test_dates, train_dates = [], []\n",
    "    \n",
    "    for date_val in df_ts.index.unique():\n",
    "        if any(date_val in x for x in ranges_train_ts):\n",
    "            train_dates.append(date_val)\n",
    "        else:\n",
    "            test_dates.append(date_val)\n",
    "\n",
    "    test_dates = [t for t in test_dates if t > divider_so]\n",
    "\n",
    "    df_ts_train, df_ts_test = df_ts.loc[train_dates], df_ts.loc[test_dates]\n",
    "    #print(\"BUILT DATASET: train = {}, test = {}\".format(df_ts_train.loc[train_dates[0], \"target_0\"], df_ts_test.loc[test_dates[0], \"R_mean_14\"]))\n",
    "\n",
    "    #print(\"TRAIN: \", df_ts_train.head(3))\n",
    "    #print(\"TEST: \", df_ts_test.head(3))\n",
    "\n",
    "    #df_ts_train = df_ts_train.resample('{}D'.format(farsightness))\n",
    "    #train_dates_every_n = pd.date_range(start=train_dates[0], end=train_dates[-1], freq=\"{}D\".format(farsightness))\n",
    "    #train_dates_region_every_n[region] = train_dates_every_n\n",
    "    test_dates_every_n = pd.date_range(start=test_dates[0], end=test_dates[-1], freq=\"{}D\".format(farsightness)).to_pydatetime()\n",
    "    test_dates_region_every_n[region] = test_dates_every_n\n",
    "    train_dates_region[region], test_dates_region[region] = train_dates, test_dates\n",
    "    df_ts_test_region[region] = df_ts_test\n",
    "    #df_ts_train = df_ts_train.loc[train_dates_every_n]\n",
    "    #print(df_ts_train.head())\n",
    "    model.fit(df_ts_train[features], df_ts_train[targets], xgb_model=model)\n",
    "    #model.train(params, df_ts_train,)\n",
    "    #model.partial_fit(df_ts_train[features], df_ts_train[targets])\n",
    "    \n",
    "# X = {mobility_t_1, mobility_t_2, mobility_t_3, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "\n",
    "for region in regions:\n",
    "    test_predictions_region = np.array([])\n",
    "    test_dates_every_n = test_dates_region_every_n[region]\n",
    "    df_ts_test = df_ts_test_region[region]\n",
    "    print(\"{}: {}\".format(region, df_ts_test.shape))\n",
    "    for i, t in enumerate(test_dates_every_n):\n",
    "        if i < len(test_dates_every_n)-1:\n",
    "            next_t = test_dates_every_n[i+1]\n",
    "            print(\"{}: {} -> {}\".format(region, t, next_t))\n",
    "            X_test_ts = df_ts_test.loc[t, features]\n",
    "            X_test_ts.sort_index(inplace=True)\n",
    "            predictions = model.predict(X_test_ts.to_numpy().reshape(1, -1))\n",
    "            test_predictions_region = np.append(test_predictions_region, predictions)\n",
    "            # 2 weeks later: today = next_t\n",
    "            dates_fit = pd.date_range(t, next_t)\n",
    "            # 2020-10-31 -> 2020-11-14\n",
    "            # 01/11: target = {01/11, 02/11, 03/11, ..., 14/11}\n",
    "            X_test_fit, y_test_fit = df_ts_test.loc[t, features], df_ts_test.loc[t, targets]\n",
    "            model.fit(X_test_fit.to_numpy().reshape(1, -1), y_test_fit.to_numpy().reshape(1,-1))\n",
    "            #X_test_fit, y_test_fit = df_ts_test.loc[dates_fit, features], df_ts_test.loc[dates_fit, targets]\n",
    "            #model.fit(X_test_fit, y_test_fit)\n",
    "            print(\"{}: FIT ON {} -> {}; {}\".format(region, dates_fit[0], dates_fit[-1], X_test_fit.shape))\n",
    "    test_predictions[region] = test_predictions_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on single region\n",
    "for region in regions:\n",
    "    current_df_ts_test = df_ts_test_region[region]\n",
    "    current_test_predictions = test_predictions[region]\n",
    "    df_plot = pd.DataFrame({'target': current_df_ts_test.iloc[0:current_test_predictions.shape[0]]['target_0']})\n",
    "    df_plot['y_hat'] = current_test_predictions\n",
    "    df_plot['error'] = (df_plot['y_hat']-df_plot['target']).abs()\n",
    "    rmse, r2 = np.sqrt(MSE(df_plot['y_hat'], df_plot['target'])), r2_score(df_plot['y_hat'], df_plot['target'])\n",
    "    df_plot.plot(title=\"{}: RMSE -> {}, R2 -> {}\".format(region, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates, test_dates = [], []\n",
    "ranges_train_ts = [pd.date_range(pd.to_datetime('2020-10-01'), pd.to_datetime('2020-12-01'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "\n",
    "farsightness = 6\n",
    "delta_features = 7\n",
    "lags = range(delta_features)\n",
    "lags_target = range(farsightness)\n",
    "\n",
    "trafficKPIs = [col for col in df_traffic_predictions.columns if \"smooth\" in col]\n",
    "covidKPIs = [col for col in df_covid_predictions.columns if \"mean\" in col and \"delta\" not in col]\n",
    "temperatureKPIs = []# [col for col in df_temperature.columns if \"min\" in col]\n",
    "\n",
    "params = {'objective': 'reg:squarederror'}\n",
    "\n",
    "regions_to_train = regions\n",
    "models_regions = {}\n",
    "\n",
    "# train during PO\n",
    "train_also_PO = True\n",
    "if train_also_PO:\n",
    "    print(\"ALSO TRAIN DURING PO\")\n",
    "    ranges_train_PO = [pd.date_range(pd.to_datetime('2020-03-01'), pd.to_datetime('2020-07-01'))]#, pd.date_range(pd.to_datetime('2020-11-01'), pd.to_datetime('2020-11-30'))]#, pd.date_range(pd.to_datetime('2020-12-01'), pd.to_datetime('2020-12-15'))]\n",
    "    for region in regions_to_train:\n",
    "        # filter ts by region\n",
    "        df_traffic_ts = df_traffic_predictions.loc[df_traffic_predictions.index.get_level_values(1)==region]\n",
    "        df_covid_ts = df_covid_predictions.loc[df_covid_predictions.index.get_level_values(1)==region]\n",
    "        df_temperature_ts = df_temperature.loc[df_temperature.index.get_level_values(1)==region]\n",
    "        \n",
    "        df_traffic_ts = df_traffic_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "        #df_covid_ts = df_covid_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "        df_temperature_ts = df_temperature_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "    \n",
    "        # create dataframe with last values\n",
    "        df_ts = pd.DataFrame()\n",
    "        features = []\n",
    "        targets = []\n",
    "        target_col = \"R_mean\"\n",
    "        for lag in lags:\n",
    "            lag_shift = lag+1\n",
    "            for col in trafficKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_traffic_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            for col in covidKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_covid_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "            for col in temperatureKPIs:\n",
    "                feature = \"{}_{}\".format(col, lag_shift)\n",
    "                df_ts[feature] = df_temperature_ts.shift(lag_shift)[col]\n",
    "                features.append(feature)\n",
    "        for lag in lags_target:\n",
    "            target = \"target_{}\".format(lag)\n",
    "            targets.append(target)\n",
    "            df_ts[target] = df_covid_ts.shift(-1*lag)[target_col]\n",
    "\n",
    "        df_ts = df_ts[targets+features]\n",
    "        df_ts.dropna(inplace=True)\n",
    "        all_dfs.append(df_ts.copy())\n",
    "        df_ts = df_ts.reset_index(level='Regione')\n",
    "        test_dates, train_dates = [], []\n",
    "\n",
    "        for date_val in df_ts.index.unique():\n",
    "            if any(date_val in x for x in ranges_train_ts):\n",
    "                train_dates.append(date_val)\n",
    "\n",
    "        df_ts_train = df_ts.loc[train_dates]\n",
    "        xgtrain = DMatrix(df_ts_train[features].values, df_ts_train[targets[-1]].values)\n",
    "        #model.fit(df_ts_train[features], df_ts_train[targets])\n",
    "        #xgtest = xgb.DMatrix(test.values)\n",
    "        #model.train(params, xgtrain)\n",
    "        model = train(params, xgtrain)\n",
    "        models_regions[region] = model\n",
    "    \n",
    "# then during SO\n",
    "train_dates_region_every_n = {}\n",
    "test_dates_region_every_n = {}\n",
    "train_dates_region = {}\n",
    "test_dates_region = {}\n",
    "df_ts_test_region = {}\n",
    "all_dfs = []\n",
    "\n",
    "for region in regions_to_train:\n",
    "    # filter ts by region\n",
    "    df_traffic_ts = df_traffic_predictions.loc[df_traffic_predictions.index.get_level_values(1)==region]\n",
    "    df_covid_ts = df_covid_predictions.loc[df_covid_predictions.index.get_level_values(1)==region]\n",
    "    df_temperature_ts = df_temperature.loc[df_temperature.index.get_level_values(1)==region]\n",
    "    \n",
    "    df_traffic_ts = df_traffic_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "    #df_covid_ts = df_covid_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "    df_temperature_ts = df_temperature_ts.groupby(level=1).transform(lambda x: (x-x.mean())/x.std(ddof=1))\n",
    "    # create dataframe with last values\n",
    "    df_ts = pd.DataFrame()\n",
    "    features = []\n",
    "    targets = []\n",
    "    target_col = \"R_mean\"\n",
    "    for lag in lags:\n",
    "        lag_shift = lag+1\n",
    "        for col in trafficKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_traffic_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "        for col in covidKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_covid_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "        for col in temperatureKPIs:\n",
    "            feature = \"{}_{}\".format(col, lag_shift)\n",
    "            df_ts[feature] = df_temperature_ts.shift(lag_shift)[col]\n",
    "            features.append(feature)\n",
    "    for lag in lags_target:\n",
    "        target = \"target_{}\".format(lag)\n",
    "        targets.append(target)\n",
    "        df_ts[target] = df_covid_ts.shift(-1*lag)[target_col]\n",
    "\n",
    "    df_ts = df_ts[targets+features]\n",
    "    df_ts.dropna(inplace=True)\n",
    "    all_dfs.append(df_ts.copy())\n",
    "    df_ts = df_ts.reset_index(level='Regione')\n",
    "    test_dates, train_dates = [], []\n",
    "    \n",
    "    for date_val in df_ts.index.unique():\n",
    "        if any(date_val in x for x in ranges_train_ts):\n",
    "            train_dates.append(date_val)\n",
    "        else:\n",
    "            test_dates.append(date_val)\n",
    "\n",
    "    test_dates = [t for t in test_dates if t > divider_so]\n",
    "\n",
    "    df_ts_train, df_ts_test = df_ts.loc[train_dates], df_ts.loc[test_dates]\n",
    "    #print(\"BUILT DATASET: train = {}, test = {}\".format(df_ts_train.loc[train_dates[0], \"target_0\"], df_ts_test.loc[test_dates[0], \"R_mean_14\"]))\n",
    "\n",
    "    #print(\"TRAIN: \", df_ts_train.head(3))\n",
    "    #print(\"TEST: \", df_ts_test.head(3))\n",
    "\n",
    "    #df_ts_train = df_ts_train.resample('{}D'.format(farsightness))\n",
    "    #train_dates_every_n = pd.date_range(start=train_dates[0], end=train_dates[-1], freq=\"{}D\".format(farsightness))\n",
    "    #train_dates_region_every_n[region] = train_dates_every_n\n",
    "    test_dates_every_n = pd.date_range(start=test_dates[0], end=test_dates[-1], freq=\"{}D\".format(farsightness)).to_pydatetime()\n",
    "    test_dates_region_every_n[region] = test_dates_every_n\n",
    "    train_dates_region[region], test_dates_region[region] = train_dates, test_dates\n",
    "    df_ts_test_region[region] = df_ts_test\n",
    "    #df_ts_train = df_ts_train.loc[train_dates_every_n]\n",
    "    #print(df_ts_train.head())\n",
    "    #model.fit(df_ts_train[features], df_ts_train[targets], xgb_model=model)\n",
    "    xgtrain = DMatrix(df_ts_train[features].values, df_ts_train[targets[-1]].values)\n",
    "    try:\n",
    "        models_regions[region] = train(params, xgtrain, xgb_model=models_regions[region])\n",
    "    except:\n",
    "        model = train(params, xgtrain)\n",
    "        models_regions[region] = model\n",
    "    #model = train(params, xgtrain, xgb_model=model)\n",
    "    #model.train(params, df_ts_train,)\n",
    "    #model.partial_fit(df_ts_train[features], df_ts_train[targets])\n",
    "    \n",
    "# X = {mobility_t_1, mobility_t_2, mobility_t_3, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_predictions = {}\n",
    "test_targets = {}\n",
    "\n",
    "accumulated_t = []\n",
    "accumulated_predictions = []\n",
    "\n",
    "for region in regions_to_train:\n",
    "    test_predictions_region = np.array([])\n",
    "    test_target_region = np.array([])\n",
    "    test_dates = test_dates_region[region]\n",
    "    df_ts_test = df_ts_test_region[region]\n",
    "    print(\"{}: {}\".format(region, df_ts_test.shape))\n",
    "    for i, t in enumerate(test_dates):\n",
    "        X_test_ts = df_ts_test.loc[t, features]\n",
    "        X_test_ts.sort_index(inplace=True)\n",
    "        \n",
    "        predictions = models_regions[region].predict(DMatrix(X_test_ts.to_numpy().reshape(1, -1)))\n",
    "        test_predictions_region = np.append(test_predictions_region, predictions)\n",
    "        \n",
    "        X_test_fit, y_test_fit = df_ts_test.loc[t, features], df_ts_test.loc[t, targets[-1]]\n",
    "        test_target_region = np.append(test_target_region, y_test_fit)\n",
    "        \n",
    "        if i % farsightness == farsightness - 1 or i == len(test_dates) - 1:\n",
    "            xgtrain = DMatrix(df_ts_test.loc[accumulated_t, features].values, df_ts_test.loc[accumulated_t, targets[-1]].to_numpy())\n",
    "            models_regions[region] = train(params, xgtrain, xgb_model=models_regions[region])\n",
    "            accumulated_t, accumulated_predictions = [], []\n",
    "        else:\n",
    "            accumulated_predictions.append(predictions)\n",
    "            accumulated_t.append(t)\n",
    "            \n",
    "    test_predictions[region] = test_predictions_region\n",
    "    test_targets[region] = test_target_region\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "test_targets = {}\n",
    "\n",
    "for region in regions_to_train:\n",
    "    test_predictions_region = np.array([])\n",
    "    test_target_region = np.array([])\n",
    "    test_dates = test_dates_region[region]\n",
    "    df_ts_test = df_ts_test_region[region]\n",
    "    print(\"{}: {}\".format(region, df_ts_test.shape))\n",
    "    for i, t in enumerate(test_dates):\n",
    "        X_test_ts = df_ts_test.loc[t, features]\n",
    "        X_test_ts.sort_index(inplace=True)\n",
    "        \n",
    "        predictions = models_regions[region].predict(DMatrix(X_test_ts.to_numpy().reshape(1, -1)))\n",
    "        test_predictions_region = np.append(test_predictions_region, predictions)\n",
    "        \n",
    "        X_test_fit, y_test_fit = df_ts_test.loc[t, features], df_ts_test.loc[t, targets[-1]]\n",
    "        test_target_region = np.append(test_target_region, y_test_fit)\n",
    "        \n",
    "        if i < len(test_dates)-1:\n",
    "            xgtrain = DMatrix(X_test_fit.to_numpy().reshape(1, -1), y_test_fit.reshape(1, -1))\n",
    "            models_regions[region] = train(params, xgtrain, xgb_model=models_regions[region])\n",
    "            \n",
    "    test_predictions[region] = test_predictions_region\n",
    "    test_targets[region] = test_target_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for region in regions_to_train:\n",
    "    df_plot_region = pd.DataFrame({\"predictions\": test_predictions[region], \"target\": test_targets[region]})\n",
    "    rmse, r2 = np.sqrt(MSE(df_plot_region['predictions'], df_plot_region['target'])), r2_score(df_plot_region['predictions'], df_plot_region['target'])\n",
    "    \n",
    "    df_plot_region.plot(title=\"{}: {:.3f}, {:.3f}\".format(region, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO integrare abruzzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-covid",
   "language": "python",
   "name": "traffic-covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
