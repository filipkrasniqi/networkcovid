{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALREADY OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import date, datetime\n",
    "import geojson\n",
    "import copy\n",
    "\n",
    "# TODO 1) more KPIs for covid X (indice RT???)\n",
    "data_path = \"/Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/\"\n",
    "saved = \"{}saved/\".format(data_path)\n",
    "traffic_daily = \"{}TS_1800_daily.pkl\".format(saved)\n",
    "covid = \"{}covid/\".format(data_path)\n",
    "covid_daily = \"{}covid_rt.csv\".format(saved)#\"{}covid_regioni.csv\".format(covid)\n",
    "region_traffic_daily = \"{}all.pkl\".format(saved)\n",
    "by_region_path = \"{}By_Region/\".format(data_path)\n",
    "\n",
    "covid_cols = ['Date', 'Regione', 'terapia_intensiva', 'nuovi_positivi', 'tamponi_giornalieri', 'totale_casi', 'deceduti', 'totale_casi_giornalieri', 'terapia_intensiva_giornalieri', 'R_mean']\n",
    "traffic_cols = ['Date', 'Regione', 'Hin_Succ', 'DL_VOL', 'UL_VOL', 'USERNUM_AVG']\n",
    "new_traffic_cols = ['Date', 'Regione', 'Handover', 'Download vol.', 'Upload vol.', '#Users']\n",
    "regions_rename_traffic = {'Abruzzi': 'Abruzzo', 'Emilia-romagna': 'Emilia Romagna', \\\n",
    "                          'Friuli-venezia giulia': 'Friuli Venezia Giulia', 'Valle d`aosta': \"Valle d'Aosta\",\\\n",
    "                         'Trentino-alto adige': \"Trentino-Alto Adige\"}\n",
    "\n",
    "to_sum_KPIs = ['totale_casi_giornalieri', 'terapia_intensiva_giornalieri', 'terapia_intensiva', 'nuovi_positivi', 'tamponi_giornalieri', 'R_mean']\n",
    "covidKPIs = ['R_mean']+to_sum_KPIs\n",
    "trafficKPIs = ['Handover', 'Download vol.', 'Upload vol.', '#Users']\n",
    "\n",
    "# controllo se ...\n",
    "NEW_DATA, FORCE = True, True\n",
    "if NEW_DATA:\n",
    "    if not FORCE and os.path.isfile(region_traffic_daily):\n",
    "        df_traffic_daily = pd.read_pickle(region_traffic_daily)\n",
    "    else: \n",
    "        df_traffic_daily = pd.read_pickle(traffic_daily)\n",
    "        # read new data\n",
    "        _, _, filenames = next(os.walk(by_region_path))\n",
    "        dfs = []\n",
    "        for filename in filenames:\n",
    "            if \"LTE_1800\" in filename:\n",
    "                try:\n",
    "                    df = pd.read_pickle(\"{}{}\".format(by_region_path, filename))\n",
    "                    df['Regione'] = filename.split(\"_\")[2]\n",
    "                    df.USERNUM_AVG = pd.to_numeric(df.USERNUM_AVG, errors='coerce')\n",
    "                    dfs.append(df)\n",
    "                except:\n",
    "                    print(\"ERRORE: {}\".format(filename))\n",
    "                \n",
    "        df_traffic_daily = pd.concat(dfs)\n",
    "        df_traffic_daily.Regione = df_traffic_daily.Regione.apply(lambda x: x.capitalize())\n",
    "\n",
    "        for col_old, col_new in zip(traffic_cols, new_traffic_cols):\n",
    "            df_traffic_daily = df_traffic_daily.rename(columns={col_old: col_new})\n",
    "        \n",
    "        for key in regions_rename_traffic.keys():\n",
    "            df_traffic_daily.loc[df_traffic_daily.Regione == key, \"Regione\"] = regions_rename_traffic[key]\n",
    "        \n",
    "        df_traffic_daily.to_pickle(region_traffic_daily)\n",
    "else:\n",
    "    df_traffic_daily = pd.read_pickle(traffic_daily)\n",
    "    map_city_regione = {\"MILANO\": \"Lombardia\", \"BERGAMO\": \"Lombardia\", \"NAPOLI\": \"Campania\", \"ROMA\": \"Lazio\", \"TORINO\": \"Piemonte\"}\n",
    "\n",
    "    columns = ['data', 'denominazione_regione','denominazione_provincia','sigla_provincia','lat','long','totale_casi']\n",
    "    if \"Regione\" not in df_traffic_daily.columns:\n",
    "        # assegno regioni\n",
    "        df_traffic_daily['Regione'] = df_traffic_daily['COMUNE'].apply(lambda comune: map_city_regione[comune])\n",
    "    \n",
    "df_covid = pd.read_csv(covid_daily)\n",
    "\n",
    "# sums regions such as trento + bolzano\n",
    "def sumRegions(df, dateCol = 'Date', regionCol='Regione', cols = to_sum_KPIs, region1 = \"Bolzano\", region2 = \"Trento\", regionNew = \"Trentino-Alto Adige\"):\n",
    "    dfRegion1, dfRegion2 = df.loc[df[regionCol] == region1], df.loc[df[regionCol] == region2]\n",
    "    dfRegion1.set_index(dateCol, inplace=True)\n",
    "    dfRegion2.set_index(dateCol, inplace=True)\n",
    "    newVals = dfRegion1[to_sum_KPIs]+dfRegion2[to_sum_KPIs]\n",
    "    newVals.reset_index(inplace=True)\n",
    "    newVals['Regione'] = regionNew\n",
    "    df = df.loc[(df[regionCol] != region1) & (df[regionCol] != region2)]\n",
    "    return df.append(newVals)\n",
    "\n",
    "# adds italy as cumulative over days\n",
    "def addItalyData(df, cols):\n",
    "    dfTemp = df.resample('D', on='Date').sum().reset_index()\n",
    "    dfTemp['Regione']='Italia'\n",
    "    dfTemp = dfTemp[cols]\n",
    "    return pd.concat([df, dfTemp])\n",
    "\n",
    "def map_geojson(region):\n",
    "    regions_map = {\"Valle d'Aosta/Vallée d'Aoste\": 'Valle d\\'Aosta', \"Trentino-Alto Adige/Südtirol\": 'Trentino-Alto Adige',\\\n",
    "                  \"Friuli-Venezia Giulia\": \"Friuli Venezia Giulia\", \"Emilia-Romagna\": \"Emilia Romagna\"}\n",
    "    return regions_map[region]\n",
    "\n",
    "# data from string to datetime\n",
    "try:\n",
    "    df_covid.data = pd.to_datetime(df_covid.data)\n",
    "    df_covid.rename(columns={'data': 'Date'}, inplace=True)\n",
    "except:\n",
    "    print(\"ALREADY OK\")\n",
    "    \n",
    "df_covid = sumRegions(df_covid)\n",
    "\n",
    "traffic_cols = new_traffic_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_traffic_predictions=\"{}predictions/traffic.pkl\".format(saved)\n",
    "path_traffic_predictions_csv=\"{}predictions/traffic.csv\".format(saved)\n",
    "df_traffic_predictions_temp = pd.read_pickle(path_traffic_predictions)\n",
    "df_traffic_predictions_temp.to_csv(path_traffic_predictions_csv)\n",
    "\n",
    "path_covid_predictions=\"{}predictions/covid.pkl\".format(saved)\n",
    "path_covid_predictions_csv=\"{}predictions/covid.csv\".format(saved)\n",
    "df_covid_predictions = pd.read_pickle(path_covid_predictions)\n",
    "df_covid_predictions.to_csv(path_covid_predictions_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>RRC_S_Succ</th>\n",
       "      <th>RRC_S_Att</th>\n",
       "      <th>RRC_S_SR</th>\n",
       "      <th>RRC_RE_Succ</th>\n",
       "      <th>RRC_RE_Att</th>\n",
       "      <th>IntraF_Hout_Succ</th>\n",
       "      <th>IntraF_Hout_Att</th>\n",
       "      <th>InterF_Hout_Succ</th>\n",
       "      <th>InterF_Hout_Att</th>\n",
       "      <th>Handover</th>\n",
       "      <th>...</th>\n",
       "      <th>InterR_HO_OUT_E2G_Att</th>\n",
       "      <th>Download vol.</th>\n",
       "      <th>Upload vol.</th>\n",
       "      <th>#Users</th>\n",
       "      <th>ERAB_S_Succ</th>\n",
       "      <th>ERAB_S_Att</th>\n",
       "      <th>Handover_MA</th>\n",
       "      <th>Download vol._MA</th>\n",
       "      <th>Upload vol._MA</th>\n",
       "      <th>#Users_MA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Regione</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <th>Abruzzo</th>\n",
       "      <td>722914109.0</td>\n",
       "      <td>723559625.0</td>\n",
       "      <td>2399.867376</td>\n",
       "      <td>2109077.0</td>\n",
       "      <td>2755617.0</td>\n",
       "      <td>69768501.0</td>\n",
       "      <td>69410898.0</td>\n",
       "      <td>29058705.0</td>\n",
       "      <td>29152448.0</td>\n",
       "      <td>87240956.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41672.0</td>\n",
       "      <td>2.892451e+15</td>\n",
       "      <td>2.471538e+14</td>\n",
       "      <td>3.184160e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <th>Abruzzo</th>\n",
       "      <td>718452155.0</td>\n",
       "      <td>718983916.0</td>\n",
       "      <td>2399.873855</td>\n",
       "      <td>2131711.0</td>\n",
       "      <td>2792486.0</td>\n",
       "      <td>84230949.0</td>\n",
       "      <td>83904966.0</td>\n",
       "      <td>28343453.0</td>\n",
       "      <td>28429081.0</td>\n",
       "      <td>103161979.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54111.0</td>\n",
       "      <td>2.675922e+15</td>\n",
       "      <td>2.237421e+14</td>\n",
       "      <td>3.220258e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <th>Abruzzo</th>\n",
       "      <td>732998734.0</td>\n",
       "      <td>733541088.0</td>\n",
       "      <td>2399.825795</td>\n",
       "      <td>2155915.0</td>\n",
       "      <td>2846211.0</td>\n",
       "      <td>86249305.0</td>\n",
       "      <td>85912857.0</td>\n",
       "      <td>29106383.0</td>\n",
       "      <td>29189094.0</td>\n",
       "      <td>105738844.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55830.0</td>\n",
       "      <td>2.691140e+15</td>\n",
       "      <td>2.226775e+14</td>\n",
       "      <td>3.271108e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <th>Abruzzo</th>\n",
       "      <td>729004305.0</td>\n",
       "      <td>729571151.0</td>\n",
       "      <td>2399.844823</td>\n",
       "      <td>2116294.0</td>\n",
       "      <td>2829792.0</td>\n",
       "      <td>84713582.0</td>\n",
       "      <td>84381441.0</td>\n",
       "      <td>29279339.0</td>\n",
       "      <td>29355363.0</td>\n",
       "      <td>104350340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47662.0</td>\n",
       "      <td>2.647715e+15</td>\n",
       "      <td>2.187153e+14</td>\n",
       "      <td>3.189687e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <th>Abruzzo</th>\n",
       "      <td>706629792.0</td>\n",
       "      <td>707240933.0</td>\n",
       "      <td>2399.768004</td>\n",
       "      <td>2272802.0</td>\n",
       "      <td>2936730.0</td>\n",
       "      <td>79952197.0</td>\n",
       "      <td>79642735.0</td>\n",
       "      <td>28033160.0</td>\n",
       "      <td>28114250.0</td>\n",
       "      <td>98488811.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35454.0</td>\n",
       "      <td>2.735595e+15</td>\n",
       "      <td>2.249541e+14</td>\n",
       "      <td>3.108692e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-24</th>\n",
       "      <th>Veneto</th>\n",
       "      <td>225596711.0</td>\n",
       "      <td>225693675.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>534582.0</td>\n",
       "      <td>768383.0</td>\n",
       "      <td>7189438.0</td>\n",
       "      <td>7223154.0</td>\n",
       "      <td>8989396.0</td>\n",
       "      <td>9086800.0</td>\n",
       "      <td>24560829.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22754.0</td>\n",
       "      <td>1.227038e+12</td>\n",
       "      <td>1.239326e+11</td>\n",
       "      <td>1.148751e+06</td>\n",
       "      <td>406781583.0</td>\n",
       "      <td>406840893.0</td>\n",
       "      <td>2.263051e+07</td>\n",
       "      <td>1.268557e+12</td>\n",
       "      <td>1.193639e+11</td>\n",
       "      <td>1.108370e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25</th>\n",
       "      <th>Veneto</th>\n",
       "      <td>226892106.0</td>\n",
       "      <td>226990072.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>544697.0</td>\n",
       "      <td>778281.0</td>\n",
       "      <td>7290843.0</td>\n",
       "      <td>7323795.0</td>\n",
       "      <td>9044861.0</td>\n",
       "      <td>9143584.0</td>\n",
       "      <td>25162624.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22194.0</td>\n",
       "      <td>1.265358e+12</td>\n",
       "      <td>1.239708e+11</td>\n",
       "      <td>1.155531e+06</td>\n",
       "      <td>408781539.0</td>\n",
       "      <td>408834867.0</td>\n",
       "      <td>2.281185e+07</td>\n",
       "      <td>1.273790e+12</td>\n",
       "      <td>1.198096e+11</td>\n",
       "      <td>1.111068e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-26</th>\n",
       "      <th>Veneto</th>\n",
       "      <td>228933364.0</td>\n",
       "      <td>229031967.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>534915.0</td>\n",
       "      <td>771242.0</td>\n",
       "      <td>7482217.0</td>\n",
       "      <td>7517542.0</td>\n",
       "      <td>9205983.0</td>\n",
       "      <td>9307026.0</td>\n",
       "      <td>25735694.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21704.0</td>\n",
       "      <td>1.294111e+12</td>\n",
       "      <td>1.227355e+11</td>\n",
       "      <td>1.155699e+06</td>\n",
       "      <td>412255006.0</td>\n",
       "      <td>412310286.0</td>\n",
       "      <td>2.297402e+07</td>\n",
       "      <td>1.281229e+12</td>\n",
       "      <td>1.200135e+11</td>\n",
       "      <td>1.113032e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-27</th>\n",
       "      <th>Veneto</th>\n",
       "      <td>214647857.0</td>\n",
       "      <td>214744605.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>462945.0</td>\n",
       "      <td>684452.0</td>\n",
       "      <td>6555173.0</td>\n",
       "      <td>6585317.0</td>\n",
       "      <td>8301996.0</td>\n",
       "      <td>8401086.0</td>\n",
       "      <td>21873387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13830.0</td>\n",
       "      <td>1.317346e+12</td>\n",
       "      <td>1.129490e+11</td>\n",
       "      <td>1.054649e+06</td>\n",
       "      <td>386189271.0</td>\n",
       "      <td>386234427.0</td>\n",
       "      <td>2.314916e+07</td>\n",
       "      <td>1.283160e+12</td>\n",
       "      <td>1.205004e+11</td>\n",
       "      <td>1.114277e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-28</th>\n",
       "      <th>Veneto</th>\n",
       "      <td>203750066.0</td>\n",
       "      <td>203850901.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>498957.0</td>\n",
       "      <td>719187.0</td>\n",
       "      <td>5627962.0</td>\n",
       "      <td>5656738.0</td>\n",
       "      <td>7230392.0</td>\n",
       "      <td>7334436.0</td>\n",
       "      <td>19245821.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9118.0</td>\n",
       "      <td>1.345221e+12</td>\n",
       "      <td>1.132375e+11</td>\n",
       "      <td>1.010849e+06</td>\n",
       "      <td>365976431.0</td>\n",
       "      <td>366018082.0</td>\n",
       "      <td>2.338292e+07</td>\n",
       "      <td>1.275306e+12</td>\n",
       "      <td>1.207240e+11</td>\n",
       "      <td>1.115320e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7280 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RRC_S_Succ    RRC_S_Att     RRC_S_SR  RRC_RE_Succ  \\\n",
       "Date       Regione                                                       \n",
       "2020-01-01 Abruzzo  722914109.0  723559625.0  2399.867376    2109077.0   \n",
       "2020-01-02 Abruzzo  718452155.0  718983916.0  2399.873855    2131711.0   \n",
       "2020-01-03 Abruzzo  732998734.0  733541088.0  2399.825795    2155915.0   \n",
       "2020-01-04 Abruzzo  729004305.0  729571151.0  2399.844823    2116294.0   \n",
       "2020-01-05 Abruzzo  706629792.0  707240933.0  2399.768004    2272802.0   \n",
       "...                         ...          ...          ...          ...   \n",
       "2021-02-24 Veneto   225596711.0  225693675.0  2400.000000     534582.0   \n",
       "2021-02-25 Veneto   226892106.0  226990072.0  2400.000000     544697.0   \n",
       "2021-02-26 Veneto   228933364.0  229031967.0  2400.000000     534915.0   \n",
       "2021-02-27 Veneto   214647857.0  214744605.0  2400.000000     462945.0   \n",
       "2021-02-28 Veneto   203750066.0  203850901.0  2400.000000     498957.0   \n",
       "\n",
       "                    RRC_RE_Att  IntraF_Hout_Succ  IntraF_Hout_Att  \\\n",
       "Date       Regione                                                  \n",
       "2020-01-01 Abruzzo   2755617.0        69768501.0       69410898.0   \n",
       "2020-01-02 Abruzzo   2792486.0        84230949.0       83904966.0   \n",
       "2020-01-03 Abruzzo   2846211.0        86249305.0       85912857.0   \n",
       "2020-01-04 Abruzzo   2829792.0        84713582.0       84381441.0   \n",
       "2020-01-05 Abruzzo   2936730.0        79952197.0       79642735.0   \n",
       "...                        ...               ...              ...   \n",
       "2021-02-24 Veneto     768383.0         7189438.0        7223154.0   \n",
       "2021-02-25 Veneto     778281.0         7290843.0        7323795.0   \n",
       "2021-02-26 Veneto     771242.0         7482217.0        7517542.0   \n",
       "2021-02-27 Veneto     684452.0         6555173.0        6585317.0   \n",
       "2021-02-28 Veneto     719187.0         5627962.0        5656738.0   \n",
       "\n",
       "                    InterF_Hout_Succ  InterF_Hout_Att     Handover  ...  \\\n",
       "Date       Regione                                                  ...   \n",
       "2020-01-01 Abruzzo        29058705.0       29152448.0   87240956.0  ...   \n",
       "2020-01-02 Abruzzo        28343453.0       28429081.0  103161979.0  ...   \n",
       "2020-01-03 Abruzzo        29106383.0       29189094.0  105738844.0  ...   \n",
       "2020-01-04 Abruzzo        29279339.0       29355363.0  104350340.0  ...   \n",
       "2020-01-05 Abruzzo        28033160.0       28114250.0   98488811.0  ...   \n",
       "...                              ...              ...          ...  ...   \n",
       "2021-02-24 Veneto          8989396.0        9086800.0   24560829.0  ...   \n",
       "2021-02-25 Veneto          9044861.0        9143584.0   25162624.0  ...   \n",
       "2021-02-26 Veneto          9205983.0        9307026.0   25735694.0  ...   \n",
       "2021-02-27 Veneto          8301996.0        8401086.0   21873387.0  ...   \n",
       "2021-02-28 Veneto          7230392.0        7334436.0   19245821.0  ...   \n",
       "\n",
       "                    InterR_HO_OUT_E2G_Att  Download vol.   Upload vol.  \\\n",
       "Date       Regione                                                       \n",
       "2020-01-01 Abruzzo                41672.0   2.892451e+15  2.471538e+14   \n",
       "2020-01-02 Abruzzo                54111.0   2.675922e+15  2.237421e+14   \n",
       "2020-01-03 Abruzzo                55830.0   2.691140e+15  2.226775e+14   \n",
       "2020-01-04 Abruzzo                47662.0   2.647715e+15  2.187153e+14   \n",
       "2020-01-05 Abruzzo                35454.0   2.735595e+15  2.249541e+14   \n",
       "...                                   ...            ...           ...   \n",
       "2021-02-24 Veneto                 22754.0   1.227038e+12  1.239326e+11   \n",
       "2021-02-25 Veneto                 22194.0   1.265358e+12  1.239708e+11   \n",
       "2021-02-26 Veneto                 21704.0   1.294111e+12  1.227355e+11   \n",
       "2021-02-27 Veneto                 13830.0   1.317346e+12  1.129490e+11   \n",
       "2021-02-28 Veneto                  9118.0   1.345221e+12  1.132375e+11   \n",
       "\n",
       "                          #Users  ERAB_S_Succ   ERAB_S_Att   Handover_MA  \\\n",
       "Date       Regione                                                         \n",
       "2020-01-01 Abruzzo  3.184160e+06          NaN          NaN           NaN   \n",
       "2020-01-02 Abruzzo  3.220258e+06          NaN          NaN           NaN   \n",
       "2020-01-03 Abruzzo  3.271108e+06          NaN          NaN           NaN   \n",
       "2020-01-04 Abruzzo  3.189687e+06          NaN          NaN           NaN   \n",
       "2020-01-05 Abruzzo  3.108692e+06          NaN          NaN           NaN   \n",
       "...                          ...          ...          ...           ...   \n",
       "2021-02-24 Veneto   1.148751e+06  406781583.0  406840893.0  2.263051e+07   \n",
       "2021-02-25 Veneto   1.155531e+06  408781539.0  408834867.0  2.281185e+07   \n",
       "2021-02-26 Veneto   1.155699e+06  412255006.0  412310286.0  2.297402e+07   \n",
       "2021-02-27 Veneto   1.054649e+06  386189271.0  386234427.0  2.314916e+07   \n",
       "2021-02-28 Veneto   1.010849e+06  365976431.0  366018082.0  2.338292e+07   \n",
       "\n",
       "                    Download vol._MA  Upload vol._MA     #Users_MA  \n",
       "Date       Regione                                                  \n",
       "2020-01-01 Abruzzo               NaN             NaN           NaN  \n",
       "2020-01-02 Abruzzo               NaN             NaN           NaN  \n",
       "2020-01-03 Abruzzo               NaN             NaN           NaN  \n",
       "2020-01-04 Abruzzo               NaN             NaN           NaN  \n",
       "2020-01-05 Abruzzo               NaN             NaN           NaN  \n",
       "...                              ...             ...           ...  \n",
       "2021-02-24 Veneto       1.268557e+12    1.193639e+11  1.108370e+06  \n",
       "2021-02-25 Veneto       1.273790e+12    1.198096e+11  1.111068e+06  \n",
       "2021-02-26 Veneto       1.281229e+12    1.200135e+11  1.113032e+06  \n",
       "2021-02-27 Veneto       1.283160e+12    1.205004e+11  1.114277e+06  \n",
       "2021-02-28 Veneto       1.275306e+12    1.207240e+11  1.115320e+06  \n",
       "\n",
       "[7280 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traffic_predictions_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_regione = df_traffic_daily.groupby('Regione').resample('D', on='Date').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2020-01-01\n",
       "1      2020-01-02\n",
       "2      2020-01-03\n",
       "3      2020-01-04\n",
       "4      2020-01-05\n",
       "          ...    \n",
       "8495   2021-02-24\n",
       "8496   2021-02-25\n",
       "8497   2021-02-26\n",
       "8498   2021-02-27\n",
       "8499   2021-02-28\n",
       "Name: Date, Length: 8500, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_td_regione['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter in the wanted range of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic_daily_PO, df_covid_PO = df_td_regione.loc[(df_td_regione.Date >= '2020-03-01') & (df_td_regione.Date <= '2020-07-31')], df_covid.loc[(df_covid.Date >= '2020-03-01') & (df_covid.Date <= '2020-08-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic_daily_SO, df_covid_SO = df_td_regione.loc[(df_td_regione.Date >= '2020-09-01') & (df_td_regione.Date <= '2020-12-31')], df_covid.loc[(df_covid.Date >= '2020-09-01') & (df_covid.Date <= '2021-01-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter covid data for available traffic regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Valle d'Aosta\", 'Veneto', 'Toscana', 'Piemonte', 'Molise', 'Abruzzo', 'Puglia', 'Marche', 'Basilicata', 'Sardegna', 'Trentino-Alto Adige', 'Lombardia', 'Sicilia', 'Liguria', 'Calabria', 'Emilia Romagna', 'Campania', 'Umbria', 'Lazio', 'Friuli Venezia Giulia'}\n"
     ]
    }
   ],
   "source": [
    "regions = set(df_traffic_daily_SO.Regione.unique()).intersection(df_traffic_daily_PO.Regione.unique())\n",
    "print(regions)\n",
    "def filterByTrafficRegions(df_covid, regions):\n",
    "    df_covid.rename(columns={'denominazione_regione': 'Regione'}, inplace=True)\n",
    "    query = ' | '.join([f'Regione==\"{r}\"' for r in regions])\n",
    "    return df_covid.query(query)\n",
    "\n",
    "df_covid_PO, df_covid_SO = filterByTrafficRegions(df_covid_PO, regions), filterByTrafficRegions(df_covid_SO, regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_PO['Date'], df_covid_SO['Date'] = pd.to_datetime(df_covid_PO['Date']), pd.to_datetime(df_covid_SO['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns and adding cumulative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_traffic_daily_SO, df_covid_SO, df_traffic_daily_PO, df_covid_PO = df_traffic_daily_SO[traffic_cols],    df_covid_SO[covid_cols], df_traffic_daily_PO[traffic_cols], df_covid_PO[covid_cols]\\n\\ndef addItalyData(df, cols, traffic = False, aggr = None):\\n    if aggr is None:\\n        aggr = {col: \\'sum\\' for col in cols if \"mean\" not in col}#, \\'tamb\\': np.mean}\\n        if not traffic:\\n            aggr[\\'R_mean\\'] = \\'mean\\'\\n        \\n    dfTemp = df.resample(\\'D\\', on=\\'Date\\').agg(aggr).reset_index()\\n    dfTemp[\\'Regione\\']=\\'Italia\\'\\n    dfTemp = dfTemp[cols]\\n    df = df.reset_index()\\n    return pd.concat([df, dfTemp])\\n\\ndf_traffic_daily_PO, df_traffic_daily_SO = addItalyData(df_traffic_daily_PO, trafficKPIs, traffic=True),     addItalyData(df_traffic_daily_SO, trafficKPIs, traffic=True)\\ndf_covid_PO, df_covid_SO = addItalyData(df_covid_PO, covidKPIs),    addItalyData(df_covid_SO, covidKPIs)\\n    '"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_traffic_daily_SO, df_covid_SO, df_traffic_daily_PO, df_covid_PO = df_traffic_daily_SO[traffic_cols],\\\n",
    "    df_covid_SO[covid_cols], df_traffic_daily_PO[traffic_cols], df_covid_PO[covid_cols]\n",
    "\n",
    "def addItalyData(df, cols, traffic = False, aggr = None):\n",
    "    if aggr is None:\n",
    "        aggr = {col: 'sum' for col in cols if \"mean\" not in col}#, 'tamb': np.mean}\n",
    "        if not traffic:\n",
    "            aggr['R_mean'] = 'mean'\n",
    "        \n",
    "    dfTemp = df.resample('D', on='Date').agg(aggr).reset_index()\n",
    "    dfTemp['Regione']='Italia'\n",
    "    dfTemp = dfTemp[cols]\n",
    "    df = df.reset_index()\n",
    "    return pd.concat([df, dfTemp])\n",
    "\n",
    "df_traffic_daily_PO, df_traffic_daily_SO = addItalyData(df_traffic_daily_PO, trafficKPIs, traffic=True), \\\n",
    "    addItalyData(df_traffic_daily_SO, trafficKPIs, traffic=True)\n",
    "df_covid_PO, df_covid_SO = addItalyData(df_covid_PO, covidKPIs),\\\n",
    "    addItalyData(df_covid_SO, covidKPIs)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_PO['%pos'] = (df_covid_PO['nuovi_positivi']/df_covid_PO['tamponi_giornalieri'])\n",
    "df_covid_SO['%pos'] = (df_covid_SO['nuovi_positivi']/df_covid_SO['tamponi_giornalieri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle wrong and missing values (NaN or >= 1) -> ((t-1)+(t+1))/2\n",
    "def fixMissingCovid(df, col=\"%pos\"):\n",
    "    idxToSelect = (df[col].isna()) | (df[col] >= 1) | (df[col] < 0)\n",
    "    df.loc[idxToSelect, col] = np.nan\n",
    "    df[col] = df[col].interpolate(method='linear')\n",
    "    df = df.loc[~df[col].isna()]  # to handle first values\n",
    "    return df\n",
    "    \n",
    "df_covid_PO, df_covid_SO = fixMissingCovid(df_covid_PO), fixMissingCovid(df_covid_SO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:26000/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1351ec2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regionsToShow = list(regions)\n",
    "#regionsToShow.append(\"Italia\")\n",
    "\n",
    "name = \"TRAFFIC_VS_COVID\"\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app_timeseries = JupyterDash(name, external_stylesheets=external_stylesheets)\n",
    "\n",
    "app_timeseries.layout = html.Div([\n",
    "html.Label(\n",
    "    \n",
    "[\n",
    "    \"Day/Week\",\n",
    "    dcc.Dropdown(id=\"dayOrWeek\",\n",
    "                 options=[{\"label\": x, \"value\": x} for x in ['Day', 'Week']],\n",
    "                value='Day',\n",
    "                clearable=False)\n",
    "]),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Date Picker: \",\n",
    "            dcc.DatePickerRange(\n",
    "                id='date-picker-range',\n",
    "                min_date_allowed=date(2020, 3, 1),\n",
    "                max_date_allowed=date(2020, 12, 31),\n",
    "                start_date=date(2020, 3, 1),\n",
    "                end_date=date(2021, 12, 31)\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "html.Label(\n",
    "    [\n",
    "        \"TRAFFIC\",\n",
    "        dcc.Dropdown(id=\"kpi1\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in trafficKPIs],\n",
    "                    value=trafficKPIs[0],\n",
    "                    clearable=False)\n",
    "    ]),\n",
    "html.Label(\n",
    "    [\n",
    "        \"COVID\",\n",
    "        dcc.Dropdown(id=\"kpi2\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in covidKPIs],\n",
    "                    value=covidKPIs[0],\n",
    "                    clearable=False)\n",
    "    ]),\n",
    "html.Label(\n",
    "    [\n",
    "        \"Regione\",\n",
    "        dcc.Dropdown(id=\"regions\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in regionsToShow],\n",
    "                    value=\"Lombardia\",\n",
    "                    multi=True,\n",
    "                    clearable=True)\n",
    "    ],\n",
    "),\n",
    "    html.Label(\n",
    "                [\"Rolling average window \",\n",
    "                html.Br(),\n",
    "                dcc.Input(\n",
    "                id='rolling_avg',\n",
    "                type='number',\n",
    "#                 value=1\n",
    "                )]\n",
    "    ),\n",
    "    html.Label(\n",
    "                [\"Shift COVID\",\n",
    "                html.Br(),\n",
    "                dcc.Input(\n",
    "                id='shift',\n",
    "                type='number',\n",
    "                )]\n",
    "    ),\n",
    "    html.Br(),\n",
    "html.Label(\n",
    "    [\n",
    "        \"Scatterplot\",\n",
    "        dcc.Dropdown(id=\"scatterplot\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in [\"Yes\", \"No\"]],\n",
    "                    value=\"No\",\n",
    "                    clearable=False)\n",
    "    ]),\n",
    "html.Div(dcc.Graph(id=name))])\n",
    "\n",
    "@app_timeseries.callback(\n",
    "Output(name, \"figure\"), \n",
    "[\n",
    "     Input('date-picker-range', 'start_date'),\n",
    "     Input('date-picker-range', 'end_date'),Input(\"dayOrWeek\", \"value\"), Input(\"kpi1\", \"value\"), Input(\"kpi2\", \"value\"), Input(\"regions\", \"value\"), Input(\"rolling_avg\", \"value\"), Input(\"shift\", \"value\"), Input(\"scatterplot\", \"value\")])\n",
    "def display_map_period(start_date, end_date, dayOrWeek, trafficKPI, covidKPI, regions, roll_avg, shift_amount, scatter):\n",
    "    \n",
    "    if start_date is not None:\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    if end_date is not None:\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    if dayOrWeek != \"Day\":\n",
    "        df_covid_1, df_covid_2 = df_covid_PO.groupby('Regione').resample('W-Mon', on='Date').sum().reset_index(),\\\n",
    "            df_covid_SO.groupby('Regione').resample('W-Mon', on='Date').sum().reset_index()\n",
    "        df_traffic_1, df_traffic_2 = df_traffic_daily_PO.groupby('Regione').resample('W-Mon', on='Date').sum().reset_index(), df_traffic_daily_SO.groupby('Regione').resample('W-Mon', on='Date').sum().reset_index()\n",
    "    else:\n",
    "        df_covid_1, df_covid_2 = df_covid_PO, df_covid_SO\n",
    "        df_traffic_1, df_traffic_2 = df_traffic_daily_PO, df_traffic_daily_SO\n",
    "        \n",
    "    df_covid_2 = df_covid_2.loc[df_covid_2.Date > df_traffic_2.Date.min()]\n",
    "\n",
    "    df_traffic_1[df_traffic_1[trafficKPI] <= 0], df_traffic_2[df_traffic_2[trafficKPI] <= 0] = np.nan, np.nan\n",
    "    df_traffic_1.dropna(subset=[trafficKPI], inplace=True)\n",
    "    df_traffic_2.dropna(subset=[trafficKPI], inplace=True)\n",
    "    \n",
    "    if isinstance(regions, str):\n",
    "        regions = [regions]\n",
    "        \n",
    "    if regions is None:\n",
    "        regions = ['Italia']\n",
    "        \n",
    "    if roll_avg is None or roll_avg <= 0:\n",
    "        roll_avg = 1\n",
    "        \n",
    "    if shift_amount is None:\n",
    "        shift_amount = 0\n",
    "\n",
    "    if scatter == \"Yes\":\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "        fig.update_xaxes(title_text=trafficKPI)\n",
    "        fig.update_yaxes(title_text=covidKPI)\n",
    "        \n",
    "    else:\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "        \n",
    "        # Set x-axis title\n",
    "        fig.update_xaxes(title_text=\"Day of year\")\n",
    "\n",
    "        # Set y-axes titles\n",
    "        fig.update_yaxes(title_text=trafficKPI, secondary_y=False)\n",
    "        fig.update_yaxes(title_text=covidKPI, secondary_y=True)\n",
    "\n",
    "    traffic_colors = ['#FF0000', '#f56342', '#f57e42', '#f59642', '#f5a742']\n",
    "    covid_colors = ['#0000FF', '#0062ff', '#008cff', '#00b3ff', '#00b7e0']\n",
    "    \n",
    "    def filter_fun(df):\n",
    "        return (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "    \n",
    "    covidKPI2, trafficKPI2 = covidKPI, trafficKPI\n",
    "    \n",
    "    for i, r in enumerate(regions):\n",
    "        df_traffic_region_1, df_traffic_region_2 = df_traffic_1.loc[df_traffic_1.Regione == r], df_traffic_2.loc[df_traffic_2.Regione == r]\n",
    "        df_covid_region_1, df_covid_region_2 = df_covid_1.loc[df_covid_1.Regione == r], df_covid_2.loc[df_covid_2.Regione == r]\n",
    "        df_traffic_region_1, df_traffic_region_2 = df_traffic_region_1.loc[filter_fun(df_traffic_region_1)], df_traffic_region_2.loc[filter_fun(df_traffic_region_2)]\n",
    "        df_covid_region_1, df_covid_region_2 = df_covid_region_1.loc[filter_fun(df_covid_region_1)], df_covid_region_2.loc[filter_fun(df_covid_region_2)]\n",
    "        if shift_amount != 0:\n",
    "            df_covid_region_1, df_covid_region_2 = df_covid_region_1.shift(shift_amount), df_covid_region_2.shift(shift_amount)\n",
    "            # sommo N giorni a tutti nel date\n",
    "            df_covid_region_1['Date'] += pd.DateOffset(shift_amount)\n",
    "            df_covid_region_2['Date'] += pd.DateOffset(shift_amount)\n",
    "            \n",
    "        if roll_avg > 1:\n",
    "            covidKPI2, trafficKPI2 = \"{}_roll\".format(covidKPI), \"{}_roll\".format(trafficKPI)\n",
    "            df_traffic_region_1[trafficKPI2], df_traffic_region_2[trafficKPI2], df_covid_region_1[covidKPI2], df_covid_region_2[covidKPI2] = \\\n",
    "                df_traffic_region_1[trafficKPI].rolling(roll_avg).mean(), df_traffic_region_2[trafficKPI].rolling(roll_avg).mean(), \\\n",
    "                df_covid_region_1[covidKPI].rolling(roll_avg).mean(), df_covid_region_2[covidKPI].rolling(roll_avg).mean()\n",
    "        #df_traffic_region_1.dropna(subset=[trafficKPI2], inplace=True)\n",
    "        #df_traffic_region_2.dropna(subset=[trafficKPI2], inplace=True)\n",
    "        #df_covid_region_1.dropna(subset=[covidKPI2], inplace=True)\n",
    "        #df_covid_region_2.dropna(subset=[covidKPI2], inplace=True)\n",
    "        def normalize(df, col):\n",
    "            return (df[col]-df[col].mean())/df[col].std()\n",
    "        df_traffic_all, df_covid_all = pd.concat([df_traffic_region_1, df_traffic_region_2]), pd.concat([df_covid_region_1, df_covid_region_2])\n",
    "        df_covid_all[covidKPI2] = normalize(df_covid_all, covidKPI2)\n",
    "        df_traffic_all[trafficKPI2] = normalize(df_traffic_all, trafficKPI2)\n",
    "        \n",
    "        if scatter == \"Yes\":\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                    x=df_traffic_all[trafficKPI2],\n",
    "                    y=df_covid_all[covidKPI2],\n",
    "                    mode='markers+text',\n",
    "                    name=\"{} vs {} - {}\".format(trafficKPI, covidKPI, r)\n",
    "                )\n",
    "            )\n",
    "            #fig.update_yaxes(range=[0, 1])\n",
    "        else:\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                    x=df_traffic_region_1.Date,\n",
    "                    y=df_traffic_region_1[trafficKPI2],\n",
    "                    marker=dict(\n",
    "                        color=traffic_colors[i]\n",
    "                    ),\n",
    "                    name=\"{} - {}\".format(trafficKPI, r)\n",
    "                ),\n",
    "                secondary_y=False,\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                    x=df_traffic_region_2.Date,\n",
    "                    y=df_traffic_region_2[trafficKPI2],\n",
    "                    marker=dict(\n",
    "                        color=traffic_colors[i]\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                    name=\"{} - {}\".format(trafficKPI, r)\n",
    "                ),\n",
    "                secondary_y=False,\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                    x=df_covid_region_1.Date,\n",
    "                    y=df_covid_region_1[covidKPI2],\n",
    "                    marker=dict(\n",
    "                        color=covid_colors[i]\n",
    "                    ),\n",
    "                    name=\"{} - {}\".format(covidKPI, r),\n",
    "                ),\n",
    "                secondary_y=True,\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                    x=df_covid_region_2.Date,\n",
    "                    y=df_covid_region_2[covidKPI2],\n",
    "                    marker=dict(\n",
    "                        color=covid_colors[i]\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                    name=\"{} - {}\".format(covidKPI, r)\n",
    "                ),\n",
    "                secondary_y=True,\n",
    "            )\n",
    "    \n",
    "    # Add figure title\n",
    "    fig.update_layout(\n",
    "        title_text=\"{} vs {}\".format(trafficKPI, covidKPI)\n",
    "    )\n",
    "\n",
    "    # fig = fill_with_areas(selected_data_groupped['Date'], dateRange, fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "#app_timeseries = build_app_timeseries(df_traffic_daily_SO, df_covid_SO)\n",
    "app_timeseries.run_server(mode='inline', port=26000) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_token='pk.eyJ1IjoiZnJhbmNpZ2plY2kiLCJhIjoiY2tpazZveWhmMDZ5MzMxcWp4bzIxbm0wYyJ9.J_qWOJqADI6tZfle2bbZFg'\n",
    "df_covid_all = pd.concat([df_covid_PO, df_covid_SO])\n",
    "df_traffic_all = pd.concat([df_traffic_daily_PO, df_traffic_daily_SO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='{}{}'.format(data_path, 'covid/regioni.geojson')\n",
    "with open(path) as f:\n",
    "    json_data = geojson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regions_to_filter = df_covid_all.loc[df_covid_all.Regione != 'Italia'].Regione.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Puglia', 'Emilia Romagna', 'Veneto', 'Lombardia', 'Abruzzo',\n",
       "       'Molise', 'Friuli Venezia Giulia', 'Basilicata', 'Calabria',\n",
       "       'Sicilia', 'Marche', 'Liguria', 'Campania', 'Sardegna', 'Lazio',\n",
       "       'Umbria', 'Piemonte', 'Toscana'], dtype=object)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_to_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Abruzzo', 'Basilicata', 'Calabria', 'Campania', 'Emilia Romagna',\n",
       "       'Friuli Venezia Giulia', 'Lazio', 'Liguria', 'Lombardia', 'Marche',\n",
       "       'Molise', 'Piemonte', 'Puglia', 'Sardegna', 'Sicilia', 'Toscana',\n",
       "       'Trentino-Alto Adige', 'Umbria', \"Valle d'Aosta\", 'Veneto'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traffic_all.loc[df_traffic_all.Regione != 'Italia'].Regione.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = set()\n",
    "for f in json_data.features:\n",
    "    regions.add(f[\"properties\"][\"reg_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_filtered = copy.deepcopy(json_data)\n",
    "for i, jd in enumerate(json_data_filtered.features):\n",
    "    region = jd[\"properties\"][\"reg_name\"]\n",
    "    if region not in regions_to_filter:\n",
    "        # TODO provo a mapparlo\n",
    "        try:\n",
    "            jd[\"properties\"][\"reg_name\"] = map_geojson(region)\n",
    "        except:\n",
    "            print(\"MANCA {}\".format(region))\n",
    "            del json_data_filtered.features[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Puglia', 'Emilia Romagna', 'Veneto', 'Lombardia', 'Abruzzo',\n",
       "       'Molise', 'Friuli Venezia Giulia', 'Basilicata', 'Calabria',\n",
       "       'Sicilia', 'Marche', 'Liguria', 'Campania', 'Sardegna', 'Lazio',\n",
       "       'Umbria', 'Piemonte', 'Toscana'], dtype=object)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_all.Regione.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:36000/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1374a8370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_regione = 'Regione'\n",
    "\n",
    "app_map = JupyterDash(\"CovidMap\", external_stylesheets=external_stylesheets)\n",
    "\n",
    "data_column, column_regione = 'Date', 'Regione'\n",
    "\n",
    "app_map.layout = html.Div([\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Date Picker: \",\n",
    "            dcc.DatePickerRange(\n",
    "                id='date-picker-range',\n",
    "                min_date_allowed=date(2020, 3, 1),\n",
    "                max_date_allowed=date(2020, 12, 31),\n",
    "                start_date=date(2020, 3, 1),\n",
    "                end_date=date(2021, 12, 31)\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    html.Label([\n",
    "            \"Covid KPI\",\n",
    "            dcc.Dropdown(id=\"covidKPI\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in covidKPIs],\n",
    "                        value=covidKPIs[0],\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Label([\n",
    "            \"Traffic KPI\",\n",
    "            dcc.Dropdown(id=\"trafficKPI\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in trafficKPIs],\n",
    "                        value=trafficKPIs[0],\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Label(\n",
    "                [\"Rolling average window \",\n",
    "                html.Br(),\n",
    "                dcc.Input(\n",
    "                id='rolling_avg',\n",
    "                type='number',\n",
    "#                 value=1\n",
    "                )]\n",
    "    ),\n",
    "    html.Label(\n",
    "                [\"Shift COVID\",\n",
    "                html.Br(),\n",
    "                dcc.Input(\n",
    "                id='shift',\n",
    "                type='number',\n",
    "                )]\n",
    "    ),\n",
    "    dcc.Graph(id=\"CovidMap\")]) # , animate = True\n",
    "\n",
    "# TODO pensare a come finire questo plot: metterei lag, mov avg, date picker per impostare la correlation.\n",
    "# TODO eventualmente farne un altro in cui seleziono solo uno dei due e ho anche slider\n",
    "\n",
    "@app_map.callback(\n",
    "[Output(\"CovidMap\", \"figure\")], \n",
    "    [\n",
    "         Input('date-picker-range', 'start_date'),\n",
    "         Input('date-picker-range', 'end_date'),\n",
    "        Input(\"covidKPI\", \"value\"), Input(\"trafficKPI\", \"value\"),Input(\"rolling_avg\", \"value\"), Input(\"shift\", \"value\")]\n",
    ")  \n",
    "def display_covid_period(start_date, end_date, covidKPI, trafficKPI, roll_avg, shift_amount):\n",
    "\n",
    "    layout = go.Layout(# width = 770, height=650,\n",
    "                       margin={\"r\":5,\"t\":5,\"l\":5,\"b\":5},\n",
    "                      mapbox = dict(center= {\"lat\": 41.892770, \"lon\": 12.483667},\n",
    "                                    accesstoken=map_token,\n",
    "                                    zoom=4))\n",
    "    \n",
    "    if start_date is not None:\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    if end_date is not None:\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    df_traffic_all[df_traffic_all[trafficKPI] <= 0] = np.nan\n",
    "    df_traffic_all.dropna(subset=[trafficKPI], inplace=True)\n",
    "        \n",
    "    if roll_avg is None or roll_avg <= 0:\n",
    "        roll_avg = 1\n",
    "        \n",
    "    if shift_amount is None:\n",
    "        shift_amount = 0\n",
    "                                    \n",
    "    df_covid_regions = df_covid_all.loc[df_covid_all.Regione != 'Italia']\n",
    "    df_traffic_regions = df_traffic_all.loc[df_traffic_all.Regione != 'Italia']\n",
    "    \n",
    "    def filter_fun(df):\n",
    "        return (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "    \n",
    "    df_traffic_regions = df_traffic_regions.loc[filter_fun(df_traffic_regions)]\n",
    "    df_covid_regions = df_covid_regions.loc[filter_fun(df_covid_regions)]\n",
    "    if shift_amount != 0:\n",
    "        df_covid_regions = df_covid_regions.shift(shift_amount)\n",
    "        df_covid_regions['Date'] += pd.DateOffset(shift_amount)\n",
    "\n",
    "    covidKPI2, trafficKPI2 = covidKPI, trafficKPI    \n",
    "    \n",
    "    if roll_avg > 1:\n",
    "        covidKPI2, trafficKPI2 = \"{}_roll\".format(covidKPI), \"{}_roll\".format(trafficKPI)\n",
    "        df_traffic_regions[trafficKPI2], df_covid_regions[covidKPI2] = \\\n",
    "            df_traffic_regions[trafficKPI].rolling(roll_avg).mean(), \\\n",
    "            df_covid_regions[covidKPI].rolling(roll_avg).mean()\n",
    "        \n",
    "    \n",
    "    map_vals = []\n",
    "    for region in df_traffic_regions.Regione.unique():\n",
    "        df_c, df_t = df_covid_regions.loc[df_covid_regions.Regione == region], df_traffic_regions.loc[df_traffic_regions.Regione == region]\n",
    "        df_c[\"Correlation\"] = df_c[covidKPI2]\n",
    "        df_t[\"Correlation\"] = df_t[trafficKPI2]\n",
    "        df_c.set_index('Date', inplace=True)\n",
    "        df_t.set_index('Date', inplace=True)\n",
    "        df_c.index = df_c.index.normalize()\n",
    "        df_t.index = df_t.index.normalize()\n",
    "        map_vals.append({\"Regione\": region, \"Correlation\": df_c.corrwith(df_t)['Correlation']})\n",
    "    df_corr = pd.DataFrame(map_vals)\n",
    "\n",
    "    data = [go.Choroplethmapbox( \n",
    "                                 locations = df_corr[column_regione],\n",
    "                                 z = df_corr[\"Correlation\"],\n",
    "                                 colorscale = 'inferno',\n",
    "                                 zmin=-1, zmax=1,\n",
    "    #                              text =regions,\n",
    "                                 featureidkey=\"properties.reg_name\",\n",
    "                                 colorbar = dict(thickness=20, ticklen=3),\n",
    "                                 geojson = json_data_filtered,\n",
    "                                 marker_line_width=0, marker_opacity=0.7)]\n",
    "\n",
    "    # Plot the figure \n",
    "    fig=go.Figure(data=data, layout=layout) # \n",
    "    fig.update_geos(showcountries=False, showcoastlines=False, showland=False, fitbounds=\"locations\")\n",
    "    \n",
    "    return [fig] # \n",
    "    \n",
    "\n",
    "app_map.run_server(mode='inline', port=36000, debug=True) #  use_reloader=False, mode='jupyterlab',debug=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO e se inserissimo percentuale di terapie intensive occupate???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# una riga per ogni (roll, shift); da parte ...\n",
    "rolls, shifts = [1, 5, 10], [0, 10, 20, 30, 40, 50]\n",
    "df_vals = []\n",
    "# filter dates\n",
    "\n",
    "df_covid_corr, df_traffic_corr = df_covid_all, df_traffic_all\n",
    "only_SO = True\n",
    "if only_SO:\n",
    "    df_covid_corr, df_traffic_corr = df_covid_SO, df_traffic_daily_SO\n",
    "\n",
    "df_covid_regions = df_covid_corr.loc[df_covid_corr.Regione != 'Italia']\n",
    "df_traffic_regions = df_traffic_corr.loc[df_traffic_corr.Regione != 'Italia']\n",
    "regions_corr = df_covid_regions.Regione.unique()\n",
    "\n",
    "# TODO per ora solo questo\n",
    "corrCovidKPIs, corrTrafficKPIs = [\"%pos\", \"terapia_intensiva\", \"R_mean\"], [\"Handover\"] # covidKPIs, trafficKPIs\n",
    "\n",
    "for roll_avg, shift_covid in itertools.product(*[rolls, shifts]):    \n",
    "    shifted_df_covid_regions = df_covid_regions.shift(-1*shift_covid)\n",
    "    shifted_df_covid_regions['Date'] += pd.DateOffset(-1*shift_covid)\n",
    "    to_copy = {\"roll\": roll_avg, \"shift\": shift_covid}\n",
    "    \n",
    "    for region in regions_corr:\n",
    "        row = to_copy.copy()\n",
    "        row['Regione']=region\n",
    "        for covidKPI, trafficKPI in itertools.product(*[corrCovidKPIs, corrTrafficKPIs]):\n",
    "            covidKPI2, trafficKPI2 = \"{}_{}_{}\".format(covidKPI, roll_avg, shift_covid), \"{}_{}_{}\".format(trafficKPI, roll_avg, shift_covid)\n",
    "            df_traffic_regions[trafficKPI2], shifted_df_covid_regions[covidKPI2] = \\\n",
    "                df_traffic_regions[trafficKPI].rolling(roll_avg).mean(), \\\n",
    "                shifted_df_covid_regions[covidKPI].rolling(roll_avg).mean()\n",
    "\n",
    "            col = \"{}_vs_{}\".format(covidKPI, trafficKPI)\n",
    "        \n",
    "            df_c, df_t = shifted_df_covid_regions.loc[shifted_df_covid_regions.Regione == region], df_traffic_regions.loc[df_traffic_regions.Regione == region]\n",
    "            df_c[\"Correlation\"] = df_c[covidKPI2]\n",
    "            df_t[\"Correlation\"] = df_t[trafficKPI2]\n",
    "            df_c.set_index('Date', inplace=True)\n",
    "            df_t.set_index('Date', inplace=True)\n",
    "            df_c.index = df_c.index.normalize()\n",
    "            df_t.index = df_t.index.normalize()\n",
    "            row[col] = df_c.corrwith(df_t)['Correlation']\n",
    "        df_vals.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO per ogni (covid, traffic), calcolo per rolling avg = {1,3,5, 7}, shift covid = {5, 10, 15, 20} la distribuzione del coeff\n",
    "df_correlations = pd.DataFrame(df_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:46001/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13715c7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO fare grafico con selezione col e dentro boxplot\n",
    "regionsToShow = list(regions)\n",
    "regionsToShow.append(\"Italia\")\n",
    "shifts = range(-50, 50)\n",
    "\n",
    "name = \"BOXPLOT CORRELATIONS per REGION\"\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app_boxplot = JupyterDash(name, external_stylesheets=external_stylesheets)\n",
    "\n",
    "app_boxplot.layout = html.Div([\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Date Picker: \",\n",
    "            dcc.DatePickerRange(\n",
    "                id='date-picker-range',\n",
    "                min_date_allowed=date(2020, 3, 1),\n",
    "                max_date_allowed=date(2020, 12, 31),\n",
    "                start_date=date(2020, 3, 1),\n",
    "                end_date=date(2021, 12, 31)\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "html.Label(\n",
    "    [\n",
    "        \"TRAFFIC\",\n",
    "        dcc.Dropdown(id=\"kpi1\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in trafficKPIs],\n",
    "                    value=trafficKPIs[0],\n",
    "                    clearable=False)\n",
    "    ]),\n",
    "html.Label(\n",
    "    [\n",
    "        \"COVID\",\n",
    "        dcc.Dropdown(id=\"kpi2\",\n",
    "                     options=[{\"label\": x, \"value\": x} for x in covidKPIs],\n",
    "                    value=covidKPIs[0],\n",
    "                    clearable=False)\n",
    "    ]),\n",
    "    html.Label(\n",
    "                [\"Rolling average window \",\n",
    "                html.Br(),\n",
    "                dcc.Input(\n",
    "                id='rolling_avg',\n",
    "                type='number',\n",
    "#                 value=1\n",
    "                )]\n",
    "    ),\n",
    "html.Div(dcc.Graph(id=name))])\n",
    "\n",
    "@app_boxplot.callback(\n",
    "Output(name, \"figure\"), \n",
    "[\n",
    "     Input('date-picker-range', 'start_date'),\n",
    "     Input('date-picker-range', 'end_date'),Input(\"kpi1\", \"value\"), Input(\"kpi2\", \"value\"), Input(\"rolling_avg\", \"value\")])\n",
    "def display_boxplot(start_date, end_date, trafficKPI, covidKPI, roll_avg):\n",
    "    \n",
    "    if start_date is not None:\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    if end_date is not None:\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "    if roll_avg is None:\n",
    "        roll_avg = 1\n",
    "    \n",
    "    def filter_fun(df):\n",
    "        return (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "    \n",
    "    df_covid_regions, df_traffic_regions = df_covid_all.loc[filter_fun(df_covid_all)], df_traffic_all.loc[filter_fun(df_traffic_all)]\n",
    "    \n",
    "    col = \"{}_vs_{}\".format(covidKPI, trafficKPI)\n",
    "    df_vals = []\n",
    "    \n",
    "    for shift_covid in shifts:    \n",
    "        shifted_df_covid_regions = df_covid_regions.shift(-1*shift_covid)\n",
    "        shifted_df_covid_regions['Date'] += pd.DateOffset(-1*shift_covid)\n",
    "        to_copy = {\"roll\": roll_avg, \"shift\": shift_covid}\n",
    "        \n",
    "        covidKPI2, trafficKPI2 = covidKPI, trafficKPI\n",
    "\n",
    "        for region in regions_corr:\n",
    "            row = to_copy.copy()\n",
    "            row['Regione']=region\n",
    "            if roll_avg > 1:\n",
    "                covidKPI2, trafficKPI2 = \"{}_{}_{}\".format(covidKPI, roll_avg, shift_covid), \"{}_{}_{}\".format(trafficKPI, roll_avg, shift_covid)\n",
    "                df_traffic_regions[trafficKPI2], shifted_df_covid_regions[covidKPI2] = \\\n",
    "                    df_traffic_regions[trafficKPI].rolling(roll_avg).mean(), \\\n",
    "                    shifted_df_covid_regions[covidKPI].rolling(roll_avg).mean()\n",
    "\n",
    "            df_c, df_t = shifted_df_covid_regions.loc[shifted_df_covid_regions.Regione == region], df_traffic_regions.loc[df_traffic_regions.Regione == region]\n",
    "            #df_c[covidKPI2] = (df_c[covidKPI2]-df_c[covidKPI2].mean())/df_c[covidKPI2].std()\n",
    "            #df_t[trafficKPI2] = (df_t[trafficKPI2]-df_t[trafficKPI2].mean())/df_t[trafficKPI2].std()\n",
    "            df_c[\"Correlation\"] = df_c[covidKPI2]\n",
    "            df_t[\"Correlation\"] = df_t[trafficKPI2]\n",
    "            df_c.set_index('Date', inplace=True)\n",
    "            df_t.set_index('Date', inplace=True)\n",
    "            df_c.index = df_c.index.normalize()\n",
    "            df_t.index = df_t.index.normalize()\n",
    "            row[col] = df_c.corrwith(df_t)['Correlation']\n",
    "            df_vals.append(row)\n",
    "    \n",
    "    df_correlations = pd.DataFrame(df_vals)\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        yaxis=dict(\n",
    "        range=[-1, 1]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig = px.box(df_correlations, x=\"shift\", y=col)\n",
    "    \n",
    "    # TODO add trace con media\n",
    "    means = df_correlations.groupby(by=[\"shift\"]).mean()\n",
    "    medians = df_correlations.groupby(by=[\"shift\"]).median()\n",
    "    #print(medians)\n",
    "    #for shift in sorted(df_correlations.shift.unique()):\n",
    "    #    medians.append(df_correla)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=means.index, y=means[col],\n",
    "                    mode='lines',\n",
    "                    name='Mean'))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=medians.index, y=medians[col],\n",
    "                    mode='lines',\n",
    "                    name='Median'))\n",
    "    \n",
    "    # Add figure title\n",
    "    fig.update_layout(\n",
    "        title_text=\"{} vs {}\".format(trafficKPI, covidKPI),\n",
    "        yaxis=dict(\n",
    "            range=[-1, 1]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # fig = fill_with_areas(selected_data_groupped['Date'], dateRange, fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "#app_timeseries = build_app_timeseries(df_traffic_daily_SO, df_covid_SO)\n",
    "app_boxplot.run_server(mode='inline', port=46001) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PO: 01/03 -> 31/05 -> 90 -> min #samples = 50\n",
    "# SO: 01/10 -> 31/12 -> 90 -> min #samples = 50\n",
    "# ASSESTAMENTO = A = dopo quanti giorni non cresce più; \n",
    "# m(R, t) = mediana dopo t giorni con RA = R; var(R, t) = MAX - MIN\n",
    "# A* = A s.t. max min\n",
    "# OSS: aumentanto RA diminuisce var(R, t); media risulta simile.\n",
    "# tenendo RA = 1 è meglio\n",
    "# SO: ci sono regioni con correlazione mooooooolto bassa\n",
    "# HANDOVER\n",
    "# vs % pos, [PO + SO]: A = 30; m(1, 30) = 0.4\n",
    "# vs % pos, PO: A = 26; m(1, 27) = 0.7 -> luminoso un po' ovunque. A* = 20\n",
    "# vs % pos, SO: A = 31; m(1, 31) = 0.6; oscilla in (31-38); A* = 28; m(A) = 0, m(A*) = 0.13; però i q1 sono simili\n",
    "\n",
    "# vs nuovi_positivi, [PO+SO]: A = 30, m(1, 30) = 0.4\n",
    "# vs nuovi_positivi, PO: A = 30, m(1, 30) = 0.6\n",
    "# vs nuovi_positivi, SO: A = A* = 36, m(1, 36) = 0.65; m(A*) = 0.24; oscilla in (29-36)\n",
    "\n",
    "# vs TI, [PO+SO]: A = 38, m(1, 38) = 0.3\n",
    "# vs TI, PO: A = 40, m(1, 40) = 0.8 -> anche \n",
    "# vs TI, SO: A = 40, m(1, 38) = 0.5; m(A*) = -0.5 -> regioni che non seguono trend\n",
    "\n",
    "# CONCLUSIONI HANDOVER:\n",
    "# 1) PO risulta essere molto più preciso; questo perchè durante la PO non c'era residuo di positività che, invece, ad esempio nel caso di Veneto, è chiarissimo durante la SO\n",
    "\n",
    "\n",
    "# Upload volume\n",
    "# % pos: negativo -> più persone aumentano nell'utilizzo dell'upload, più si è in lockdown -> informazione di come la positività influisce su ...\n",
    "# vs % pos: PO+SO: A = 29, m(1, 29) = -0.5\n",
    "# vs % pos, PO: A = 30, m(1, 30) = -0.77; A* = 17, min(A*) = -0.2, min(A) = -0.07\n",
    "# vs % pos, SO: A = 29; m(1, 29) = -0.6\n",
    "\n",
    "# vs % n_p: PO+SO: A = 29, m(1, 29) = -0.5\n",
    "# vs % n_p, PO: A = 27, m(1, 28) = -0.6; A* = 27, min(A*) = -0.4\n",
    "# vs % n_p, SO: A = 30; m(3, 30) = -0.5; A* = 26, m(A*) = 0 (B)\n",
    "\n",
    "# vs % TI: PO+SO: A = 40, m(1, 40) = -0.5\n",
    "# vs % TI, PO: A = 40, m(1, 40) = -0.8; min(A*) = -0.56\n",
    "# vs % TI, SO: A = 41; m(1, 41) = -0.7; min(A) = 0.6 (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soa di vecchi lavori con questi\n",
    "# predizione su RT -> un dato a settimana da \n",
    "# predizione su TI\n",
    "#0) DL and UL sono sproporzionati (es: roma - lazio)\n",
    "#1) timeseries per spiegare correlazione con lag che varia + differenze tra regioni + differenze prima - seconda ondata\n",
    "#2) boxplots per trovare lags per coppie: Hin vs {covid_features}, upload vs {covid features}\n",
    "#3) regioni: esempi di correlazione buona in piu regioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lazio_luglio = pd.read_pickle(\"{}{}\".format(by_region_path, \"LTE_1800_Lazio_1wave_07.pkl\"))\n",
    "df_citta = pd.read_pickle(\"{}{}\".format(data_path, \"LTE_1800_Roma.pkl\"))\n",
    "\n",
    "# LTE_1800_Lombardia_2wave_10.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lazio_luglio.loc[df_lazio_luglio.Date > pd.to_datetime('2020-01-01')].resample('D', on='Date').sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roma = df_citta.loc[df_citta.COMUNE==\"ROMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roma.loc[df_roma.Date > pd.to_datetime('2020-01-01')].resample('D', on='Date').sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_napoli = df_citta.loc[df_citta.COMUNE==\"NAPOLI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/jupyter_dash/jupyter_app.py\", line 289, in run\n",
      "    super_run_server(**kwargs)\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/dash/dash.py\", line 1716, in run_server\n",
      "    self.server.run(host=host, port=port, debug=debug, **flask_run_options)\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/flask/app.py\", line 990, in run\n",
      "    run_simple(host, port, self, **options)\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/werkzeug/serving.py\", line 1052, in run_simple\n",
      "    inner()\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/werkzeug/serving.py\", line 996, in inner\n",
      "    srv = make_server(\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/werkzeug/serving.py\", line 847, in make_server\n",
      "    return ThreadedWSGIServer(\n",
      "  File \"/Users/filipkrasniqi/.local/share/virtualenvs/traffic-covid-andFrCfE/lib/python3.8/site-packages/werkzeug/serving.py\", line 740, in __init__\n",
      "    HTTPServer.__init__(self, server_address, handler)\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/socketserver.py\", line 452, in __init__\n",
      "    self.server_bind()\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/server.py\", line 138, in server_bind\n",
      "    socketserver.TCPServer.server_bind(self)\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/socketserver.py\", line 466, in server_bind\n",
      "    self.socket.bind(self.server_address)\n",
      "OSError: [Errno 48] Address already in use\n"
     ]
    }
   ],
   "source": [
    "df_napoli.loc[df_napoli.Date > pd.to_datetime('2020-01-01')].resample('D', on='Date').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-covid",
   "language": "python",
   "name": "traffic-covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
