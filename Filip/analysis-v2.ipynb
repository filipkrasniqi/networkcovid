{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numpy import cos, sin, arcsin, sqrt\n",
    "from math import radians\n",
    "import seaborn as sns\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# need for token (mapbox)\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoiZmlsaXBrcmFzbmlxaSIsImEiOiJja2luOW9jdmgwa3J3MnpvNXhkNGJ6MWFtIn0.eevoM5byqvtc1nC0oXpuOw\")\n",
    "\n",
    "def haversine(row, lonlat):\n",
    "    lat1, lon1 = lonlat\n",
    "    lon2, lat2 = row['LNG'], row['LAT']\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * arcsin(sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "def cell_from_coords(data, lonlat):\n",
    "    data['LAT'], data['LNG'] = pd.to_numeric(data['LAT_Y'],errors='coerce'), pd.to_numeric(data['LONG_X'],errors='coerce')\n",
    "    data['distance'] = data.apply(lambda row: haversine(row, lonlat), axis=1)\n",
    "    row = data.sort_values(by='distance').iloc[0:1]\n",
    "    data.drop(['distance', 'LAT', \"LNG\"], axis=1, inplace=True)\n",
    "    return row\n",
    "\n",
    "def normalize(data, column):\n",
    "    data.loc[:, column] = (data[column]-data[column].mean())/data[column].std()\n",
    "    return data\n",
    "\n",
    "def fix_coords(data):\n",
    "    data['LAT'], data['LNG'] = pd.to_numeric(data['LAT_Y'],errors='coerce'), pd.to_numeric(data['LONG_X'],errors='coerce')\n",
    "    return data\n",
    "\n",
    "def prepare_for_hexbin(dataframe, weekly = True):\n",
    "    if weekly:\n",
    "        data_groupped = dataframe.groupby('ECELL_ID').resample('W-Mon', on='Date').mean().reset_index().sort_values(by='Date')\n",
    "    else:\n",
    "        data_groupped = dataframe.groupby('ECELL_ID').resample('MS', on='Date').mean().reset_index().sort_values(by='Date') \n",
    "    data_groupped = data_groupped.sort_values(by='Date')\n",
    "    data_groupped['DateString'] = data_groupped['Date'].map(lambda x: x.strftime('%j'))\n",
    "    data_groupped[\"DateString\"] = (data_groupped[\"DateString\"].astype(int)+1)//7\n",
    "    return data_groupped\n",
    "\n",
    "def remove_outliers(df, col):\n",
    "    df = df.dropna(subset=[col])\n",
    "    return df[df[col] < np.percentile(df[col],95)]\n",
    "\n",
    "\n",
    "data_path = \"/Users/filipkrasniqi/Documents/Datasets.tmp/traffic-covid/\"\n",
    "cities = [\"Milano\", \"ROMA\", \"TORINO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data regarding Rome and Milan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_milano, data_rome, data_turin = [pd.read_pickle(\"{}LTE_1800_{}.pkl\".format(data_path, city)) for city in cities]\n",
    "#data_milano, data_rome, data_turin = fix_coords(data_milano), fix_coords(data_rome), fix_coords(data_turin)\n",
    "data_milano = fix_coords(pd.read_pickle(\"{}LTE_1800_{}.pkl\".format(data_path, cities[0])))\n",
    "data_milano_2 = fix_coords(pd.read_pickle(\"{}LTE_1800_{}_P2.pkl\".format(data_path, cities[0])))\n",
    "data_rome = fix_coords(pd.read_pickle(\"{}LTE_1800_{}.pkl\".format(data_path, cities[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_milano = fix_coords(pd.read_pickle(\"{}LTE_1800_{}.pkl\".format(data_path, cities[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from the three datasets regarding DL_VOL and Hin_Succ\n",
    "data_milano = remove_outliers(data_milano, \"DL_VOL\")\n",
    "data_milano = remove_outliers(data_milano, \"Hin_Succ\")\n",
    "\n",
    "data_milano_2 = remove_outliers(data_milano_2, \"DL_VOL\")\n",
    "data_milano_2 = remove_outliers(data_milano_2, \"Hin_Succ\")\n",
    "#data_rome = remove_outliers(data_rome, \"DL_VOL\")\n",
    "data_rome = remove_outliers(data_rome, \"DL_VOL\")\n",
    "data_rome = remove_outliers(data_rome, \"Hin_Succ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging them\n",
    "all_data_milano = pd.concat([data_milano, data_milano_2])\n",
    "all_data_milano[\"City\"] = 0\n",
    "data_rome[\"City\"] = 1\n",
    "all_data = pd.concat([all_data_milano, data_rome])\n",
    "all_data[\"USERNUM_AVG\"] = all_data[\"USERNUM_AVG\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_groupped_week = prepare_for_hexbin(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_groupped_month = prepare_for_hexbin(all_data, weekly = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, required_columns = [\"DL_VOL\", \"Hin_Succ\", \"USERNUM_AVG\"], [\"LAT\", \"LNG\", \"DateString\", \"City\"]\n",
    "week_selected_data_groupped = data_groupped_week[columns+required_columns].dropna()\n",
    "#selected_data_groupped = data_groupped[columns+required_columns].dropna()\n",
    "week_selected_data_groupped[\"City\"] = week_selected_data_groupped[\"City\"].astype(int)\n",
    "week_selected_data_groupped[\"City\"] = week_selected_data_groupped[\"City\"].apply(lambda x: cities[x])\n",
    "\n",
    "month_selected_data_groupped = data_groupped_month[columns+required_columns].dropna()\n",
    "#selected_data_groupped = data_groupped[columns+required_columns].dropna()\n",
    "month_selected_data_groupped[\"City\"] = month_selected_data_groupped[\"City\"].astype(int)\n",
    "month_selected_data_groupped[\"City\"] = month_selected_data_groupped[\"City\"].apply(lambda x: cities[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x265352f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = JupyterDash(\"Map\")\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Label([\"KPIs\", dcc.Dropdown(\n",
    "        id=\"kpi\",\n",
    "        options=[{\"label\": x, \"value\": x} for x in columns],\n",
    "        value=columns[0],\n",
    "        clearable=False,\n",
    "                )]),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Citt√†\",\n",
    "            dcc.Dropdown(id=\"city\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in week_selected_data_groupped.City.unique()],\n",
    "                        value=week_selected_data_groupped[\"City\"].unique()[1],\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Data range\",\n",
    "            dcc.Dropdown(id=\"dateRange\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in [\"Week\", \"Month\"]],\n",
    "                        value=\"Week\",\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Div(dcc.Graph(id=\"map-chart\"))\n",
    "]) # , style={'columnCount': 2}\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"map-chart\", \"figure\"), \n",
    "    [Input(\"kpi\", \"value\"), Input(\"city\", \"value\"), Input(\"dateRange\", \"value\")])\n",
    "\n",
    "def display_map(kpi, city, dateRange):\n",
    "    \n",
    "    if dateRange == \"Week\":\n",
    "        selected_data_groupped = week_selected_data_groupped\n",
    "    else:\n",
    "        selected_data_groupped = month_selected_data_groupped\n",
    "    \n",
    "    filtered_data_groupped = selected_data_groupped.where(lambda x:x.City==city).dropna()\n",
    "    fig = ff.create_hexbin_mapbox(\n",
    "        data_frame=filtered_data_groupped,\n",
    "        lat=\"LAT\", lon=\"LNG\", nx_hexagon=30, animation_frame=\"DateString\", color=kpi,\n",
    "        color_continuous_scale=\"Inferno\", labels={\"color\": kpi, \"frame\": \"DateString\"}\n",
    "    )\n",
    "    fig.update_layout(margin=dict(b=0, t=0, l=0, r=0))\n",
    "    fig.layout.sliders[0].pad.t=20\n",
    "    fig.layout.updatemenus[0].pad.t=60\n",
    "\n",
    "#     fig.show()  \n",
    "    return fig\n",
    "\n",
    "app.run_server(mode='inline') # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for period visualization\n",
    "all_data[\"hour\"] = [t.hour for t in pd.DatetimeIndex(all_data.Date)]\n",
    "columns_all_data, required_columns_all_data = [\"DL_VOL\", \"Hin_Succ\", \"USERNUM_AVG\"], [\"LAT\", \"LNG\", \"City\", 'hour', 'Date', 'ECELL_ID']\n",
    "periods = [\"Dawn\", \"Morning\", \"Lunch\", \"Afternoon\", \"Evening\"]\n",
    "# getting data with relative period\n",
    "evening_data = all_data[columns_all_data+required_columns_all_data].where(lambda x: (x.hour >= 20) & (x.hour <= 23)).dropna()\n",
    "afternoon_data = all_data[columns_all_data+required_columns_all_data].where(lambda x: (x.hour >= 16) & (x.hour <= 19)).dropna()\n",
    "lunch_data = all_data[columns_all_data+required_columns_all_data].where(lambda x: (x.hour >= 12) & (x.hour <= 15)).dropna()\n",
    "morning_data = all_data[columns_all_data+required_columns_all_data].where(lambda x: (x.hour >= 8) & (x.hour <= 11)).dropna()\n",
    "dawn_data = all_data[columns_all_data+required_columns_all_data].where(lambda x: (x.hour >= 4) & (x.hour <= 7)).dropna()\n",
    "# assign column \"period\"\n",
    "evening_data[\"period\"] = 4\n",
    "afternoon_data[\"period\"] = 3\n",
    "lunch_data[\"period\"] = 2\n",
    "morning_data[\"period\"] = 1\n",
    "dawn_data[\"period\"] = 0\n",
    "# TODO io voglio un punto per ogni (cella, periodo): √® cos√¨??? in teoria no!!\n",
    "# merge all in one\n",
    "\n",
    "evening_data_week, afternoon_data_week, lunch_data_week, morning_data_week, dawn_data_week = \\\n",
    "        prepare_for_hexbin(evening_data), prepare_for_hexbin(afternoon_data), prepare_for_hexbin(lunch_data), \\\n",
    "        prepare_for_hexbin(morning_data), prepare_for_hexbin(dawn_data)\n",
    "\n",
    "evening_data_month, afternoon_data_month, lunch_data_month, morning_data_month, dawn_data_month = \\\n",
    "        prepare_for_hexbin(evening_data, weekly = False), prepare_for_hexbin(afternoon_data, weekly = False), \\\n",
    "        prepare_for_hexbin(lunch_data, weekly = False), prepare_for_hexbin(morning_data, weekly = False), \\\n",
    "        prepare_for_hexbin(dawn_data, weekly = False)\n",
    "\n",
    "#period_data_groupped_month = prepare_for_hexbin(period_data, weekly = False)\n",
    "#period_data = pd.concat([dawn_data, morning_data, lunch_data, afternoon_data, evening_data])\n",
    "period_data_groupped_week = pd.concat([evening_data_week, afternoon_data_week, lunch_data_week, morning_data_week, dawn_data_week])\n",
    "period_data_groupped_month = pd.concat([evening_data_month, afternoon_data_month, lunch_data_month, morning_data_month, dawn_data_month])\n",
    "\n",
    "period_columns = columns+required_columns+['period', 'ECELL_ID']\n",
    "period_week_selected_data_groupped = period_data_groupped_week[period_columns].dropna()\n",
    "period_week_selected_data_groupped[\"period\"] = period_week_selected_data_groupped[\"period\"].astype(int)\n",
    "period_week_selected_data_groupped[\"City\"] = period_week_selected_data_groupped[\"City\"].astype(int)\n",
    "period_week_selected_data_groupped[\"City\"] = period_week_selected_data_groupped[\"City\"].apply(lambda x: cities[x])\n",
    "period_week_selected_data_groupped[\"period\"] = period_week_selected_data_groupped[\"period\"].apply(lambda x: periods[x])\n",
    "\n",
    "period_month_selected_data_groupped = period_data_groupped_month[period_columns].dropna()\n",
    "period_month_selected_data_groupped[\"period\"] = period_month_selected_data_groupped[\"period\"].astype(int)\n",
    "period_month_selected_data_groupped[\"City\"] = period_month_selected_data_groupped[\"City\"].astype(int)\n",
    "period_month_selected_data_groupped[\"City\"] = period_month_selected_data_groupped[\"City\"].apply(lambda x: cities[x])\n",
    "period_month_selected_data_groupped[\"period\"] = period_month_selected_data_groupped[\"period\"].apply(lambda x: periods[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:16000/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x266ccd9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app_period = JupyterDash(\"PERIOD\")\n",
    "\n",
    "app_period.layout = html.Div([\n",
    "    html.Label([\"KPIs\", dcc.Dropdown(\n",
    "        id=\"kpi\",\n",
    "        options=[{\"label\": x, \"value\": x} for x in columns],\n",
    "        value=columns[0],\n",
    "        clearable=False,\n",
    "                )]),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Citt√†\",\n",
    "            dcc.Dropdown(id=\"city\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in period_week_selected_data_groupped.City.unique()],\n",
    "                        value=period_week_selected_data_groupped[\"City\"].unique()[1],\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Data range\",\n",
    "            dcc.Dropdown(id=\"dateRange\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in [\"Week\", \"Month\"]],\n",
    "                        value=\"Week\",\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Period\",\n",
    "            dcc.Dropdown(id=\"period\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in period_week_selected_data_groupped.period.unique()],\n",
    "                        value=\"Dawn\",\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Label(\n",
    "        [\n",
    "            \"Period vs evening\",\n",
    "            dcc.Dropdown(id=\"period_vs_evening\",\n",
    "                         options=[{\"label\": x, \"value\": x} for x in [\"Yes\", \"No\"]],\n",
    "                        value=\"No\",\n",
    "                        clearable=False,),\n",
    "        ]\n",
    "    ),\n",
    "    html.Div(dcc.Graph(id=\"period-chart\"))])\n",
    "    \n",
    "@app_period.callback(\n",
    "    Output(\"period-chart\", \"figure\"), \n",
    "    [Input(\"kpi\", \"value\"), Input(\"city\", \"value\"), Input(\"dateRange\", \"value\"), Input(\"period\", \"value\"), Input(\"period_vs_evening\", \"value\")])\n",
    "def display_map_period(kpi, city, dateRange, period, periodVsEvening):\n",
    "    \n",
    "    if period == 'Evening':\n",
    "        periodVsEvening = 'No'\n",
    "    \n",
    "    if dateRange == \"Week\":\n",
    "        selected_data_groupped = period_week_selected_data_groupped\n",
    "    else:\n",
    "        selected_data_groupped = period_month_selected_data_groupped\n",
    "    \n",
    "    filtered_data_groupped = selected_data_groupped.where(lambda x:x.City==city).dropna()\n",
    "    if periodVsEvening == 'No':\n",
    "        filtered_data_groupped = filtered_data_groupped.where(lambda x:x.period==period).dropna()\n",
    "        filtered_data_groupped = filtered_data_groupped.set_index(['ECELL_ID', 'DateString'])\n",
    "        filtered_data_groupped.reset_index(inplace=True)\n",
    "    else:\n",
    "        filtered_data_groupped = filtered_data_groupped.set_index(['ECELL_ID', 'DateString'])\n",
    "        filtered_data_groupped_evening = filtered_data_groupped.where(lambda x:x.period=='Evening').dropna()\n",
    "        filtered_data_groupped_period = filtered_data_groupped.where(lambda x:x.period==period).dropna()\n",
    "        \n",
    "        filtered_data_groupped = filtered_data_groupped_evening#\n",
    "        filtered_data_groupped[kpi] = (filtered_data_groupped[kpi] - filtered_data_groupped_period[kpi]).abs()\n",
    "        \n",
    "        filtered_data_groupped.reset_index(inplace=True)\n",
    "        filtered_data_groupped_evening.reset_index(inplace=True)\n",
    "        filtered_data_groupped_period.reset_index(inplace=True)\n",
    "        \n",
    "    fig = ff.create_hexbin_mapbox(\n",
    "        data_frame=filtered_data_groupped,\n",
    "        lat=\"LAT\", lon=\"LNG\", nx_hexagon=30, animation_frame=\"DateString\", color=kpi,\n",
    "        color_continuous_scale=\"Inferno\", labels={\"color\": kpi, \"frame\": \"DateString\"}\n",
    "    )\n",
    "    fig.update_layout(margin=dict(b=20, t=20, l=0, r=0))\n",
    "    \n",
    "    fig.layout.sliders[0].pad.t=30\n",
    "    fig.layout.updatemenus[0].pad.t=50\n",
    "\n",
    "#     fig.show()  \n",
    "    return fig\n",
    "\n",
    "app_period.run_server(mode='inline', port=16000) # debug=True, use_reloader=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO parlare con Andrea per analizzare Roma (dritte su zone e altro)\n",
    "# TODO different KPIs -> Filip -> X\n",
    "# TODO per month instead of week -> Filip -> X\n",
    "\n",
    "# TODO represent in different period during days, and compare with dinner time (as a base for home) -> Filip\n",
    "# TODO represent in different period of weeks, and compare with weekend -> Filip\n",
    "\n",
    "# TODO find info about density of population on specific places / areas -> Franci, (Filip)\n",
    "# TODO find area specification per area (e.g.: business, home, turistic, ...) -> Franci, (Filip)\n",
    "\n",
    "# -> brainstorming: attempt on 23/12\n",
    "\n",
    "# es: Garibaldi -> DoW, h8-h12, h14-h18: work\n",
    "# DoW + WE, h18-6: home\n",
    "\n",
    "# TODO ratio at every time of dl_link\n",
    "# TODO dl_link/#user -> low values represent high mobility areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-covid",
   "language": "python",
   "name": "traffic-covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
